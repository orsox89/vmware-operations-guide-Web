[
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-9---infrastructure-architect/4.9.1-the-chef-and-his-cooking/",
      "title": "1. The Chef and His Cooking",
      "tags": [],
      "description": "",
      "content": "I see myself as an Infrastructure Architect. After almost a decade in application world, I entered the weird and wonderful world of enterprise IT infrastructure, starting as a presales with Sun Microsystems in 2003. My job titles, roles and departments have changed many times since then, but fundamentally it\u0026rsquo;s about architecting enterprise infrastructure. My official role is a Product Manager for an operations management product, but I still see myself as the engineer doing the performance troubleshooting and reading logs.\nThe Chef and His Cooking This is a story of the life of a VMware Admin that I shared as an impromptu presentation at our VMUG Singapore back in 2014 and it still resonates until today.\nThe restaurant business provides a good analogy to our IaaS business. We, the infrastructure architect, are the Chef. In that end-user environment where you work, you are the expert in producing what your customers want. You architect and design a solid platform, where your customers can confidently run their VMs. If there is an issue, you often get involved, restoring their confidence in your creation. You are seen as the VMware expert, or the virtualization expert. Yes, you may engage VMware Professional Services or Support, but they are not employees of you company. You are the employee. As far as your customers concern, the buck stops at you.\nYou do not sell hardware nor software; you charge your customers per VM. In fact, to ensure that your customers order the right kind of VM, you need to charge per vCPU, per vRAM and per vDisk. The chargeback model is something that I very rarely see discussed. We tend to stay in technical discussions. We need to realise we are no longer just a System Builder. We are Service Provider. By not extending our circle of influence into how App Teams should pay for our service, we created the issue we have today (Oversized VMs, dormant VMs, VM sprawl). We need to \u0026ldquo;step out from the kitchen\u0026rdquo; from time to time. We need to be like the Chef who steps out into the dining area, building relationships with his customers, explaining the reason behind his cooking.\nAs the Architect, we are the best person to determine how much to charge for these. We built this environment. We know the costs, and we know the capacity. Not convinced? Put it this way, would you rather someone else determine how much your creation is worth?\nWe all know that IT exists because of Business. It starts with the Business. Some of the issues we have are caused by unsuitable chargeback models and incorrect Service Tiering. The VM in Tier 1 (mission critical) platform cannot cost the same as the VM in Tier 3 (non-production). I\u0026rsquo;d make sure there is distinct difference in quality between Tier 1, Tier 2 and Tier 3, so it\u0026rsquo;s easy for business to choose. Need a good example? Review this.\nUsing the restaurant analogy, say you cook fried rice. It\u0026rsquo;s your dish. You need to determine the price of the fried rice. You also need to be able to justify why you have normal fried rice and special fried rice, and why the special one costs a lot more for the same amount of food.\nTo me, the Chargeback model and the Service Tiering serve as Key Drivers to our Architecture. I will not consider my architecture complete unless I include these 2 in my design. We are architecting to meet the business requirements, which are \u0026ldquo;defined\u0026rdquo; in the chargeback model (e.g. the business wants a $100 VM per month, not a $100K VM per month), and service tiering (e.g. the business wants 99.999% and 3% CPU Contention).\nAs shared, I see a chance for us to step up and step out.\nStep out of the kitchen and network with your customers (the Application team). Educate and fix the problem at the source. Step up from pure IT architecture to business architecture. Architect your pricing strategy and service tiering. The good thing about pricing is\u0026hellip; your benchmark is already set.\nAzure, AWS, Google, and many Service Providers have already set the benchmark. Your private cloud cannot be too far from it. Too low and you will likely make a loss (it\u0026rsquo;s almost impossible to beat their efficiency). Too high and you will get a complain. Another source of benchmark is to consider what it would cost to run the same applications on physical servers\nIf you are pricing your VDI, the cost of a PC sets your benchmark. You can be higher, but not by a huge gap. A PC costs $800 with Windows + 3 year warranty + 17\u0026quot; monitor. Add your IT Desktop cost, and you meet your benchmark.\nI hope you enjoyed it and do share your life story!\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.1-roles-and-responsibilities/",
      "title": "1. Roles &amp; Responsibilities",
      "tags": [],
      "description": "",
      "content": "We covered the various roles required in cloud operations earlier, so let\u0026rsquo;s dive into the roles specific for DaaS operations. Depending on the size \u0026amp; complexity of the VDI architecture, there can be many roles involved in operations.\nRole Responsibility Level 1 Ops Reactive: respond to user complaint or alerts and perform simple remediation. Typically does not require reading logs. Proactive health check of the environment, as part of the SOP. Look at availability, performance and compliance. Level 2 Ops Reactive: Perform advance troubleshooting. Likely require reading logs and Windows Events. Proactive: Analyse the overall environment, especially from performance and availability. Should do this at least once a week. Capacity Review the pool and farm capacity. Depending on the volatility, this could be done monthly. Compliance Set the compliance settings to agreed internal and industry standard. Verify that non-compliance alert was addressed timely and correctly by the operations team. Report the comp. IT Management Weekly report, focusing on the overall health and not individual users or pools. Monthly presentation and review, supported for live dashboard for an interactive discussion. The responsibilities cover the 7 pillar of operations. As Horizon requires vSphere, Microsoft ADAM Database, Microsoft Active Directory (MS AD) and other components, you need to manage all of them as a system.\nPillar Availability Any desktops that are in bad state? Any availability problems in vSAN, NSX, vSphere, DC network switches, WAN network? Performance There are 2 sides of performance: a single user and the whole DaaS.\nA single user troubleshooting may require going deep into the user’s desktop and user’s specific settings (e.g. MS AD group policy, MS Outlook plugins). Tools such as SysInternals and Windows Event analyser can come in handy. This may involve disable settings as you eliminate possibilities.\nDaaS-wide troubleshooting requires going broad into all the users (affected and not affected with the issue). It requires analyses across the stacks. You likely need various adapters of vRealize Operations and Log Insights, and develop your own custom dashboard that’s specific to your architecture. Capacity There are many parts of DaaS capacity.\nThe 1st part is the desktop, pools and farms. Make sure the desktop is rightsized, and the pools \u0026amp; farms can meet the load.\nThe 2nd part is Horizon servers and infrastructure. This covers Horizon servers (Connection Servers, Universal Access Gateway and App Volume Managers), non Horizon servers (Microsoft SQL Servers, MS AD, Load Balancers, AV servers, single sign on servers, security servers).\nThe 3rd part is the network. This excludes the data center network, but includes the client network and the Wide Area Network (WAN). The client network can be in the form of shared office, café or mall, airport or home. The WAN can be a mixed of mobile, wireless or leased lines.\nThe 4th part is the underlying SDDC where the EUC is running. Cost VDI has a direct comparison to a physical laptop or desktop. One reason why VDI does not dominate End User Computing market is their cost is comparable with laptop or desktop, and laptop provides the offline capability. One way to keep the cost down is the consolidation ratio. How many desktops or users can you pack into a single cluster? Compliance Different users may require different compliance. How do you prove that you’ve delivered continuous compliance? Configuration Any misconfiguration, outdated configuration, incompatible configuration or suboptimal configuration? This needs to be checked across the entire stack, especially the lower stack as problem in a stack will impact the stack above it. From the brief summary above, you can see that VDI operations management is complex. It\u0026rsquo;s much more than waiting for user to complain and then troubleshoot a single desktop.\nMinimize the time troubleshooting single users by optimizing the Windows image, so you can focus on wide-spread problems. Using VMware OS Optimization Tool, you can get improvements like these:\nreduce disk space by up to 80%. reduces the time to create desktop pools by up to 3x. speed up user profile creation from 30 seconds to 8 seconds. reduce memory by up to 2x. reduce CPU usage by up to 40% reduce disk IOPS by up to 2.5x. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-7---vmware-it-operations/4.7.1-background/",
      "title": "1. Background",
      "tags": [],
      "description": "",
      "content": "As VMware continued to make acquisitions and drive organic growth, the infrastructure monitoring landscape expanded to include thousands of objects, significantly increasing Objects licensing costs.\nSimultaneously, challenges with configuration and tool management started to build up. The increased complexity of our infrastructure landscape and growing demand for modern, proactive features such as dashboards, reports, rich historical data, and real-time monitoring made it clear that the existing tooling was no longer adequate.\nChallenges VMware IT Tools Team, are responsible for Availability, Performance and Automate the monitoring to cover IT Infrastructure monitoring space. We were running various tools for silo and legacy monitoring since we don\u0026rsquo;t have a tool to cover proactive and End-to-End monitoring. Its lead into operation over-ahead and more Opex cost.\nAs a consumer, it\u0026rsquo;s difficult to see their owned device monitoring courage, historical data, dashboards and reports. They need to analysis various tools matrix to troubleshoot their problem. Need more time to isolate the issue on multi support group organisation.\nDefining Solution Requirements Before we got to work migrating to new infrastructure monitoring solutions, we needed to formulate a solid definition of success - what were we trying to achieve and how would we know when we got there. To get started, VMware IT prepared a case study focused on the current data collection methodology, frequency, metrics, and how the existing tool issued alerts and notifications. It included the service owner requirements according to application type for new custom groups, dashboards, views, and scheduled reports. We collected all the custom monitoring requirements and created user stories to support the service owner\u0026rsquo;s requests.\nVMware IT recognized the need to move from traditional monitoring to a more modern approach. Shifting from reactive monitoring to a proactive, modern stance would help us identify new issues and root causes more quickly. The advanced reporting capabilities in modern monitoring solutions provide the flexibility to customize performance metrics based on service owner requirements.\nVMware IT use vRealize Operations Manager for our infrastructure monitoring to gain application-to-storage visibility across physical, virtual, and cloud infrastructures. We can now investigate and solve complex technical issues faster because of the more precise analytics provided by vRealize Operations. Once the vCenters are identified and plugged in, all components under the purview of each vCenter get automatically monitored during the lifecycle of the component.\nMigration Preparation Ensuring continuous monitoring with no impact to service owners with a seamless migration was a critical objective that drove the team\u0026rsquo;s preparations. The first step was to set up the vRealize Operations node and location-based collectors behind the load balancer, to meet network latency and high availability standards.\nCustomization was a key area of focus. We ensured that the correct ownership was assigned to each application and tagged accordingly to configure alert notifications based on the application owner\u0026rsquo;s specifications and policies.\nIn vRealize Operations we used the \u0026ldquo;delay\u0026rdquo; feature to set alert timeframes according to the requirements of service owners. This helped us to ensure that all the alerts received by service owners are actionable. We also created container tags to distinguish our inventory as production, non-production and maintenance which helps our team provide efficient operational support.\nWe wrote several scripts based on the vRealize Operations API to automate steps to configure the monitoring tool.\nSimplified the migration of 4,000 plus devices Separate devices by operating system (OS) Group and map them according to specific policies Attach objects and devices to service owners Create remote checks for critical items mapped to container tags Once we completed writing these scripts, it was time to launch the migration of devices from the current tool to vRealize Operations.\nWe have many objects being monitored and it\u0026rsquo;s challenging to know who is responsible to remediate/action upon the alerts. To simplify this, we have introduced IMSET, an external service to accomplish these requirements.\nWe tagged objects based on support groups and enabled this tagged information in IMSET payload to reflect the tag name in alert content. This helps Operations teams to easily identify the Application/Service Owner and thus reduce the overall time taken to remediate the issue.\nImplementation Approach To launch this phase, we completed several steps and collaborated closely with service owners to ensure their acceptance of the vRealize Operations alerts.\nThe first step was to extract the master object inventory list from the existing tool. Next, the VMware IT infrastructure team installed agents on servers and confirmed the object availability from vRealize Operations. Finally, we initiated the prepared scripts to create the objects and then mapped to the groups and policies from the existing tool object inventory list.\nThe plan was to run parallel monitoring between the current tool and vRealize Operations for three months. We created a separate channel in the Network Operations Centers (NOC) dashboard to receive all vRealize Operations alerts and run a comparison between the existing tool and vRealize Operations alerts against the objects.\nDuring the parallel monitoring stage, VMware IT exported the data from NOC dashboard, then worked together with the service owners to compare and fine-tune the alerts. Once the service owners accepted the alerts issued from vRealize Operations, we discontinued parallel monitoring and began utilizing vRealize Operations as the primary monitoring tool for VMware IT infrastructure.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-6---automation/4.6.1-introduction/",
      "title": "1. Introduction",
      "tags": [],
      "description": "",
      "content": "I bet you still remember that part \u0026ldquo;Yes, I did not cover Automation. For me, that\u0026rsquo;s part of Architecture. You should not automate what you cannot operate.\u0026rdquo;\nIn other words, what you can operate should be automated.\nAnd \u0026ldquo;Using an analogy, it\u0026rsquo;s like a plane with many automation features. That\u0026rsquo;s a feature of the plane.\u0026rdquo; The times where pilots had to do everything manually while flying a plane are long gone. Nowadays a modern plane is supporting the crew through automation - think of the autopilot.\nvRealize Operations is doing automation out of the box in form of automated control routines; it is \u0026ldquo;automatically\u0026rdquo; monitoring the environment thorough pre-defined or custom Symptoms, Alert Definitions and Compliance Packs. These routines control the creation of Alarms and provides information presented through Dashboards and Reports.\nVarious Compliance Packs help reduce risk and enforce IT and regulatory standards for vSphere through continuous checks and automated drift remediation.\nBut there is more.\nAnd this is exactly how you should operate your environment. Self-Driving Operations should not remain just a catchword, let us make it a reality!\nBenefits Probably everybody knows the impact automation has on the industry, not only since the invention of industrial robotics in the 50s and 60s of the last century.\nBut why is automation important, what are the reasons behind introducing a technology which may be complex and cost intensive as it might appear at first sight?\nYes, automation may indicate that you will need to invest time initially, and time means money. You are making a one-time invest or if you will, increasing your CAPEX.\nWhat does it give you back? The answer is actually pretty easy:\nRepetitive work does not have to be done manually anymore; you are reducing your OPEX You free up time to focus on more important things for your business Repetitive work is done the same way, following a descriptive procedure, eliminating human errors (except for the ones in your procedure) It makes auditing easier or even possible in first place It increases productivity, reliability and performance Automation is work force multiplier Basic Principles of Automation Before we jump into the essentials of this chapter, let us take a quick look on the typical ingredients of automated systems. The following picture shows the four basic elements comprising an automated system. Controller, sensors, actors and the plant build a closed loop.\nThis is example of a closed is also called closed-loop feedback control. Another, less complex kind of automated system is shown in the next picture. It is a so called open-loop control.\nHow does this translate to an environment managed by vRealize Operations? Let us start with the less complex example, the ingredients are at the end the same in both examples.\nAs you can see in the next figure, some parts are easy to be mapped to components that you will find in your SDDC.\nThe sensors are our adapter instances collecting metrics and properties, the controller is vRealize Operations itself and the plant that we would like to control or automate is e.g., our vCenter instance managing ESXi hosts, VMs, Datastores etc.\nBut what are the actors and how could the controller, so vRealize Operations, interact with other systems?\nI will answer both questions in the next sections, so keep reading, you have made it through the dry theory.\nInter-System Communication I start with the second part of the question; how can vRealize Operations interact with other systems?\nWith \u0026ldquo;other systems\u0026rdquo; I am referring to systems contributing to the automation but not necessarily being the plant we want to control.\nMany customers have extended vRealize Operations to interact with other systems using interfaces provided by those systems. In context of automation, we usually use the term Application Programing Interfaces - APIs. Interacting with other systems means outgoing as well as incoming communication as seen from the vRealize Operations perspective.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-5---log-insight/4.5.1-vsphere/",
      "title": "1. vSphere",
      "tags": [],
      "description": "",
      "content": "Log Insight provides the ability to slice and dice vCenter events, tasks and alarms. This can be handy in audit investigation.\nvCenter Events Analysis To see all the vCenter events, all we need is to select a built-in variable called VC Event Type. A log entry that has this field exist will appear.\nFrom the following chart, we can see there are steady stream of events every 10 minutes. You can change the data granularity.\nWe can see actual event names by changing into a table. We can sort it to show the top events if required.\nWe are interested in events impacting our consumer (VMs), so let\u0026rsquo;s filter it out. The filter is vim25.vm* as that is what vCenter shows in its log as we can see from the above table. I did not know that vCenter uses vim25.vm, but looking at the table above I could make an educated guess.\nOnce the above filter is set, I rerun the search and get all events impacting VM.\nLet\u0026rsquo;s zoom into one of the events. Let\u0026rsquo;s say we\u0026rsquo;re interested in VM configuration event and want to know what exactly was changed. So let\u0026rsquo;s zoom into that event and group it by the user who changed it. We get the following chart, showing the user in the legend.\nYou can group the data by VM name to see which VM were changed when. I\u0026rsquo;ve cropped the VM name in the legend.\nYou can see the result in tabular format. You have the VM name, user name and additional context such as the parent ESXi host at the time of the change.\nLast but not least, you can see the actual change, as higlighted in green.\nvCenter Tasks Analysis To see all the vCenter Tasks, all we need is to select a built-in variable called VC Task Type. A log entry that has this field exist will appear.\nWe can see that there is a regular stream of events throughout the day. The pattern looks normal.\nLet\u0026rsquo;s show the top tasks by showing the result in table format.\nTo zoom into any of the tasks, we specify the task name. I only specify one below, but it can take multiple.\nUsing the above, and limiting the result to a narrower time window, we can zoom into the nearest minute.\nSnapshot Analysis You can visually see all the snapshot operations with a single filter vmw_esxi_snapshot_operation. Just use the exist operator.\nGroup the data by the operations and you will get something like this. I can see there are 3 snapshots created but only two were removed. So one of the VM still has a snapshot.\nThe above shows the time too. In production, you should not take snapshot during busy hours, especially on mission critical VM. So if you run the query in the last 1 week, you should expect no data during the busy hours, and all the daily back up should appear within the backup window.\nYou can see the details such as the VM name and other context, so see which VM did not have its snapshot removed.\nYou can check the snapshot name (partially masked out in grey) and whether the snapshot include memory.\nTemplate Analysis How do you prove to auditor that your templates have not been modified by unauthorised person. If a template has been modified, you want to know who did it.\nThe good thing is there are only a few things you can change to a template. You can rename the template, change the permission, and convert it into a VM. All other changes require the template to be converted into a VM first. That means we can focus on this conversion.\nThe vCenter logs the entry as \u0026ldquo;mark virtual machine as template\u0026rdquo; when you convert a VM into a template. When it is converted back to, it writes \u0026ldquo;mark as virtual machine\u0026rdquo;. So it\u0026rsquo;s a matter of tracking these 2 entries.\nvSphere Health In general, you know that you did a good job with your vSphere IaaS as the VM owners are happy with the performance of their VMs. The business is powered by the VMware infrastructure that you design and operate. However, there is a chance that the vSphere logs bear evidence of hidden issues which are not visible from the UI.\nAs VMware professionals, we know vSphere well and probably have years of experience working with vSphere. We can architect, design, implement, upgrade, and troubleshoot it.\nThe same thing cannot be said about the logs. Generally speaking, deep knowledge of vSphere logs belongs to VMware GSS engineers, as they read logs on a daily basis, and perform all kinds of troubleshooting activities. That knowledge has been transitioned to Log Insight release after release in the form of a vSphere content pack.\nOne common question I get from customers is how to prove that there are not hidden warning lurking around in the log files. As you know, vSphere produces a lot of logs.\nYour first stop should be the General Problems dashboard in Log Insight. This dashboard checks the health of your vSphere using 8 queries. You expect a flying color, meaning it should be blank like this. That means vSphere has not logged any issues.\nLet\u0026rsquo;s look at some of the queries that Log Insight runs. The SCSI latency is based on 1 second, which is 1,000,000 microseconds. Here is what the query looks like:\n1 second is on the high side; you can change it to a lower number. Do note that this is from VMkernel viewpoint and it\u0026rsquo;s taking 1 SCSI operation (1 read or 1 write), so the number will be much higher than vCenter average. I\u0026rsquo;ve seen 12 ms value in vCenter (from the real time chart, so it is a 20 second average) became 600 ms. For details, see this.\nThe above query is pretty simple, as it\u0026rsquo;s looking for a specific item. Here is a much broader health check.\nThe example below checks for any errors in the vCenter which have not yet been reported as an alarm.\nThis query below checks for cluster imbalance.\nAnd this query tracks for VM which were rebooted due to HA.\nAll the above widgets are what you would check out first. You might also want to ensure that there are no errors across major vSphere components.\nVM Log File The file vmware.log contains detailed VM activity messages including reconfiguration events, vmotions, VMware tools messages, memory state, power on/off events, features enabled, API requests, etc. It can be used to troubleshoot events leading up to core dumps or kernel panics.\nFor more information, read this blog by Julie Roman.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-4---super-metrics/4.4.1-what-is-a-super-metric/",
      "title": "1. What Is a Super Metric?",
      "tags": [],
      "description": "",
      "content": "It is a programming language with mathematical formula that contains a combination of one or more metrics for one or more objects. Once you create a super metric, it persists over time and can be used for different interactions just like any other metric. It can be used in views, reports, dashboards and symptom definitions.\nSuper metrics are created with a list of operators and functions. These can be further combined and operated using several conditional expressions like \u0026lsquo;where\u0026rsquo; or \u0026lsquo;if-else\u0026rsquo;.\nOver the last few releases, there have been several enhancements focused on creating and working on super metrics more easily. With autocomplete in the new editor starting in vRealize Operations 7.5, you simply start typing an object name or object type, and the Super Metric Editor will pop up a list of options that match. You can keep typing to refine the list and then use Enter key to select and finalize the super metric formula.\nSupermetrics calculate the present value. You can’t compare against historical data.\nBefore starting to create a super metric, make sure you identify the following:\nObjects or object types that are involved Metrics which will need to be used. How to combine the metrics? Which operator, function or expression to use? Which object type will be used to assign super metric? Policy in which super metric will need to be enabled "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-3---sddc-vs-iaas/4.3.1-vm-it-is-not-what-you-think/",
      "title": "1. VM, it is not what you think!",
      "tags": [],
      "description": "",
      "content": "In this chapter, we will dive into why seemingly simple technology, an X86 machine virtualized, has a large ramification for the IT industry. In fact, it is turning a lot of things upside down and breaking down silos that have existed for decades in large IT organizations. We will cover the following topics:\nWhy virtualization is not what we think it is\nVirtualization vs Partitioning\nA comparison between a physical server and a virtual machine\nJourney into the Virtual World It is the era of the cloud. Who does not know what a VM is? Even a business user who has never seen one knows what it is. It is just a physical server, virtualized. Nothing more.\nWise men say that small leaks sink the ship. We think that\u0026rsquo;s a good way to explain why IT departments who manage physical servers well struggle when the same servers were virtualized.\nWe can also use Pareto principle (80/20) rule. 80% of a VM is identical to physical server. But it\u0026rsquo;s the 20% differences that hit you. We will highlight some of this \u0026ldquo;20% portion\u0026rdquo;, focusing on areas that impact data center management.\nThe change caused by virtualization is much larger than the changes brought forward by previous technologies. In the past two or more decades, we transitioned from mainframes to the client/server-based model to the web-based model. These are commonly agreed upon as the main evolutions in IT architecture. However, all of these are just technological changes. It changes the architecture, yes, but it does not change the operation in a fundamental way. Both the client-server and web shifts did not talk about the \u0026ldquo;journey\u0026rdquo;. There was no journey to the client-server based model. However, with virtualization, we talk about the virtualization journey. It is a journey because the changes are massive and involve a lot of people. That\u0026rsquo;s why the evolution toward multi-cloud operations is also called a journey.\nGartner correctly predicted the impact of virtualization in 2007. More than 1 decade later we still have not completed the journey. Proving how pervasive the change is, here is the following summary on the article1 from Gartner:\nNotice how Gartner talks about change in culture. So, virtualization has a cultural impact too. In fact, if your virtualization journey is not fast enough, look at your organization\u0026rsquo;s structure and culture. Have you broken the silos? Do you empower your people to take risk and do things that have never been done before? Are you willing to flatten the organization chart?\nThe siloes that have served you well is likely your #1 barrier to multi-cloud.\nSo why exactly is virtualization causing such a fundamental shift? To understand this, we need to go back to the basics, which is what exactly virtualization is. It\u0026rsquo;s pretty common that senior IT management have a misconception about what this actually is.\nTake a look at the following comments. Have you seen them in your organization?\n\u0026ldquo;VM is just Physical Machine virtualized. Even VMware said the Guest OS is not aware it\u0026rsquo;s virtualized and it does not run differently.\u0026rdquo; \u0026ldquo;It is still about monitoring CPU, RAM, Disk, Network. No difference.\u0026rdquo; \u0026ldquo;It is a technology change. Our management process does not have to change.\u0026rdquo; \u0026ldquo;All of these VMs must still feed into our main Enterprise IT Management system. This is how we have run our business for decades and it works.\u0026rdquo; If only life was that simple, we would all be 100 percent virtualized and have no headaches! Virtualization has been around for decades, and yet most organizations have not mastered it. The proof of mastering if you have completed the journey and have reached the highest level of virtualization maturity model.\nAlthough virtualization looks similar on the cover to a physical world, it is completely re-architected under the hood.\nVirtual Machine vs Physical Machine VM is not just a physical server virtualized. Yes, there is a P2V process. However, once it is virtualized, it takes on a new shape. That shape has many new and changed properties, and some old properties are no longer applicable or available. The following is an old screenshot, taken years ago. Can you spot properties that do not exist in physical server?\nLet\u0026rsquo;s highlight some of the properties that do not exist in a physical server. I\u0026rsquo;ll focus on those properties that have an impact on management, as management is the topic of this book.\nProperties Physical Server VM BIOS A unique BIOS for every brand and model. Even the same model (for example, HP DL 380 Generation 9) can have multiple versions of BIOS. BIOS needs updates and management, often with physical access to a data center. This requires downtime. This is standardized in a VM. There is only one type, which is the VMware motherboard. This is independent from the ESXi motherboard. VM BIOS needs far less updates and management. The inventory management system no longer needs the BIOS management module. Virtual Hardware Not applicable This is a new layer below BIOS. It needs an update on every vSphere release. A data center management system needs to be aware of this as it requires a deep knowledge of vSphere. For example, to upgrade the Virtual Hardware, the VM has to be in the power-off stage. Drivers Many drivers are loaded and bundled with the OS. Often, you need to get from respective hardware vendors for the latest drivers. All these drivers need to be managed. This can be complex operation, as they vary from model to model and brand to brand. The management tool has rich functionalities, such as checking compatibility, rolling out drivers, rolling back if there is an issue, and so on. Relatively fewer drivers are loaded with the Guest OS; some drivers are replaced by the ones provided by VMware Tools. Even with NPIV, the VM does not need the FC HBA driver. VMware Tools needs to be managed, with vCenter being the most common management tool. With all the above differences, how does it impact the hardware upgrade process?\nPhysical Server VM Downtime required. It is done offline and is complex. OS reinstallation and updates are required, hence it is a complex project in the physical world. Sometimes, a hardware upgrade is not even possible without upgrading the application. It is done online and is simple. Virtualization decouples the application from hardware dependency. A VM can be upgraded from a 5-year-old hardware to a new one, moving from the local SCSI disk to 10 Gb FCoE, from dual core to a 18-core CPU. So yes, MS-DOS can run on 10 Gb Ethernet accessing SSD storage via the PCIe lane. You just need to perform vMotion to the new hardware. As a result, the operation is drastically simplified. In the preceding table, we compared the core properties of a physical server with a VM. Every server needs storage, so let\u0026rsquo;s compare the storage properties.\nPhysical Server VM For servers connected to SAN, they can see the SAN and FC fabric. They need HBA drivers and have FC PCI cards, and have multipathing software installed. Normally needs an advanced filesystem or volume manager to RAID local disk. No VM is connected to FC fabric or the SAN. VM only sees the local disk. Even with N_Port ID Virtualization (NPIV) and physical Raw Device Mapping (RDM), the VM does not send FC frames. Multipathing is provided by vSphere, transparent to VM. There is no need for RAID local disk. It is one virtual disk, not two. Availability is provided at the hardware layer. Backup agent and backup LAN needed in the majority of cases. Not needed in the majority of cases, as backup is done via vSphere VADP API. Agent is only required for application-level backup. Big difference in storage. How about Network and Security?\nIn vSphere, a VM is connected to a distributed virtual switch. It is not directly connected to the physical NIC in your ESXi host. The ESXi host\u0026rsquo;s physical NICs become the virtual switch\u0026rsquo;s uplinks instead. This means that the traditional top-of-rack (TOR) switch has been entirely virtualized. It runs completely as software. This means the management software needs to understand the distributed vSwitch and its features.\nPhysical Server VM NIC teaming is common. Typically needs two cables per server. NIC teaming provided by ESXi. VM is not aware and only sees one vNIC. Guest OS is VLAN aware. It is configured inside the OS. Moving VLAN requires reconfiguration. VLAN is generally provided by vSphere, and not done inside the Guest OS. This means VM can be moved from one VLAN to another with no downtime. With network virtualization, VM is moving from VLAN to VXLAN. The AV agent is installed on Guest, and can be seen by the attacker. An AV agent runs on the ESXi host as a VM (one per ESXi). It cannot be seen by the attacker from inside the Guest OS. AV consumes OS resources. AV signature updates cause high storage throughput. AV consumes minimal Guest OS resources as it is offloaded to the ESXi Agent VM. AV signature updates do not require high IOPS inside the Guest OS. The total IOPS is also lower at the ESXi host level as it is not done per VM. Lastly, let\u0026rsquo;s take a look at the impact on management. As can be seen next, even the way we manage a server changes once it is converted into a VMs\nProperties Physical Server VM Approach on Monitoring An agent is commonly deployed. It is typical for a server to have multiple agents. In-Guest counters are accurate as the OS can see the physical hardware. A physical server has an average of 5 percent CPU utilization due to the multicore chip. As a result, there is no need to monitor it closely. An agent is typically not deployed. Certain areas such as application and Guest OS monitoring are still best served by an agent. The key in-Guest counters are not accurate as Guest OS does not see the physical hardware. A VM has an average of 50 percent CPU utilization as it is right sized. This is 10 times higher when compared with a physical server. As a result, there is a need to monitor closely, especially when physical resources are oversubscribed. Capacity management becomes a discipline in itself. Approach on Availability HA is provided by \u0026ldquo;clusterware\u0026rdquo; such as Microsoft Windows Server Failover Clusters (WSFC) and Veritas Cluster Server (VCS). Clusterware tends to be complex and expensive. Cloning a physical server is a complex task and requires the boot drive to be on the SAN or LAN, which is not typical. Snapshot is rarely done, due to cost and complexity. We find only very large IT departments practice physical server snapshot. HA is a built-in core component of vSphere. From what we see, most clustered physical servers end up as just a single VM as vSphere HA is good enough. Cloning can be done easily. It can even be done live. The drawback is that the clone becomes a new area of management. Snapshot can be done easily. In fact, this is done every time as part of backup process. Snapshot also becomes a new area of management as they tend to be forgotten. Company Asset The physical server is a company asset and it has book value in the accounting system. It needs proper asset management as components vary among servers. Here, the annual stock-take process is required. VM is not an asset as it has no accounting value. A VM is like a document. It is technically a folder with files in it. Stock-take process is no longer required as the VM cannot exist outside vSphere. The link from Gartner no longer works, so I guess you gotta trust me now.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-2---operational-maturity/4.2.1-gap-analysis/",
      "title": "1. Gap Analysis",
      "tags": [],
      "description": "",
      "content": "For each issue/question below, the ideal answer is provided in light grey so you know what it should be. Replace it with your own so the gap can be addressed.\nPerformance Business Question Ideal Answer Do your business units (your customers) blame the infrastructure first? If yes, why? Business Units (Apps Team) do not blame us because there is transparency on how each of their VM is being served. Is that because you have not defined the performance they can expect? There is a formal SLA on both Performance and Availability, which is applied to each VM based on the class of service they buy. Both SLA are clearly defined and measured every 5 minutes. For Performance SLA, we check CPU, RAM, Disk and network. How do you know when your IaaS is not serving the VM well? Do you depend on complaint to know if your IaaS isn\u0026rsquo;t performing? Our operations do not depend on complain. SLA enables us to be proactive and provide early warning to CIO. We track the threshold and act before complaint is made. How can you move toward proactive operations? What metrics do you use to measure IaaS performance? Does Help Desk provide a good first level defense? Or does it simply pass through to the next level? Help Desk uses the SLA, with a custom dashboard given to them. They encourage App Team to self-service as the same dashboard is provided. Our operations is VM-centric and application-centric, even though we are the infrastructure team. Capacity / Hardware Justification Business Question Ideal Answer Can you justify new infrastructure when utilization is not yet high? This is not referring to additional money that comes with a new project, this is referring to existing clusters/storage. Yes. We maximize utilization without compromising performance. Performance is at the heart of our capacity management. We also consider concentration risk, and do not exceed the limit set in business continuity policy. It takes time to buy hardware. Do you have an early warning in place? Other than utilization, what other metrics do you consider? As it takes time to buy hardware, Performance SLA breach serves as early warning as they happen before VM Owner complains. VM Right-Sizing Business Question Ideal Answer Do you have many over-provisioned VMs? Do you know how much to reclaim, and from which VMs? No. We do not interfere with application team business. They are paying for each vCPU, vRAM and vDisk. Are the VM Owners convinced on your recommendation? If not, why? There is progressive pricing and a discount for a small VM. These 2 factors make larger VMs much more expensive, hence encouraging right sizing right from the start. If an LOB wants to waste their money, that\u0026rsquo;s certainly their right. We do highlight how much they can save if they right-size How do you right-size without impacting performance? We may advise, but never dictate VM size, as it all depends on the applications. Configuration Business Question Ideal Answer Do you know who changed what in your infrastructure? Does the Auditor ask for such information? Yes. We mine vCenter logs, tasks and events. We provide the Auditor with a custom portal using Log Insight. Do you need to implement the vSphere Hardening Guide? Yes. We implement the vSphere Hardening Guide. The compliance dashboard is made available for customers to see, demonstrating transparency in our IaaS platform. Do you have to comply with industry specific security (e.g. PCI DSS, HIPAA)? Troubleshooting Business Question Ideal Answer On issue that spans multiple team, do you use a set of common tools to perform joint analysis? Or each team use their own, working in silo? Yes. The Storage and Network teams have custom access to both vCenter and vRealize. For vRealize Operations and Log Insight, we created custom dashboards so they are not overwhelmed with unnecessary information. Does Network Team and Storage Team have good visibility into the VMware environment? Do you have good visibility into Network and Storage? Yes. Storage, Network, and Compute have access to one another\u0026rsquo;s tools. We use the True Visibility Suite to correlate with Network and Storage, so everyone is looking at the same information. As part of Root Cause Analysis, do you setup alert so issue can be detected faster if it happens again? Yes. Alerts are mandatory as exit criteria in RCA. Availability Business Question Ideal Answer Guest OS Availability differs from VM Availability and Infra Availability. How do you report Guest OS Availability for each VM? We use VMware Tools for heartbeat. If Tools are not reporting, we check for signs of life (e.g. disk and network activity) What is your Availability SLA for Guest OS? How often is this tracked? We deliver 99.99% per month for each Tier 1 VM, tracked every 5 minutes. We do not track lower tiers as developers may reboot their VMs. Application Business Question Ideal Answer Do you have visibility into what applications are running on each VMs? To some extent, as our policy is not to install agents on each VM. Agents create maintenance, and at times interferes with VM performance. We use network analysis to detect common applications. Can you map the Business Units and their Applications into each VM in vSphere? Can you report performance by applications? Yes, we can. We organize our vCenter folders to reflect the BU, applications and tiers within the apps. Business Management Business Question Ideal Answer Is your chargeback or billing operationalized? Do your customers see your billing model as fair \u0026amp; competitive? Yes. Our pricing model is much simpler than AWS/Azure pricing. The model is simpler, and we have less choice versus public cloud. Can you justify the pricing of each service tier to your customers? How does it compare with the public cloud? We publish the comparison for our internal customers to see. Do you have challenges ensuring predictable billing for your cloud? We bill by allocation (what is configured to each VM), not by actual utilization. This is in-line with AWS billing model. This helps to make billing more predictable. Coupled with annual billing, we can predict revenue and plan our break-even accordingly. Public Cloud Business Question Ideal Answer Does App Team use AWS/Azure, bypassing IT? Why? As Enterprise IT, we are in the business of being a multi-cloud broker. We have both our on-prem cloud, and public cloud (VMware on Amazon, Azure and Amazon). Is your IaaS cheaper and better than public cloud, especially VMware on AWS? If yes, quantify it. Our on-prem is 25% cheaper than VMware on AWS and 40% cheaper than Amazon. This is in-line with other industry, where owning is cheaper than renting. If you use public cloud, do you know when VMs are not performing? If yes, what metrics do you track since AWS/Azure has limited metrics? AWS and Azure do not provide visibility on how our VM compete with other VMs. This prevents applications from making the right scaling decision. Network Operations Center (NOC) Business Question Ideal Answer Do you have a set of big screen dashboards that provides live information into the environment? Yes. We rotate a few screens showing critical information such as Availability, Performance, Security (compliance), Capacity. What information is provided? How useful is the information? We look at Applications, VMs and IaaS. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-1---quiz-answers/4.1.1-part-1-operations-management/",
      "title": "1. Part 1 - Operations Management",
      "tags": [],
      "description": "",
      "content": "Performance SLA You should exclude CPU Co-Stop from Performance SLA because the reason for CoStop could be the VM itself. IaaS SLA should not measure problems beyond your control. Read this for details.\nYou should exclude CPU Contention from Performance SLA because its value can go as high as 37.5% without the application noticing any degradation. You can login to Windows or Linux and feel it\u0026rsquo;s responsive. Read this for details.\n\u0026ldquo;Good\u0026rdquo; Advice The problem with the advice is it assumes utilization as the metric for performance. You want to drive by contention, while aiming to maximize utilization.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-9---other-dashboards/3.9.1-green-operations/",
      "title": "1. Green Operations",
      "tags": [],
      "description": "",
      "content": "Customer\u0026rsquo;s requirements to VMware can largely be classified into 2 timeline:\nPast What has been achieved. Demonstrates their savings and achievement to date. They want both the relative comparison and absolute value. The relative is show case they leading their peers in the industry, and performs better than public cloud. The absolute shows the hard numbers on their green impact to the environment. Future What can be achieved Find and realize future potential environmental benefits by optimizing their virtual environment and virtualizing their remaining physical environment. Optimization covers a wide range of wastage and efficiency, such as zombie VM and EC2, oversized datastores, and islands of clusters. Virtualizing is not limited to server, but include storage, back up, security, network, and non x86 workload. To implement the above requirements, we need to see 3 aspects of Sustainable Operations:\nClean Demand This means genuine demand, required by either business or IT. Opportunity to clean up the demand: Orphaned files, VMDK, VM, LUN. They may not even appear in the inventory. Powered off VM. Not orphaned as it appears in Inventory. Snapshot, both at VM level and storage level. Idle VM. Cover AWS EC2, Azure VM, GCP VM. Unused VM (cover AWS EC2, Azure VM, GCP VM). They may not be idle, but no business usage anymore. The VM owner may have left the company Unused AWS storage files or K8 shared volume. The VM no longer uses them. Oversized VM. Cover AWS EC2, Azure VM, GCP VM (could be worse due to their fixed size). Runaway VM or EC2. They consume excessive resource due, typically due to software bug such as memory leak or CPU lock Unmap files at storage level. Reduction of agents. While each agent maybe light in resource, collectively they can result in high overhead. Green Supply Hardware \u0026amp; Software infrastructure that is optimized Opportunity to optimize the supply Fibre Channel -\u0026gt; Ethernet consolidation. No need 2 separate network for storage and server. Physical Array -\u0026gt; vSAN migration. HCI consumes less power and DC footprint. Physical Network -\u0026gt; NSX migration. Physical FW, LB, etc Islands of hardware due to physical air gaps -\u0026gt; NSX Ageing hardware. Newer CPU has more cores and more power efficient Physical Desktop -\u0026gt; VDI with thin client. This also improves security. Incorrect power mgmt settings. Many customers like to set power management to Max, legacy of old best practice. Oversized cluster, datastore, storage arrays, physical switches, SAN fabric, network devices. Unused resource (physical servers, network devices, network ports). Old equipment are easily forgotten in large environment. Smaller DC footprint. Less land usage. Lean Operations Run with minimal overhead and buffer Opportunity to optimize the operations itself (process, people, tools) SLA-based Operations. Customers can go beyond the simple Availability SLA and introduce Performance SLA and Compliance SLA. Using the Class of Service feature, they provide differentiated services. Business-aware Operations. Using a proper inventory of VM, grouped by Business Units and Applications, customers can show how the business runs on the IaaS platform. On-Demand scaling. Some customers like GIC in Singapore implemented on-demand scaling for VDI. On the weekend it\u0026rsquo;s reset back to original size. Correct utilization counters. Current counters are legacy of Virtual Center 1.0, have not changed in 17 years. Virtualization has matured but we still use the highly conservative counters, resulting in excess hardware. By using the correct counters for the correct use case, customers can run higher utilization. Total Carbon Emissions footprint or CO2 Avoidance have become two important data center KPIs for all organisations of all sizes. vRealize Operations helps by providing the observability required to calculate and understand what an organisation\u0026rsquo;s CO2 footprint looks like when the power metrics of vSphere and SDDC objects monitored are calculated and visualised.\nvRealize Operations collects power consumption metrics (Energy in Joules and Power in Watts) for ESXi Host and VM objects. These metrics can be used to calculate power savings and CO2 emissions using super metrics.\nESXi has an extra metric called Cap. I\u0026rsquo;ve not seen it used, and how its impacts on performance is measured. If you know, let me know.\nEnergy Usage is the total consumption over a period of time. It\u0026rsquo;s expressed in Joule or Watt-hour, where 1 Wh = 3600 J. Using car analogy, think of it as distance covered in 1 hour.\nUsage is the rate. It\u0026rsquo;s the consumption at any given second. So if you consume 1 W non stop for 10 hour, you consume 10 Wh. If you consume 1 W non stop for 0.5 hour, you consume 0.5 Wh.\nTake note that Energy Usage is not carried forward to the next collection cycle. It gets reset to 0. So if you want to know the total power consumed in the last 1 hour (as the chart below covers 1 hour), you need to sum all the data points. You can\u0026rsquo;t take the average.\nFor Energy, you can take average, min and max of the data points. You don\u0026rsquo;t sum them up.\nCalculations for these dashboards are aimed to be conservative, hence your actual savings are likely to be more.\nWe are not including the following in the above savings calculation:\nPhysical buildings and land. With virtualization, you consume less footprint. This means less physical rack. Network equipment - Less physical servers mean less network ports. Because firewall, load balancers, IDS, IPS can be VM, you have less equipment. Other components like UPS, facilities, lighting, cooling and labour. Assumptions and references:\nPower consumption of a small server (1 socket, 10 cores, 32 GB RAM) = 0.1 KW CO2 emission per KWh = 0.6 Kg (from IEA Global Energy \u0026amp; CO2 Status Report 2019) Electricity cost = $0.106 per KWh (based on contiguous US average value, see VMware TCO Reference Calculator) Tree offset for CO2 Emission = 36.4 pound of carbon per tree (see United States Environmental Protection Agency report on Greenhouse Gases Equivalencies calculator) which is equivalent to 36.4 * 2.24 Kg of carbon per tree. Environment Savings This dashboard compares physical vs virtual workloads. Physical means every single VM would exist as a physical server, though much smaller than an ESXi Host, if they were not virtualized. While a small physical server draws a lot less power than ESXi, it adds up, especially over time. The dashboard compares power consumption of all the theoretical non-virtualized workloads with the actual power consumption of the ESXi hosts.\nThe calculations applied to the Sustainability supermetrics are detailed below and can all be modified as required through vRealize Operations under the respective calculations to reflect regional factors that are at different values for each customer environment (e.g. Power cost per KWh - set to 0.106 in this dashboard):\nPower Consumed before Virtualization = Number of VMs x 0.1 in KW Power Consumed after Virtualization = Power Consumed by all ESXi hosts in KW Monthly savings ($) = Power Savings in a month in KWh x 0.106 Carbon Emissions before Virtualization = Power consumed in KWh before Virtualization x 0.744 Kg Carbon Emissions after Virtualization = Power consumed in KWh after Virtualization x 0.744 Kg Environmental Impact The Dashboard identifies the Idle VMs and Power savings that could be achieved by reclaiming them. It also provides their associated CO2 emissions. While each VM may only consume a small amount of power, collectively the impact starts to add up. Additionally, this dashboard displays the idle VMs per cluster, so you can see where your inefficiencies lie within each cluster.\nIdle workloads (VMs) are quantified here with the potential power savings that could be achieved by decommissioning the workloads. The dashboard also provides CO2 emissions amount calculated from this group of VMs. While each VM only consumes a tiny amount of power (approximately 0.x - 2 Watts), collectively and over time they can add up depending on how efficiently you have been right-sizing your environment on a regular basis. Additionally, the cluster view helps to aggregate the number of idle VMs per cluster, so identifying which clusters have a lot of Idle VMs is easier. Finally, by leveraging published EPA multipliers, your are able to calculate using super metric, the number of trees to plant that can help compensate CO2 emissions from these idle VMs.\nCO2 emission from Idle VMs = Power Consumed by Idle VMs x 0.744 Kg.\nTrees required to compensate CO2 emission due to Idle VMs = CO2 emission from Idle VMs (Kg) / (36.4 x 2.22)\nGreen Data Center Dashboard The Green Data Center view represents a comparison of what the CO2 emissions footprint would be calculated if every VM in the environment was a physical server (based on average industry values for server power usage in KWh). A total tally of the physical server count and total power usage is reflected on the left representing the negative impact on Sustainability goals.\nThen the center column of views represents the total amount of CO2 avoidance and power savings achieved with VMware virtualisation having consolidated this total number of physical workloads into VMs. This reflects a KPI for businesses to highlight on this executive view.\nLastly, the views on the right represent a current state view of the inventory virtualised with trends and a heatmap to help identify clusters that potential targets for further consolidation and efficiency.\nIdentify Green Options to Run Workload Dashboard This dashboard is designed to be an interactive way to allow users to identify which VM\u0026rsquo;s, ESXi hosts and Compute Clusters are consuming the most power (Watts). The Geographical dashboard view allows representation of the various Green Data Center objects based on their \u0026ldquo;green score\u0026rdquo; KPI. ESXi hosts that are tagged by host hardware model details identified from object native metrics are also categorised on the bottom to help identify and compare power efficiencies for all hardware models in use.\nAdditional configuration will be required after importing the dashboard package to assign geographical tag against the ESXi hosts and editing their respective vendor model details. Refer to the import instructions for additional detail.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-8---true-visibility-suite-dashboards/3.8.1-microsoft-sql-server/",
      "title": "1. Microsoft SQL Server",
      "tags": [],
      "description": "",
      "content": "The Microsoft SQL (MS SQL) Server summary dashboard is generally used by Database Administration (DBA) teams. They use it to explore problematic MS SQL Instances.\nThis is a custom dashboard. You can download it here on VMware {code}.\nDesign Consideration The MS SQL Server Summary was designed to allow the user to select a MS SQL Instance, then be shown all child objects, their health, and metrics that could reflect problems. Once the MS SQL Instance is selected the user immediately sees Key Performance Indicators (KPIs) in the widgets below. The two Views in the sixth row of widgets have \u0026ldquo;Auto Select First Row\u0026rdquo; turned on, such that their respective Scoreboards are populated with data upon selection.\nThe design is simple, clean, and efficient, allowing DBAs to search for a database instance and work their way into the details. It\u0026rsquo;s designed to flow from top to bottom and left to right, which is reflected by the widget interaction canvas.\nHow to Use Select a MS SQL Instance in the top View widget by single clicking it, which will populate all other widgets. We\u0026rsquo;ll explore the first five rows of the dashboard first, the Instance and its metrics.\nThe MS SQL Server Instance View offers several sortable columns, the first and most relevant being Health. vRealize Operations Health is based on Alerts and severity of those Alerts, a powerful construct used to gauge general well-being of objects. The View has been built such that unhealthy Instances are shown in red, while healthy instances are shown in green, helping the user to immediately identify problems.\nSQL Version, CPU Usage, Memory Usage, Buffer Cache Hit Ratio, and several other KPIs are also shown in the top View. These provide the user with some context around a potentially unhealthy Instance. These columns are also sortable, giving the user the ability to see the most active Instances.\nOnce an Instance has been identified and chosen, the four rows of Scoreboard widgets are populated with historical data. These Scoreboards have been configured to show Instance metrics by group: Buffer, Performance, Disk, Lock, Memory, Process, Query, and Statements.\nThey have been configured to show four metrics each, including the most current value and historical data using Dashboard Time. That is, the timeframe you select for your dashboard will be propagated into these widgets. This provides the user with some texture when troubleshooting a problem. They can now see when metrics values started changing and if there is any correlation between them.\nAs you hover over KPIs, the dashboard will show you details about it (name and value) and give you the option to double click to explore the trend of that particular metric via a Metric Chart.\nDouble clicking launches this metric in a Metric Chart, giving the user even more options.\nThe user now has the ability to use all of the Metric Chart Features: Show Dynamic Thresholds, Anomalies, Trend Lines, and the ability to adjust the period of time. They can take snapshots to share with others, create alert definitions against the selected metric, or download the data being shown in a comma separated format.\nMoving to the bottom half of the dashboard, we see two child objects of the selected Instance: Databases and Queries. Jobs and Wait Types are also available child objects but aren\u0026rsquo;t quite as rich with metrics as Databases and Queries. The scoreboard widgets are driven from the Views and show object KPIs. At the bottom of the dashboard is an Object Relationship showing the original MS SQL Instance and all its children.\nStarting with the row of Views, we see two important child objects of our selected Instance, namely Databases and Queries. I\u0026rsquo;ve included navigation information in each widgets title so the user knows exactly what\u0026rsquo;s driving each View. I\u0026rsquo;ve included Health and a couple other KPIs for each object.\nUsing Views allowed me make 100% green and 25% or less Red. I\u0026rsquo;ve done something similar for Database Status and Job Last Run Status, to bring the users attention to OFFLINE/Failed statuses. All columns are sortable, giving the user the ability to see the least healthy object immediately.\nAuto Select First Row has been turned on such that the Scoreboard widgets are populated with data. All of the same Scoreboard features are available here as they were above.\nThe last widget in this dashboard is the Object Relationship, which is being driven from the original MS SQL Instance. It has been configured to show parents and children, and the health of each, represented by the green squares (healthy), yellow triangles (marginally healthy), or red circles (unhealthy). If an object doesn\u0026rsquo;t have any alerts against it, that doesn\u0026rsquo;t mean it\u0026rsquo;s necessarily healthy, but it does mean no Alert/Symptom combinations are active against it.\nIf you hover over an object, you are given some details: Type and Health. The user is also given an option to select Alerts or Details. If you double click the object the widget will re-center on that particular object, showing its parent and child objects. This can be quite useful during troubleshooting.\nSelecting Alerts will show you any Active Alerts for that object. Selecting Details will take you to the Summary page for that object, in this case the MS SQL Database Summary. Another way to see relationships from the original MS SQL Instance is to explore them via the object Summary page.\nThe object in the middle is our original MS SQL Instance. The objects below it from left to right are its child objects: Databases, Queries, Jobs, and Wait Types. Objects above the MS SQL Instance are the parent objects, including the vSphere VM the Instance is sitting on. vRTVS documentation for these relationships can be found here.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-7---executive-summary-dashboards/3.7.1-design-considerations/",
      "title": "1. Design Considerations",
      "tags": [],
      "description": "",
      "content": "CIO, Head of Global Infrastructure, and other IT Senior Management have a different requirement than technical folks. Generally they want the big picture, not details. Or at the very least, the big picture is presented first, and then drill down is provided.\nAs part of showing the big picture, trend should be included. Show the situation in the last few months, ideally coupled with projection. The data should be averaged out, so that a 5-minute spike should not show up.\nException. Things that they need their attention. Complete means nothing else can be taken out. Which information, object, metric can you take out from the dashboard? No technical info. Ideally, present in business terms, not IT jargons. Terminology such as datastore, distributed switch may need to be replaced with something suitable in your organization.\nUI that is easy to understand. So keep each dashboard to a specific question. Make sure the dashboard is easy to use. So keep the interaction, clicking, zooming, sorting, etc. minimal.\nCan the dashboard be understood within 5 seconds?\nIf yes, you buy yourself a few more minutes. Your IT Management has understood what the dashboard does, and is willing to spend more time appreciating its full capabilities.\nTake note of the \u0026ldquo;size\u0026rdquo; of your dashboard.\nKISS. Keep it simple solution. Keep the interaction, clicking, zooming, sorting, etc. minimal. Use larger fonts, round numbers (law of significant number)\nIf they ask for a self-service portal, then make it easy to access. They may not want to login to vRealize Operations. If they do, they may forget their password, so the portal should not require a password.\nThat\u0026rsquo;s what they want from you. You also need to think of what you want from them.\nYou also want to show them problems that you can get help, which is budget and resource. You do this by showing data. By giving visibility into live environment to senior management, you prove that you do need additional hardware. If there is wastage to be reclaim, you also prove on where and how large the wastage is.\nvRealize Operations provide two example dashboards to get you started. They are designed for you to present live information to your senior management. They are not designed as self service.\nAs each executive may have a unique requirements and preferences, customize the dashboard accordingly.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-6---noc-dashboards/3.6.1-design-considerations/",
      "title": "1. Design Considerations",
      "tags": [],
      "description": "",
      "content": "A dashboard projected on the large screen serves a different business purpose than a dashboard on your laptop or desktop. It is placed strategically because it displays a time sensitive information. The information presented is more urgent in nature than alerts (otherwise you simply use alerts!) and is used to complement alerts.\nThese dashboards are specifically designed for your Network or Server Operations team, who are typically stationed at the NOC. Dashboards aid your operations team to proactively monitor the health \u0026amp; availability of the VMware cloud infrastructure in near real time. Due to the specific purpose of it, not all operational use cases are suitable for these. For example, Capacity and Cost use cases are not highly time critical. They tend to stay static for hours, rendering them unsuitable for live screen.\nThe following five principals are used to design the predefined Network Operation Center dashboards.\nColor Coded All the information is color coded to classify the severity of the issue.\nColor is easier to digest than text, as you don\u0026rsquo;t even need to read. Lots of text can confuse viewers. Text can be hard to read from afar. Use key colors (green, yellow, amber, and red). By default all green. Can\u0026rsquo;t have red staying for hours (use alerts for something less urgent) No interaction on the projected screen 0 interaction, because there is no mouse and keyboard. Toolbars \u0026amp; buttons should not be used as they add confusion as there is no way to use them. Most widgets are not suitable as a result. KISS - Keep It Simple Show These dashboards are designed to show you minimal \u0026amp; critical information only. It should follow the KISS principle. Don\u0026rsquo;t show detailed charts as that is hard to read from afar. Be aware of how far the info needs to be displayed. 9 point Calibri at laptop is clear, but not at the projector screen. Ideally, all the numbers are in %, with 0 being bad and 100 being perfect. In cases like Utilization, you should use the following marker. 50% = good, balanced utilization. Ideally, this should be 75%. 0% = wastage 100% = highly utilized. Remember the 5-second test All NOC dashboards should be easy to interpret, user friendly and do not require an explanation. Choose content that drives immediate Actions Focuses on immediate remediation. Remediation action has to be immediate (within the same hours). If something can\u0026rsquo;t be fixed within the same day, why show it live? Remediation that takes \u0026gt;1 day should not be shown, as the dashboard will be red for hours. It is better to use alerts for longer remediation window. If you display something that is red most of the time, after a while the viewer will ignore it. This defeats the very purpose of displaying on the big screen. When something on the big screen is red, you want action to be taken. And it\u0026rsquo;s immediate, not tomorrow. It\u0026rsquo;s showing 5 minute data. Live! The history not so relevant, because it focuses on urgent remediation. Problems that don\u0026rsquo;t require immediate attention should be avoided, as they are distraction. Examples of suitable actions: stop provisioning of new VM, take action on VMs that abuse the shared infrastructure. Examples of not suitable actions: Increase supply of infrastructure, such as adding hardware. Designed to be displayed on a big screen Configure them to auto-rotate in a logical flow. Each dashboard is designed to fit the screen \u0026amp; no scrolling is required. The above principle applies to the part of the dashboard that is projected on the big screen. You can dual-purpose the same dashboard, to cater for the operators in the NOC room. These help desk administrators should have the same dashboard on their desktop or laptop. They can then use keyboard and mouse to interact with the dashboard, enabling them to drill down and find out more information.\nvRealize Operations provides 3 sample dashboards in this release. Tailor them to your operational needs.\nAvailability is not part of them because there is no information to distinguish between planned downtime and outage. A planned downtime can last hours, making the NOC screen displaying red for too long. If you have a set of mission critical VMs or clusters that need to be up all the time, then create a group.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-5---availability-dashboards/3.5.1-vm-availability/",
      "title": "1. VM Availability",
      "tags": [],
      "description": "",
      "content": "Use the VM Availability dashboard to calculate the availability of the Guest OS. The availability of the Guest OS is calculated because the Guest OS might not be running even when the VM is powered on. There are two layers of Availability, that is, the Consumer layer and the Provider layer. This dashboard covers the Consumer layer. You can view VMs in the selected data center, uptime trend for a selected cluster, and so on.\nDesign Consideration The dashboard is designed to help check the availability (uptime in percentage) of VMs, as availability is typically a part of services provided by the IaaS provider.\nThis dashboard does not check the application up time. It is possible that the application (e.g. a database, web server) is down while the underlying Windows or Linus is up. Generally, the service provided by IaaS team is only until Windows or Linux. To check application level, use network ping or application specific agent (e.g. Telegraf)\nHow to Use Start in Data centers widget by selecting one of the data centers listed.\nIn small environment, or if you want to see overall, you click the vSphere World object. The above action will update other widgets automatically. Think of creating a filter for this table that reflect your class of service. Group by the class of services such as Gold, silver, and bronze and default the selection to Gold. In this way, the monitoring is not cluttered with less critical workloads, and you can focus on the important VMs. One way to achieve this is by creating a vRealize Operations custom group for each class of service About the VMs by Uptime in the last 30 days bar chart\nIt displays the average uptime of VMs grouped by their availability. The bucket distribution is designed to cater for a wide array of environment. If You are monitoring only production VMs, where uptime is expected to be near 100% all the time, edit the bucket to meet your operational need. About the VMs in the Selected Data center table\nIt lists all VMs currently deployed to the data center. Average Uptime is displayed for the last 1 month of data. Expect this number to be 100% or near there for production VM. Note that the Services column will be blank unless Service Discovery is enabled and services/processes were discovered on a specific VM. The column VMs includes all VMs including powered off VMs. Select a VM from the above table.\nThe remaining widgets will automatically show the detail of the selected VM. Selected VM Uptime Trend displays the selected VM\u0026rsquo;s Guest Tool Uptime (%) across the last 30 days. Expand the 2 collapsed widgets\nIf Guest OS services or processes are discovered inside a VM, their availability is analyzed. Service \u0026lsquo;state\u0026rsquo; over time is displayed in Guest OS: Services. The dashboard displays the process or services running inside the Guest OS. This requires the Service Discovery Management Pack. The ESXi Host where the VM has run widget can show historical migration of the VM. This can be useful in determining the cause of a VM downtime. Points to Note The metric is only tracking the availability of VMware Tools, not the entire Guest OS. If Tools is not up, it assumes the Guest OS is down. To help you check that this is not a false negative, add a few line charts that shows sign of life. A good counter is IO counters such as Disk IOPS, Disk Throughput and Network Transmit Throughput, because IO requires CPU processing. CPU Usage is not a reliable counter as work by VMkernel on the VM is charged to the CPU counters. vRealize Operations 8.2 sports a new ping adapter. This means you can enhance the accuracy of the uptime measurement by creating a super metric that adds the ping information or checking the process (needs an agent, such as Telegraf). Add a property widget that lists the selected VM properties to give you more context about the VM. In large environment, it is possible that the VM name alone may not be providing enough context. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.1-design-considerations/",
      "title": "1. Design Considerations",
      "tags": [],
      "description": "",
      "content": "Configuration Management dashboards share the same design principles. They show the configuration that needs attention first, before showing overall configuration. The idea is to drive action towards optimizing configuration.\nThe overall layout is designed to balance ease of use, performance (loading time of the dashboard page) and completeness of configuration check. As a result, not all configuration settings are shown. Lack of screen real estate is another consideration behind the design.\nIn some dashboards, there are simply too many configuration items to check than the screen real estate provides. If you have a larger screen, add the additional check as you deem fit, or add legends to the pie-charts. For a start, see the list of settings that you may want to check here.\nEmpty or Exist In configuration check, we can encounter a need to check for exception. This is where the Exist or Not Exist check and Empty and Not Empty check can come in handy.\nSome ideas are:\nCheck for standalone ESXi. It will have no parent cluster Check for missing Telegraf agent in critical VM Anything else? Let\u0026rsquo;s collaborate to enhance the configuration dashboards!\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/3.3.1-design-considerations/",
      "title": "1. Design Considerations",
      "tags": [],
      "description": "",
      "content": "Capacity Management dashboards share the same design principles. They are intentionally designed to be similar, as it will be confusing if each dashboard looks totally different from one another, considering they have the same objective.\nThe dashboard is designed \u0026ldquo;top down\u0026rdquo;. It has 2 sections: summary and detail.\nThe summary section is typically placed at the top of the dashboard. It gives the big picture. The detail section is placed below the summary section. It lets you drill down into a specific object. For example, if it\u0026rsquo;s a VM capacity, you can get the detail capacity of a specific VM. Not all objects lend themselves for capacity management. Take the data center object for example. It can contain clusters of different purpose, with different performance characteristic. It might not make sense to combine the metrics into a single data center Capacity (%) metric, if the member clusters are not interchangeable.\nThis section is designed with quick context switch, as you may want to check the capacity of multiple objects in the course of capacity analysis. Take for example VM capacity analysis. The dashboard gives you all the VM-specific information and allows you to see the capacity summaries without changing screens. You can move from one VM to another and view the details without opening multiple windows.\nUI wise, the dashboard uses progressive disclosure to minimize information overload and ensure the webpage loads fast. On the other hand, so long your browser session remains, it remembers your last selection.\nYou may notice that the performance dashboards and the capacity dashboards share similar layout. The reason is there is commonality in both pillars of operations.\nThe dashboard is design to complement the out of the box pages by visualizing information differently and giving more choice of customization. For examples, the reclamation size is grouped into buckets so you can focus on the largest reclamation opportunities first, and trend charts are provided so you can quickly see the growth over time, without changing context (e.g. open a new screen).\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.1-design-consideration/",
      "title": "1. Design Consideration",
      "tags": [],
      "description": "",
      "content": "Performance Management dashboards share the same design principles. They are intentionally designed to be similar, as it will be confusing if each dashboard looks totally different from one another, considering they have the same objective.\nThe first thing to check when a VM has a performance problem is if other VMs have the same problem. If the problem is widespread the root cause is not with the VM. Hence it\u0026rsquo;s important to see the big picture, before diving into a particular area in your SDDC.\nAt the infrastructure layer, we care whether it serves everyone well. Make sure that there is no contention for resource among all the VMs in the platform. Only when the infrastructure is clear from contention can we troubleshoot a particular VM. If the infrastructure is having a hard time serving majority of the VMs, there is no point troubleshooting a particular VM. Notice all the previous sentences are about the VM. Yes, the infrastructure counters are not that relevant.\nFor objects where there are many counters, I split the dashboard into 2: contention and utilization. This keeps the dashboard simple, while emphasizing the concept of contention as the primary counter for performance.\nThe dashboard is designed \u0026ldquo;top down\u0026rdquo;. It has 2 sections: summary and detail.\nThe summary section is typically placed at the top of the dashboard. It gives the big picture. The detail section is placed below the summary section. It lets you drill down into a specific object. For example, if it\u0026rsquo;s a VM performance, you can get the detail performance of a specific VM. This detail section is also designed with quick context switch, as you may want to check the performance of multiple objects during performance troubleshooting. Take for example VM performance. The dashboard gives you all the VM-specific information and allows you to see the KPIs without changing screens. You can move from one VM to another and view the details without opening multiple windows.\nUI wise, the dashboard uses progressive disclosure to minimize information overload and ensure the webpage loads fast. On the other hand, so long your browser session remains, it remembers your last selection.\nYou may notice that many of the performance dashboards and the capacity dashboards share similar layout. The reason is there is commonality in both pillars of operations.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.1-dashboard-alert-report/",
      "title": "1. Dashboard | Alert | Report",
      "tags": [],
      "description": "",
      "content": "It is easy to think that dashboards, alerts and reports are separate and should be designed independently. If we take a step back and look at the big picture, there is actually minimal overlap, as they form a continuum. They serve the same purpose, which is the way for System to \u0026ldquo;communicate\u0026rdquo; with user.\nIf you apply this thinking, you will vrealize that you can reduce alert storm, because many alerts are better served as parts of a dashboard. Reports will also become minimal and kept for personas with no online access and use cases where no interactivity is needed.\nThe nature of alert means its use case is very narrow. You do not want to run your operations based on alerts. Too many and you\u0026rsquo;re overwhelmed. Too few and you lack the big picture visibility. Alert is only applicable in the following situation:\nUrgent. If time is not an essence, then a regular SOP with dashboard is more effective as you can see the big picture. Avoid sending alerts to personas that do not deal with day to day operations. Long term actions such as capacity management is best served with dashboard. Problem. If there is nothing wrong, there is no need to trigger an alert. That\u0026rsquo;s why in general you do not set up an alert on inventory changes, as inventory is merely an account of something. Remediation. If there is nothing you can do immediately to address the issue, why trigger an alert? Use dashboard for such cases. Few. Alert focuses on exception, not the big picture. As a result, you want this to be minimal. If the whole house is on fire, it\u0026rsquo;s too late for an alert. At the other end of the spectrum lies Report. The nature of report means its use case is also very narrow. Modern operations require a richer interaction that report lacks. Report is only applicable in the following situation:\nNo interactivity (e.g. users needs it delivered to their email inbox) Offline (e.g. users are in a plane) No access to vRealize Printed document Time bound (e.g. calendar month) Further processing (e.g. integration with other systems that has data not in vRealize) Further analysis \u0026amp; reporting (e.g. Finance team wants the data as part of their spreadsheet report) Dashboards cover the broadest use cases as it\u0026rsquo;s the most versatile.\nThe following table details how the 3 ways of engaging are complementary.\nIf user has access to the online via their desktop, consider a self-service dashboard as they require no login and it\u0026rsquo;s much easier to use. You can develop a portal with links to these dashboards and custom guide.\nThe last few releases of vRealize Operations introduces many new capabilities that change the way your dashboards can look. vRealize Operations 8.2 sports an enhanced dashboard to dashboard navigation, so you can create flow among dashboards. Your dashboards are no longer confined to be standalone dashboard.\nVersion 8.2 ships with a revamped set of dashboards. They are kept simple and meant to be customized for your specific environment. The dashboards were refined in vRealize Operations 8.4.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-6---other-metrics/2.6.1-troubleshooting-metrics/",
      "title": "1. Troubleshooting Metrics",
      "tags": [],
      "description": "",
      "content": "vRealize Operations collects and stores data every 5 minutes. This is good enough for monitoring use case, but not for troubleshooting. 300-second average is not granular enough, as performance problem may not be sustained that long. Even a performance issue that last days may consist of repeated micro bursts. I check if repeated burst exist by profiling a few thousand VMs. Here are some of the results. I compare 3 metrics (disk latency, network throughput and CPU context switch).\nThe peak column is based on 20-second average. So it\u0026rsquo;s 15x sharper than the 300-second average. It gives better visibility into the micro burst. If the burst exists, you will see something like this, where the 20-second shows much worse value consistently.\nThis is where the 20-peak counters come in. vRealize Operations 8.3 sports a set of 12 metrics that captures the highest 20-second average in any given 5-minute period (the default collection interval).\nHow are they chosen? Take a look at the table below. It shows a VM with 2 virtual disks. Each disk has its own read latency and write latency, giving us a total of 4 counters.\nWhile vRealize Operations collects every 300 seconds, it actually grabs 15 data points. Why 15? Those 15 matches the 20-second that vCenter produces. Each 20-second data point is an average of the entire 20 seconds, not a point in time such as the 20th second. So all along, vRealize Operations actually has 20-second visibility. However, it averages these 15 data points, losing the 20-second granularity.\nWhat vRealize Operations 8.3 does is to add a new metric. It does not change the existing metric, because both have their own purpose. The 5-minute average is better for your SLA and performance guarantee claim. If you guarantee 10 ms disk latency for every single IOPS, you\u0026rsquo;d be hard pressed to deliver that service. These new counters act as early warning. It\u0026rsquo;s an internal threshold that you use to monitor if your 5-minute SLA is on the way to be breached.\nvRealize Operations 8.3 takes the peak of these 15 data points, and stores them every 5 minutes. It does not store all 15 data points, because that will create a lot more IOPS and consume more storage. It answers the question \u0026ldquo;Does the VM or Guest OS experience any performance problem in any 20-second period?\u0026rdquo;\nHaving all 20-second data points are more natural to us, as we\u0026rsquo;re used to 1 second in Windows and 20 second in vCenter performance charts. But how does that additional 14 data points change the end remediation action? If the action you take to troubleshoot is the same (e.g. adjust the VM size), why pay the price of storing 15x more data points?\nIf you need to store them all, vRealize Operations Cloud does it for you. Note that it\u0026rsquo;s limited to 7 days, while this technique lets you store for 6 months as it\u0026rsquo;s just like any other regular metric.\nIn the case of virtual disk (as opposed to say memory), a VM can have many of them. A database VM with 20 virtual disks will have 40 peak counters. That also means you need to check each one by one. So vRealize Operations 8.3 takes the peak among all virtual disks read and writes. It does the same thing with vCPU. A monster VM with 64 vCPU will only have 1 metric, but this metric is the highest among 64 virtual CPU. There is no need to have visibility into each vCPU as the remediation action is the same. Whether it\u0026rsquo;s vCPU 7 or vCPU 63 that has the problem, it does not change the conclusion of troubleshooting in most cases.\nWhat are the metrics? The next question is naturally why we picked the above 12. You notice they are only VM counters. No ESXi, Resource Pool, Datastore, Cluster, etc counters. The reason is the counters at these \u0026ldquo;higher-level\u0026rdquo; objects are mathematically an average of the VMs in the object. A datastore with 10 ms disk latency represents a normalized/weighted average of all the VMs in the datastore. Another word, these counters give less visibility than the 12 above, and they can be calculated from the 12. And 1 more reason:\nYou troubleshoot VM, not infrastructure. If there is no VM, there is no problem.\nAmong the 12 counters, you notice only 1 counter tracks utilization. The other 11 tracks contention. The reason is covered here.\nWhy are Guest OS level metrics provided? Because they do not have VM equivalent, and they change the course of troubleshooting. If you have high CPU run queue, you look inside Windows and Linux, not at the underlying ESXi Host as it\u0026rsquo;s transparent to the host.\nFor CPU, the complete set of contention is provided. There are 6 counters tracking the different type of contention or wait that CPU experiences.\nFor Memory, popular metrics such as Consumed, Active, Balloon, Swap, Compress, Granted, etc are not shown as they do not indicate performance problem. Memory Contention is the only counter tracking if the VM has memory problem. VM and Guest OS can have memory problem independently. In future, we should add Guest OS memory performance counters, if we find a good one. Linux and Windows do not track memory latency, only track memory disk space consumption, throughput and IOPS. These 2 OSes do not track latency, which unfortunately is the main counter for performance.\nFor Network, vCenter does not have latency and re-transmit. It has dropped packet, but unfortunately this is subject to false positive. So we have to resort to utilization metric. In future, we should add packets per second.\nThe following screenshot shows the actual name of the 12 metrics in vRealize Operations 8.4.\nLastly, just in case you ask why we do not cover Availability (e.g. something goes down), it\u0026rsquo;s because this is better covered by events from Log Insight.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-5---network-metrics/2.5.1-why-network-monitoring-is-unique/",
      "title": "1. Why Network Monitoring Is Unique",
      "tags": [],
      "description": "",
      "content": "From performance and capacity management point of view, network has different fundamental characteristics to compute or storage. The key differences are summarized below.\nCompute or Storage Network Net available resource to VM Relatively high Low Resource allocation at VM level Granular Coarse Hardware Single purpose Multi-purpose Nature A node An interconnect Upper Limit Yes No Monitoring Simpler Harder Let\u0026rsquo;s explain the above in more detail, starting from the first difference.\nAt the end of the day, the net available resources to the VMs arewhat we care about. What the IaaS platform used is considered an overhead. The more ESXi VMkernel, NSX, vSAN, vSphere Replication use, the lesser you have left for the business workload.\nAn ESXi host has a fixed specification (for example, 2 CPUs, 36 cores, 256 GB RAM, 2 x 10 GE NIC). This means we know the upper physical limit. How much of that it available to the VMs? Another word, what is the usable capacity for the business workload?\nFor compute, the hypervisor consumes a relatively low proportion of resources. Even if you add a software-defined storage such as Virtual SAN, you are looking at around 10% total utilization but depends on many factors. The same cannot be said about network. Mass vMotion (for example, when the host enters maintenance mode), storage vMotion (in IP storage case), VM provisioning or cloning (for IP storage), and Virtual SAN all take up significant network bandwidth. In fact, the non-VM network takes up the majority of the ESXi resources. If you have 2 x 10 GE NIC, majority of it is not used by VM. The following screenshot shows that VM only gets 100 shares out of 500 shares. So the overhead can be as high as 80%! The second difference with network is the resource that is given to a single VM itself.\nFor compute, we can configure a granular size of CPU and RAM. For the CPU, we can assign one, two, three, four, etc. vCPUs. With network, we cannot specify the vNIC speed. It takes the speed of the ESXi vmnic assigned to the VM port group. So each VM will either see 1 GE or 10 GE or 25 GE (you need to have the right vNIC driver, obviously). You cannot allocate another amount, such as 500 Mbps or 250 Mbps in the Guest OS. In the physical world, we tend to assume that each server has 10 GE and the network has sufficient bandwidth. You cannot assume this in a virtual data center as you no longer have 10 GE for every VM at the physical level. It is shared and typically oversubscribed. A network intensive VM can easily hit 1 Gbps for both egress and ingress traffic. The following chart shows a Hadoop worker node receiving more than 5 Gbps worth traffic multiple times. You need to be careful in sizing the underlying ESXi if you want to run multiple VMs. While you can use Network I/O Control and vSphere Traffic Shaping, they are not configuration property of a VM. The third difference is that the hardware itself can provide different functionalities.\nFor compute, you have servers. While they may have different form factors or specifications, they all serve the same purpose-to provide processing power and a set of working memory for hypervisor or VM. For network, you have a variety of network services (firewall and load balancer) in addition to the basic network functionalities (switch, router, and gateway). You need to monitor all of them to get a complete picture. These functionalities can take the form of software or hardware. The fourth difference is the nature of network.\nCompute and storage are nodes. When you have a CPU or RAM performance issue on one host, it doesn\u0026rsquo;t typically impact another host on a different cluster. The same thing happens with storage. When a physical array has a performance issue, generally speaking it does not impact other arrays in the data center. Network is different. A local performance issue can easily be a data center-wide problem. Here is a good read by shared Ivan Pepelnjak. The fifth difference is the upper limit.\nDetermining CPU or RAM workload is easy: there is a physical limit. This makes capacity management possible, and aids in performance troubleshooting. While network has a physical limit, it can be misleading to assume it is available to all VMs all the time. Because the physical capacity of the network is shared, you have a dynamic upper limit for each workload. The VM Network port group will have more bandwidth when there is no vMotion happening. Furthermore, each VM has a dynamic upper limit as it shares the VM Network port group with other VMs. The resource available to VM also varies from host to host. Within the same host, the limit changes as time progresses. Unlike Storage I/O Control, Network I/O Control does not provide any counters that tell you that it has capped the bandwidth. In many situations, the bandwidth within the ESXi host may not be the smallest pipe between the originating VM and its destination. Within the data center, there could be firewalls, load balancers, routers, and other hops that the packet has to go through. Once it leaves the data center, the WAN and Internet are likely to be a bottleneck. This dynamic nature means every VM has its own practical limit. The sixth difference is monitoring and troubleshooting\nA distributed system is harder to monitor than a single node, especially if workload varies among the components that make up the system. The network resource available to VM also varies from host to host. Within the same host, the limit changes as time progresses. Unlike Storage I/O Control, Network I/O Control does not provide any counters that tell you that it has capped the bandwidth. NIOC can help to limit the network throughput for a particular workload or VM. If you are using 10 GE, enable NIOC so that a burst in one network workload does not impact your VM. For example, a mass vMotion operation can saturate the 10 Gb link if you do not implement NIOC. In vCenter 7, there is no counter that tracks when NIOC caps the network throughput. As a result, vRealize Operations will not tell you that NIOC has taken action. Because of all these differences, the way you approach network monitoring should also be different. If you are not the network expert in your data center, the first step is to partner with experts.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-4---storage-metrics/2.4.1-the-layers-in-storage/",
      "title": "1. The Layers in Storage",
      "tags": [],
      "description": "",
      "content": "Virtualization increases the complexity in monitoring storage performance. Just like memory, where we have more than one level, we have multiple levels for storage. At the highest level, we have VMs. A VM typically has 2-3 virtual disks (or even RDMs), such as OS drive, paging file drive, and data drive. A large database VM will have even more.\nWe are interested in data both at the VM level, and at the individual virtual disk level. If you are running a VM with a large data drive (for example, Oracle database), the performance of the data drive is what the VM owner cares about the most. At the VM level, you get the average of all drives; hence, the performance issue could be obscured.\nLatency can happen when IOPS and throughput are not high, because there are multiple stacks involved and each stack has their own queue. It begins with a process, such as a database, issuing IO request. This gets processed by Windows or Linux storage subsystem, and then send to the VM storage driver.\nBelow the VM, we have the ESXi storage subsystem and the storage adapter. We do not include ESXi in our discussion of storage counters as in general it is not a cause of storage bottleneck. Yes, the VMkernel prioritizes and queues the I/Os, but all these operations should be less than 1 millisecond. If the I/O is held at the kernel, there is a good chance that the physical device latency is more than 10 milliseconds.\nBelow the ESXi, we have the datastore level. What you can see at this level, and hence how you monitor, depends on the storage architecture. We will cover the centralized storage architecture first as it is a more deployment. We will cover the distributed architecture separately due to major differences in monitoring.\nBelow the datastore, we have the physical storage. The datastore is normally backed one to one by a LUN, so what we see at the datastore level matches with what we see at the LUN level. Multiple LUNs reside on a single array.\nIn a typical shared storage, multiple VMs run on the same ESXi, and multiple VMs share a datastore. So it is common to have an I/O blender effect, where sequential writes on individual vmdk files become random writes at the datastore level. It also changes the read/write ratio. This can occur in either VMFS or NFS. This certainly increase complexity in troubleshooting. Complexity also increases when the IO needs to go over the network, especially across different physical data centers asynchronously.\nIf you are using IP storage, take note that Read and Write do not map 1:1 to Transmit (Tx) and Receive (Rx) in Networking counters. Read and Write are both mapped to Transmit counter as the ESXi host is issuing commands, hence transmitting the packets.\nContention Metrics The main counters for performance are IOPS and latency. The rest is supporting counters, typically used in troubleshooting. Latency is part of contention counters, which includes disk queue, outstanding IO (queued), aborted SCSI commands, and dropped frame.\nFor Storage, the counter for contention is clear. First, ensure that you do not have packet loss for your IP Storage, dropped FC frames for FC protocol, or SCSI commands aborted for your block storage. They are a sign of contention as the datastore (VMFS or NFS) is shared. The counters Bus Resets and Commands Aborted should be 0 all the time. As a result, it should be fine to track them at higher level objects. Create a super metric that tracks the maximum or summation of both, and you should expect a flat line.\nOnce you have ensured that you do not have packet loss on IP Storage or aborted commands on block storage, use the latency counter and outstanding IO for monitoring. For troubleshooting, you will need to check both read latency and write latency, as they tend to have different patterns and value. It\u0026rsquo;s common to only have read or write issue, and not both.\nTotal Latency is not Read Latency + Write Latency, because it is not a simple summation. In a given second, a VM issues many IOPS. For example, the VM issues 100 reads and 10 writes in a second. Each of these 110 commands will have their own latency. The \u0026ldquo;total\u0026rdquo; latency is the average of these 110 commands. In this example, the total latency will be more influenced by the read latency, as the workload is read dominated.\nGuest OS Disk Queue This counter tracks the queue inside Linux or Windows storage subsystem. It\u0026rsquo;s not the queue at SCSI driver level, such as LSI Logic or PVSCSI. If this is high then the IO from applications did not reach the underlying OS SCSI driver, let alone the VM. If you are running VMware storage driver, such as PVSCSI, then discuss with VMware Support.\nFor Windows, the number is the snapshot at the collection period. For example, if the collection is every 5 minute, then it\u0026rsquo;s number on the 300th second, not the average of 300 numbers.\nInterestingly, Window documentation said that \u0026ldquo;Multispindle disk devices can have multiple requests active at one time, but other concurrent requests await service. Requests experience delays proportional to the length of the queue minus the number of spindles on the disks. This difference should average less than two for good performance.\u0026rdquo;\nI plot the disk queue among ~1K VMs. It\u0026rsquo;s interesting to see see some are very high.\nDisk Queue should be less than 10 in most cases, but it can spike to well above 1000. Below are typical examples, where the current queue is not even 0.01.\nThe following shows the spike. A few of these VM exceeded 1000 IO in the queue.\nLet\u0026rsquo;s take one of the VMs and drill down. This VM has regular spikes, with the last one exceeding 1000.\nTheir values should correlate with disk outstanding IO. However, the values are all low. That means the queue happens inside the Guest OS. The IO is not sent down to the VM.\nWhich in turn should have some correlation with IOPS, especially if the underlying storage in the Guest OS (not VM) is unable to cope. The queue is caused by high IOPS which cannot be processed.\nFinally, it would manifest in latency. Can you explain why the latency is actually still good?\nIt\u0026rsquo;s because that\u0026rsquo;s from the IO that reaches the hypervisor. The IO that was stuck inside Windows is not included here.\nThe application feels latency is high, but the VM does not show it as the IO is stuck in between.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-3---memory-metrics/2.3.1-virtual-memory/",
      "title": "1. Virtual Memory",
      "tags": [],
      "description": "",
      "content": "Before we talk about memory counter, we need to cover virtual memory, as it\u0026rsquo;s an integral part of memory management. The following shows how Windows or Linux masks the underlying physical memory from processes running on the OS.\nFrom the process\u0026rsquo; point of view, this technique provides a contiguous address space, which makes memory management easier. It also provides isolation, meaning process A can\u0026rsquo;t see the memory of process B. This isolation provides some level of security.\nVirtual Memory abstraction provides the possibility to overcommit. Linux may have 16 GB of physical RAM, but by using pagefile the total memory available to its processes can exceed 16 GB. The process is unaware what is backing its virtual address. It does not know whether a page is backed by Physical Memory or Swap File.\nWith virtualization, VM adds another layer. So we actually have 4 layers from Process -\u0026gt; Guest OS -\u0026gt; VM -\u0026gt; ESXi. Each of these layers have their own address space.\nFrom the VMs point of view, it provides a contiguous address space and isolation (which is security). The underlying physical pages at ESXi layer may not be contiguous, as it\u0026rsquo;s managed differently. The VM Monitor for each VM maps the VM pages to the ESXi pages1. This page mapping is not always 1:1. Multiple VM pages may point to the same ESXi pages due to transparent page sharing. On the other hand, VM page may not map to ESXi page due to balloon and swapped. The net effect is the VM pages and ESXi pages (for that VM) will not be the same, hence we need two sets of counters.\nVM Memory Counters tracks the VM Pages. There are 2 sets, one for each VM, and one a summation at ESXi level for all running VMs. Do not confuse the summation with ESXi memory counters.\nExamples: Granted or Memory Shared ESXi Memory Counters tracks the ESXi Pages. There are also 2 sets, but the summation at ESXi level contains Vmkernel own memory and VM overhead\nExamples: Consumed or Memory Shared Common This abstraction provides the possibility to overcommit, because the VM is unaware what is backing the physical address. It could be Physical Memory, Swap File, Copy On Write, zipped, or ballooned.\nFurther reading: vSphere Resource Management technical paper.\nOfficially the term is Guest Physical Page and Machine Page. I find it unnecessarily confusing, so I just call it VM pages and ESXi pages.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-2---cpu-metrics/2.2.1-guest-os/",
      "title": "1. Guest OS",
      "tags": [],
      "description": "",
      "content": "We start with the contention type of metrics as that\u0026rsquo;s the primary metric for performance, followed by utilization type of metrics.\nESXi cannot see how the Guest OS schedules its processes, and hence it can\u0026rsquo;t monitor the Guest OS. ESXi can only see what\u0026rsquo;s being sent out by the Guest. VMware Tools, which runs inside the Guest OS, is able to see inside the Guest OS. VMware Tools 10.3.5 or later and at least vSphere 6.0 P08, 6.5 P03, and 6.7 U1 are required for this.\nGuest OS CPU Run Queue Number of threads in the processor queue. For Windows, this counter excludes the threads that are running (being executed). For Linux, it includes the threads in the CPU pipeline.\nLet\u0026rsquo;s take a VM configured with 8 vCPUs. The Guest OS sees 8 threads so it will schedule up to 8 parallel processes. If there is more demand, it will have to queue them. This means the queue needs to be accounted for in Guest OS sizing.\nBecause it reports the queue, this is the primary counter to measure Guest OS performance. It tells you if the CPU is struggling to serve the demand or not.\nWhat is a healthy value?\nWindows Performance Monitor UI description is not consistent with MSDN documentation (based on Windows Server 2016 documentation). One document states that a sustained processor queue of greater than 2 threads generally indicates processor congestion. However, another states that \u0026ldquo;sustained processor queue of less than 10 threads per processor is normally acceptable, dependent of the workload\u0026rdquo;. SQL Server document states 3 as the threshold. Let me know if you have seen other recommendation from Microsoft or Linux.\nWindows or Linux utilization may be 100%, but as long as the queue is low, the workload is running as fast as it can. Adding more vCPU will in fact slow down the performance as you have higher chance of context switching.\nThere is a single queue for processor time even on computers with multiple processors. Therefore, if a computer has multiple processors, you need to divide this value by the number of processors servicing the workload. That\u0026rsquo;s why Tools reports the total count of the queues. This counter should play a role in the Guest OS CPU sizing.\nYou should profile your environment, because the number can be high for some VMs. Just look at the numbers I got below, where some VMs have well over 10 queues per vCPU. Share the finding with the VM Owner, as the remediation to reduce the queue could mean changing the application settings.\nLet\u0026rsquo;s drill down to see the first VM.\nThe CPU Run Queue spikes multiple times. It does not match the CPU Usage and CPU Context Switch Rate in pattern. I\u0026rsquo;m unsure how to explain this so if you know drop me a note. I notice the data collection is erratic though, so let\u0026rsquo;s look at another VM.\nThe following is a 2 vCPU VM running Photon OS. CPU Queue is high, even though Photon is only running at 50%. Could it be that the application is configured with too many threads that the CPU is busy doing context switching? Notice the CPU Queue maps the CPU Context Switch Rate and CPU Run. In this situation, you should bring it up to the application team attention, as it may cause performance problem and the solution is to look inside. As a proof that it\u0026rsquo;s not because of underlying contention, I added CPU Ready.\nThis property displays the last observed value only; it is not an average. Windows \u0026amp; Linux do not provide the highest and lowest variants either.\nFor Linux, we use the value of procs_running from /proc/stat (kernel/system statistics). It shows the number of processes in runnable state. It is same as the value from /proc/loadavg. It is the sum of all CPU thread run queue. The nr_running field includes currently running tasks and ready but not running tasks.\nReference: Windows and Linux.\nGuest OS CPU Context Switch CPU Context Switch costs performance \u0026ldquo;due to running the task scheduler, TLB flushes, and indirectly due to sharing the CPU cache between multiple tasks\u0026rdquo;. It\u0026rsquo;s important to track this counter and at least know what\u0026rsquo;s an acceptable behaviour for that specific application.\nBased on Windows 10 Performance Monitor documentation, context switches/sec is the combined rate at which all processors on the computer are switched from one thread to another. All else being equal, the more the processors, the higher the context switch.\nThread switches can occur either inside of a single multi-thread process or across processes. A thread switch can be caused either by one thread asking another for information, or by a thread being pre-empted by another, higher priority thread becoming ready to run.\nThere are context switch counters on the System and Thread objects. vRealize Operations only report the total.\nThe rate of Windows or Linux switching CPU context per second ranges widely. The following is taken from a Windows 10 desktop with 8 physical threads, which runs around 10% CPU. I observe the value hovers from 10K to 50K.\nThe value should correlate with CPU \u0026ldquo;utilization\u0026rdquo;, since in theory the higher the utilization the higher the chance of CPU context switch. The following chart shows a near perfect corelation. Every time CPU Usage went up, CPU Context Switch also.\nCPU context switch can happen even in a single thread application. The following shows a VDI VM with 4 vCPU. I plotted the CPU Usage Disparity vs CPU Context Switch. You can see the usage disparity went up to 78%, meaning the gap between the busiest vCPU and the most idle vCPU is 78%. This was running a security agent, which is unlikely to be designed to occupy multiple vCPU.\nLet\u0026rsquo;s plot the context switch at the same period. There is a spike at the same time, indicating that the agent was busy context switching. Note that it does not always have to be this way. The red dot shows there is no spike in context switch even though the vCPU Usage Disparity went up.\nThe value of CPU Context Switch vary widely. It can go well beyond 0.5 million, as shown in the following table, hence it\u0026rsquo;s important to profile and establish a normal base line for that specific application. What is healthy for 1 VM may not be healthy for another.\nYou can see from the table that some VM experience prolonged CPU context switch, while others do not. The VM #4 only has a short burst as the value at 95th percentile dropped to 3796. Momentary peak of context switch may not cause performance problem so in general it\u0026rsquo;s wiser to take the value somewhere between 95th and 99th percentile.\nLet\u0026rsquo;s drill down to see the first VM. This CentOS VM sporting only 4 vCPU constantly hit almost 1 million context switch. The pattern match CPU Usage.\nOn the other hand, majority of Guest OS spends well below 10K. I profiled around 2200 production VMs and here is the distribution of their CPU Context Switch. You can see that the values between 0 - 12000 accounts for 80%.\nIn your environment, you can profile it further. In the following example, I adjusted the bucket threshold by grouping all the values above 10K as one bucket, and splitting 0 - 10K bucket into multiple buckets. You can see more than half has less than 1K CPU Context Switch Rate.\nLinux Steal Time According to Red Hat documentation, Steal Time is the amount of CPU time needed by the VM that is not provided by the hypervisor. It occurs when the host allocates the CPU resource for its own process or to another guest.\nWhile Linux has this counter, it is 0 when it runs on ESXi because it\u0026rsquo;s not enabled by default. Even if it\u0026rsquo;s enabled, it only accounts for Ready time. It does not account for other time such as CoStop, VM Wait and memory wait.\nCPU Ready includes Limit. I have not verified if Linux Steal Time accounts for it.\nOther Guest OS Metrics Windows 8 and later will report CPU usage \u0026gt;100% in Task Manager and Performance Monitor when the CPU Frequency is higher than nominal speed. The reason for the change is the same with what we have covered so far, which is the need to distinguish amount of work being done. More here.\nReference: Windows and Linux.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-1---overview/2.1.1-nuances-in-metrics/",
      "title": "1. Nuances in Metrics",
      "tags": [],
      "description": "",
      "content": "\nSame name, same object, different formula The counters have the same name, belong to the same object, yet they have a different formula depending on where in the object you measure it.\nVM CPU Used in vCPU level does not include System time but at the VM level it does. The reason is that System time does not exist at vCPU level since the accounting is charged at the VM level.\nSame name, different formula Counters with the same name do not always have the same formula in different vSphere objects.\nMemory Usage: in VM this is mapped to Active, while in ESXi Host this is mapped to Consumed. In Cluster, this is Consumed + Overhead1. vRealize Operations uses Guest OS data for Usage, and falls back to Active if it\u0026rsquo;s not available.\nMemory Consumed: in ESXi this includes memory consumed by ESXi, while in Cluster it only includes memory consumed by VM.\nMemory Consumed: in VM this does not include overhead, while in Cluster it does. VM Used includes Hyper Threading but penalty is 37.5%. ESXi Used is also aware of HT but the penalty is 50%.\nSteal Time in Linux only includes CPU Ready, while Stolen time in VM include many other factors including CPU frequency.\nSame name, different meaning Counters with the same name, yet different meaning. Be careful as you may misinterpret them.\nVM CPU Usage (%) shows 62.5% when ESXi CPU Usage (%) shows 100%. This happens since VM CPU Usage considers Hyper Threading, while ESXi CPU Usage does not. It happens when the ESXi core that the VM vCPU runs is also running another thread.\nAnother example is Latency. Disk Latency and Memory Latency indicate a performance problem. They are in fact the primary counter for how well the VM is being served by the underlying IaaS. But CPU Latency does not always indicate a performance problem. Its value is affected by Hyper-Threading and CPU Frequency, which can go up or down. Sure, the VM is running at a higher or lower CPU speed, or run less efficiently, but it is not waiting to be served. It\u0026rsquo;s the equivalent on running on older CPU.\nSame name, different behaviour Memory and CPU Reservations have different behaviours from monitoring viewpoint.\nVM RAM Reservation is permanent, hence impacts memory utilization. The Memory Consumed counter includes it even though the page is not actually consumed yet. If you power on a 16 GB RAM VM into a BIOS state, and it has 10 GB Memory Reservation, the VM Consumed memory counter will jump to 10 GB. It has not actually consumed the 10 GB, but since ESXi has reserved the space, it is not available to other VMs.\nVM CPU Reservation is on demand, hence it does not impact CPU utilization. Run, Used, Demand, Usage do not include it. Their value will be 0 or near 0 if the Guest OS is not running.\nSame purpose, different name You would expect if the purpose is identical then the label or name would be identical.\nSwapped Memory in VM is called Swapped, while in ESXi is called Swap Used.\nStatic frequency CPU utilization in VM is called Run, while ESXi calls it Utilization.\nWhat vCenter calls Logical Processor (in the client UI) is what ESXi calls Physical CPU (in esxtop panel)\nConfusing name The name of the counter may not be clear.\nVM CPU Wait counter includes Idle time. Since many VMs do not run at 100%, you will see CPU Wait counter to be high. You may think it\u0026rsquo;s waiting for something (e.g. Disk or Memory) but it\u0026rsquo;s just idle.\nIn Microsoft Windows, the CPU queue only counts the queue size, while the disk queue excludes the IO commands being processed.\nConfusing roll up Why is VM CPU Ready above 100%? If you look at esxtop, many VM level counters are \u0026gt;100%.\nConfusing unit Why are CPU counters expressed in milliseconds instead of percentage or GHz? How can a time counter (milliseconds in this case) account for CPU Frequency? There is a good reason for that!\n\u0026ldquo;Missing\u0026rdquo; Counters You will find VM CPU Demand, but not VM Memory Demand. Demand does not apply to memory as it\u0026rsquo;s a form of storage, just as there is no such thing as a Demand metric for your laptop disk space.\nToo many choices When you have two watches showing different time, You are not sure which watch is the correct one.\nThere are five counters for VM CPU \u0026ldquo;utilization\u0026rdquo;: Run, Used, Usage, Usage in MHz, and Demand. Why so many counters just to track utilization, different to what Windows or Linux tracks?\nThere are 6 counters for ESXi CPU \u0026ldquo;utilization\u0026rdquo;: Core Utilization, Utilization, Used, Usage, Usage in MHz, and Demand.\nYou must remember that the counters are not just created for vSphere administrators. They are also used by the VMkernel scheduler itself as input. CPU Latency is one such counter.\nESXi vs vCenter While ESXi is the source of counters, vCenter may add its own counters and the formula don\u0026rsquo;t always match 100% in all scenarios, such as Used vs Usage.\nESXi provides Run (ms), Used (ms), Demand (MHz) for VM CPU. vCenter adds Usage (MHz) and Usage (%), which create confusion as there are now 5 choices.\nESXi shows Used (%), while vCenter shows Used (ms). The first one affected by CPU frequency and can go beyond 100%.\nESXi != VMs + VMkernel The counters at ESXi is more complex than the sum of its VM + VMkernel. The reason is there are additional parameters that must be taken into account. For example, the impact of CPU SMP (or Hyper Threading as Intel calls it) is not measured at the VM level. Be careful when summing VM counters and assume it\u0026rsquo;s ESXi counter.\nM:N relationship A VM with multiple virtual disks can span across multiple datastores, and even RDMs. On the other hand, a datastore typically hosts many VMs. An ESXi may mount multiple LUNs and a LUN is typically presented into multiple ESXi or even multiple clusters. These many to many relationships make the counters across VM, datastore, ESXi and Cluster inconsistent when viewed overall. Each of them is correct as each has to look from their own vantage point.\nWindows vs Linux Windows CPU queue excludes the running thread, Linux includes the threads being executed.\nComplicated stuff, isn\u0026rsquo;t it? And we have not added AWS, Google, Azure, applications, network, etc.\nNot all vSphere-specific characteristics are well understood by management tools that are not purpose-built for it. Partial understanding can lead to misunderstanding as wrong interpretation of counters can result in wrong action taken.\nThere is also a scalability concern. In vCenter, there are 17 CPU counters available at the VM level, and 12 of them are available at a vCPU level too. In addition, each VM comes with 28 memory counters. That means a VM with 4 vCPUs will have 93 counters (17 + 4 x 12 + 28). A vSphere environment with 1,000 VMs with 4 vCPUs as the average VM size will have process 93K counters each time it collects. If you do that every minute, you will collect almost 134 million metrics per day. Since many customers like to keep for at least 6 months, that\u0026rsquo;s 24+ billion metrics!\nWith so many metrics, the amount of business value received becomes a valid concern.\nvRealize Operations does not regurgitate the counters that vCenter has. It starts by understanding the unique behaviour of vSphere, then simplifying it by consolidating and standardizing the counters. For example, vRealize Operations creates derived counters such as KPI and capacity metrics, then applies them to CPU, RAM, disk, and network as appropriate.\nTechnically speaking, mapping usage to active for VM and consumed for ESXi makes sense, due to the two-level memory hierarchy in virtualization. At the VM level, we use active as it shows what the VM is actually consuming (related to performance). At the host and cluster levels, we use consumed because it is related to what the VM claimed (related to capacity management). This confusion has resulted in customers buying more RAM than what they need.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-7---availability-management/1.7.1-standalone-system/",
      "title": "1. Standalone System",
      "tags": [],
      "description": "",
      "content": "The simplest representation of availability is a ratio of the value of the uptime of a system to the aggregate of the values of up and down time during the observation window.\nLet\u0026rsquo;s take an example. In a year (defined as 365.25 days) a solution has a single downtime lasting 24 hours on a busy working day.\nSo, the availability can be calculated as:\nAnother equation for availability is a ratio of the Mean Time Between Failure (MTBF) and Mean Time To Repair (MTTR), or:\nThe industry practice is to call out availability in terms of \u0026ldquo;nines\u0026rdquo;. For example, 99% availability is two nines, 99.99% is termed as four nines. In our example above, the system delivered 99.73% even though it was down for entire day!\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-6---compliance-management/1.6.1-overview/",
      "title": "1. Overview",
      "tags": [],
      "description": "",
      "content": "Due to the increasing footprint of technology and related complexities it is becoming more challenging for organizations to ensure security in their environment. A predefined policy from the regulations and accrediting organizations helps in reducing the complexity and removes unnecessary duplication of effort and activity from resources. A few examples of such policies are PCI-DSS in the financial industry and HIPAA in healthcare.\nThe end customers are also demanding that businesses comply to industry-wide security standards while providing their service. For these reasons, instead of defining their own proprietary policies, businesses are either directly adopting these set standards or taking these as base policy and further customizing it to suit their need.\nWhile these guiding policies ensures the initial configuration is compliant to the security requirements, how do we ensure the environment is continuously compliant to the defined standards? This is where vRealize Operations helps. Use it to monitor the continuous compliance of the environment. The rest of the chapter will describe how we can achieve this.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-5---cost-management/1.5.1-dare-to-compare/",
      "title": "1. Dare to Compare",
      "tags": [],
      "description": "",
      "content": "In the cloud era, application teams today are provided with more choice of infrastructure. All they need is a credit card and application development can start. No need to deal with internal red tape just to get a bunch of hardware, since they are all available as an on-demand service.\nBy, the public cloud providers are competitors to internal on-prem cloud. As an internal cloud provider, you need to turn the public cloud providers into allies. That requires a shift in your business model, from infrastructure provider to a multi-cloud service broker. You broker the request for infrastructure with the most appropriate provider. You evaluate, choose and deliver multiple clouds if the on-prem cloud does not meet the business needs. Even the on-prem cloud can be a service that you procure (meaning you do not own the hardware and software), if that fits your business requirements better.\nIt is indeed possible for a small and no-frill internal IT infrastructure team to complement a much larger cloud provider. Being small, especially since you are on-site and work in the same company, enables you to offer a better service. Nobody likes dealing with the bureaucrazy, pun intended, of a large corporation\u0026rsquo;s support organization. You can get lost in the policy.\nYou also need to do an apple-to-apple comparison. List the entire components of the service. The following table provides an example, where you add your private cloud alongside externally hosted cloud. You should complement this table with another table comparing the SLA and price. I\u0026rsquo;ve provided a sample of SLA table in the Capacity Management section.\nCost and Price are related but different. Price is what your customers care as that\u0026rsquo;s what they pay. If you increase your prices too high because your costs are high, your customers will just move to public cloud.\nBe consistent with the terminology. What is Price to you is Cost to your customer. It\u0026rsquo;s easier to use the term price when describing cost to your customers. Otherwise, you can get mixed up, such as demonstrated in the following sentence: \u0026ldquo;Cluster with plenty of capacity is more expensive as the cost is only shared by few VMs\u0026rdquo;.\nWhat that sentence meant is Cost per VM, which is a hypothetical cost as you do not incur that cost.\nYou need to develop both the Pricing Model and the Cost Model, ideally at the same time.\nLet\u0026rsquo;s look at price first, as we need to start with the customer.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-4---configuration-management/1.4.1-overview/",
      "title": "1. Overview",
      "tags": [],
      "description": "",
      "content": "As an operation management software, vRealize Operations focuses on the impact to day-to-day operations a product has, rather than the feature of the product itself. Products under monitoring, such as vSphere and vSAN, can have features that are related, but have different impact to operations. Take for example, vSphere provides Limit, Reservation and Share for VM. As feature, they are closely related, appear in the same dialog box in vCenter client UI and should be mastered as one. However, they impact operations differently. The following table describes that in more details.\nvRealize Operations takes the principle that there are different impacts to operations, and applies a methodology for looking at configuration. It does not group the settings by features or objects. Rather, it begins with the impact in mind, and prioritize what can be done.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.1-good-advice/",
      "title": "1. &#34;Good&#34; Advice",
      "tags": [],
      "description": "",
      "content": "Can you figure out why the following statements are wrong? They are all well-meaning advice on the topic of Capacity Management. We\u0026rsquo;re sure you have heard them, or even given them.\nRegarding Cluster RAM:\nWe recommend 1:2 overcommit ratio between physical RAM and virtual RAM. Going above this is risky. Memory Usage on most of your clusters is high, around 90%. You should aim for 60% as you need to consider HA. Memory Active should not exceed 50-60%. You need a buffer between Active Memory and Consumed Memory. Memory should be running at high state on each host. Regarding Cluster CPU:\nCPU Ratio on cluster \u0026ldquo;XYZ\u0026rdquo; is high at 1:5, because it is an important cluster. The rest of all your clusters\u0026rsquo; overcommit ratio looks good as they are around 1:3. This gives you some buffer for spikes and HA. Keep the over commitment ratio to 1:4 for Tier 3 workload as they are not mission critical. CPU usage is around 70% on cluster \u0026ldquo;ABC\u0026rdquo;. Since they are UAT servers, don\u0026rsquo;t worry. You should get worried only when they reach 85%. The rest of your cluster\u0026rsquo;s CPU utilization is around 25%. This is good! You have plenty of capacity left. The scope of the statements above is obviously about a VMware vSphere Cluster. From a capacity monitoring point of view, cluster is the smallest logical building block, due to HA and DRS. So it is correct to assume that we do capacity planning at Cluster level, and not at Host level or Data Center level.\nCan you figure out where the mistakes are?\nYou should notice a trend by now. They have something in common. If not, answer at the Part 4: Quiz Answers!\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.1-a-day-in-the-life/",
      "title": "1. A Day In The Life of a Cloud Admin",
      "tags": [],
      "description": "",
      "content": "To understand what Performance actually is, it is always good to begin with the customer. As shared earlier, what you bought from your vendor is SDDC, but what you sell to your customers is IaaS. We have seen this in almost all customers. Whether the Application Team or VM Owner pays for the service with a chargeback model or not, it is a service. VM Owners no longer own, hence care, about the underlying infrastructure.\nHere is a common story often told in the virtualization community, which will resonate with you as an IaaS provider.\nA VM Owner complains to you that her VM is slow. It was not slow yesterday. Her application architect and lead developer have verified that:\nThe VM CPU and RAM utilization did not increase and are within a healthy range. The application team has verified that CPU Run Queue is also in the healthy range. The disk latency is good. It is below 5 milliseconds. There are no network packets loss. No change in the application settings. In fact, the application has not had any changes in the past 1 month. No recent patches were installed into Windows. There was no reboot. It has been running fine for weeks. She said your VMware environment is a shared environment, and perhaps an increase in the number of VMs and an increase in the workload of other VMs are straining your IaaS.\nShe also said that her other VM, which was P2V recently, was performing much faster in physical.\nYou are right. She is saying it\u0026rsquo;s your fault.\nWhat do you do?\nIt is certainly a difficult situation to be in. You oversee more than 10,000 VMs. You have successfully consolidated them into 500 ESXi Hosts, saving the company 9500 servers, not to mention a lot of money. You built your reputation during the process, so this is not just a matter of her VM not performing. Your reputation is at stake here.\nYou also recall that your team has been adding new VMs regularly in the past several months so she could be right. But why did it happen today, and not say a few days ago?\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-1---quiz-answers/",
      "title": "Chapter 1 - Quiz Answers",
      "tags": [],
      "description": "",
      "content": "Chapter 1 Quiz Answers Throughout the book, I sprinkled some quizzes to help you pause and ponder. This section documents the answer.\n1. Part 1 - Operations Management\r2. Part 2 - Metrics\r3. Part 3 - Dashboards\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/downloads/vsphere-metrics/",
      "title": "vSphere Metrics",
      "tags": [],
      "description": "",
      "content": "\rThis is a new project! We\u0026rsquo;d love contributors.\nvSphere Metrics is an open-source book. At \u0026gt;300 pages, it\u0026rsquo;s the most complete documentation that I know of on the topic. To keep the book size manageable, I have excluded some metrics. To see the full list, see VMware Operations Transformation, 4th Edition.\nWhile version 2.0 delivers many updates, the book is far from completing its mission. You will notice that vSphere objects such as Cluster, Datastore, and Distributed Switches are not yet documented. This book is a call for collaboration to the VCDX, VCIX and all VMware professsionals.\nCheck out the step by step instruction on how to contribute.\nThe book covers 3 types of metrics:\nVirtual Machine and Guest Operating Systems. ESXi. esxtop. Download\rVMware vSphere Metrics v2.0.1.docx\r(39311 kb)\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/acknowledgements/contributors/",
      "title": "Contributors",
      "tags": [],
      "description": "",
      "content": "This site would be nothing without the incredible contributions from the community. In the spirit of healthy competition, a leaderboard is generated based on the top contributors from the repo.\nPosition\rUser\rCommit Count\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-9---infrastructure-architect/4.9.2-global-role/",
      "title": "2. Global Role",
      "tags": [],
      "description": "",
      "content": "I made a career move from a local role to a global role in 2016. The actual transition started a few years earlier, where I volunteered in global calls for help. By the time I officially transfered in 1 Aug 2016, I was already a part of the global specialists team.\nMany years have passed since 2016, so I\u0026rsquo;d like to share the pros and cons of both roles. Hopefully it helps you in your career, and keeping the fun in work!\nIt\u0026rsquo;s common for a global corporation to have 4 levels of geographic coverage:\nLocal: cover a city or a small country. In my case, it\u0026rsquo;s just Singapore. Regional: cover a region or large country. In my case, it\u0026rsquo;s ASEAN. Continent: Asia Pacific, Europe, Africa, America Global. In a vendor environment (as opposed to end-user), there are 2 large primary teams:\nProduct team: develop the product. The sub-teams are: Product Management, R\u0026amp;D, QA, Sustaining, UX (focus on the UI), IX (focus on documentation). They focus on releasing the next big thing. Field team: sell, implement, support the product. Sales, SE, Consulting, Technical Account Managers, Support, Education, Customer Success They focus on the quarterly target, closing large deals. Of course, they are supported by many smaller \u0026amp; supporting teams, such as marketing, pricing, and CTO Office.\nI\u0026rsquo;ve never worked in Product Team, so when an opportunity arose, I took the leap of faith.\nFrom Local to Global, bypassing ASEAN and Asia Pacific. From Field to R\u0026amp;D. My boss no longer in Singapore, ASEAN and Pacific, but directly at our HQ in Palo Alto. From generalist to specialist. I now do vR Ops full time. If this is not my passion, I\u0026rsquo;d have quit long time ago! I can say with confidence that it was generally a good decision, although it comes at a price. We all work for 3 reasons. I call them the 3M\u0026rsquo;s of work:\nMoney. It pays the bills Meaning. It has to fill your spirit, not just your pocket. Merriment. It\u0026rsquo;s gotta be fun, and you love your work. The job at the global level is harder, much harder. Instead of thinking for just 1 customer (my job was Account SE), or a few customers, I have to think of the world. While working on future versions, I have to think of current and previous versions that customers are still running. Brownfield is much harder than greenfield. I learned from the R\u0026amp;D team that there were many things to be considered before adding or removing a feature. The complexity makes the job meaningful. Life is short, and the journey is as important as the destination. I\u0026rsquo;ve never done product development before. Luckily, folks are kind and we got along well. I work with the R\u0026amp;D team in Armenia, Bangalore and Palo Alto. They have never, never asked me to accommodate their time zone. I\u0026rsquo;m truly grateful for that. Folks like Monica, Chandra, Kameswaran and of course my trusted partner-in-crime Sunny Dua provide a lot of coaching and guidance. I know the fact that their mentorship is critical.\nMy perspective was widened. Before, I was just working with a few customers in Singapore, and a bit of ASEAN. Now I work with customers from Europe to US. What I accepted as the best before, has been reset. I\u0026rsquo;ve seen other regions and customers achieved something better, tackled something harder, and delivered something bigger.\nI didn\u0026rsquo;t know there was so much work! The demand for the role I took was apparently untapped. I had no idea since I was not busy when doing local role! There was so much request for help outside Singapore. I do zoom sessions regularly with customers, helping them remotely. They would login to their production environment, and we troubleshoot issue together. I get to see live environments, and gain insight into their operations.\nThe downside is people expectation. I receive regular escalation and work closely with R\u0026amp;D. I have to produce a solution instead of relying on others. My work starts where the documentation ends. Now you know why I have to write 3 books. Sunny has been a godsend for me. After intense discussion, we often come up with a solution that neither of us had originally considered.\nAnother downside is global travel. It impacts my family, and certainly myself. The jet lag and long flight in economy is not good for my health, since I have autoimmune disease and low back pain. Controlling the schedule is important, else I could travel non-stop and only spend weekends at home. My travel schedule is practically full 3 months in advance. Again, folks are generally accommodating. I learn when we explain to folks openly why we can\u0026rsquo;t be there (they are sponsoring my trip), they are willing to accommodate.\nI travel alone most of the time. After doing the requested work by the hosting country, I\u0026rsquo;d go back to the hotel, eat a quick dinner alone then do my day job. If I have dinner with the local team, that means that day I can\u0026rsquo;t do my day job. Coupled with being apart from my kids and family, loneliness is my friend.\nTravel can be sudden. I got a call to help a large customer on Thursday morning, and on Sunday I was already in the plane to see them. If you have young kids, this can be deal breaker. My 2 kids are big already, but my Mama at 81 needed care. When she passed away, I was overseas\u0026hellip;\nSpeaking of travel, gluten free is a challenge. I am allergic to both dairy and gluten, so keeping these 2 away is almost impossible when abroad. There is no easy solution today. Singapore Airlines changes the menu only every 3 months, so I know in advance exactly what I\u0026rsquo;m getting.\nI hope the sharing is useful for those who are thinking of taking a global role.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.2-rds-vs-vdi/",
      "title": "2. RDS vs VDI",
      "tags": [],
      "description": "",
      "content": "At the end of the day, users just wants to access their desktops (e.g. to organise their files) and use their applications (e.g. browser, spreadsheet). There are 2 competing architecture to deliver the above (desktop and application):\nShared Windows. This is typically Windows Server. Dedicated Windows. This is always Windows 10 The shared architecture is called RDS and the dedicated architecture is called VDI. As you can guess, the shared is cheaper as it has less overhead, but harder to troubleshoot. Shared technology also carries higher availability risk. When the application or Windows crash, more than 1 user are affected. Windows 2019 also does not have concept of shares, limit and reservation. All the sessions compete freely for its resources.\nHilko Lantiga shares another limitation of RDS is the load balancer does not balance based on actual load. It\u0026rsquo;s simply distributing the session based on initial placement. The initial placement can consider any metrics, but there is no \u0026ldquo;session vMotion\u0026rdquo; subsequently within the RDS Farm. If you are unlucky all the heavy users could end up on the same RDS session host. That\u0026rsquo;s why vRealize Operations introduces the Usage Disparity metrics.\nVDI can be used to deliver application session. It\u0026rsquo;s not common as the overhead is the same with giving entire desktop. The primary use case is usability. If you\u0026rsquo;re delivering Windows applications to Mac users, showing them a Windows desktop will be more confusing than simply showing them the individual applications. Showing the individual application will make them feel like an Apple Mac application.\nRDS presents another challenge as it introduces Farm and Host concept. A farm can have many hosts and many pools, and pool has M:N relationship to host. A session connects to a pool, and runs on the host. So a session has 2 parents: pool and host. To keep it simpler operationally, limit to 1 pool per RDS farm. But this results in smaller farms and more farms.\nIn terms of monitoring and troubleshooting, VDI provides more metrics, as it\u0026rsquo;s just a VM. RDSH provides limited metrics, as they are just a collection of processes. For example, process level contention (be it CPU, memory, disk and network) are not exposed.\nThe following diagram shows the possible permutation that you can give to a user. Let\u0026rsquo;s start with RDS first.\nFor VDI, this is what the connection looks like. The pool cannot be both desktop pool and application pool.\nI did not draw the permutation where a user accesses all 4 types of sessions. You can certainly have it. When you design, think of complexity in operations. Flexibility can reduce cost but often comes at the price of complexity. A few human errors in a year can negate the benefit of cost savings, or reduce customer satisfaction.\nHorizon sessions are ephemeral objects. In solution such as Instant Clone, the vSphere VM is also a temporary object that gets destroyed after usage. This means the historical data will be lost too. To enable troubleshooting past data, we keep a copy of the data in the User object.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-7---vmware-it-operations/4.7.2-monitoring/",
      "title": "2. Monitoring",
      "tags": [],
      "description": "",
      "content": "We prepared the number of use-cases, while defining the solution to achieve the service owners monitoring requirements. As a customer one program we worked with product team to achieve the monitoring requirements and raised the user stories to develop the solution to remove monitoring gap. We are sharing some of the key use-cases here.\nAvailability Monitoring To address challenges in monitoring availability of both virtual and physical components, we had to resort to numerous workarounds, which eventually became evident that the existing solution would not scale beyond a certain finite point.\nTo eliminate this operational overhead, the team introduced additional functionality in the form a Ping Adaptor. The ping functionality can now be easily configured at the adapter instance for IP addresses, group of IP addresses, and FQDN.\nDaily Operational Dashboard With over 250+ applications and services, and 4000+ components, it is indeed challenging for the Operations teams to have a \u0026lsquo;birds-eye\u0026rsquo; view of the health of all applications/services. vRealize Operations made it seamless with the logical grouping functionality.\nWe grouped devices based on service and application component with the help of applications owners. We used these groups to custom health and operations dashboard. This will help to know the health and deeper data analysis to troubleshoot the issue. If this dashboard was not made available, the Operations teams would have to view multiple dashboards in order to ascertain the overall health of the Applications/Services.\nObject Inventory Dashboard We have configured multiple object types per object and it\u0026rsquo;s very difficult to know what was configured and what is the data value for relational objects. Also this page will help to compare the multiple objects type value during single object troubleshooting. If this dashboard is not available, one would have to click through different sections to know the child and parent objects data values.\nAppliances Monitoring Some Applications run as appliances (vApp) to ensure better security and Application integrity. This, however, poses a challenge from a monitoring standpoint- agents or other internal probes are not allowed to be installed. As a feature request, we worked with vRealize Operations product team to develop a new SNMP Adapter. This new adapter filled the gap of monitoring remote components/vApps.\nCustom Monitoring Our main goal was to provide an end-to-end monitoring solution to service owners. With the help of super metrics and custom scripts, we covered the adhoc monitoring gaps. For example, we had a requirement to keep NTP sync value between clients and master server to a minimum. We developed a script and executed the same from client servers to obtain the NTP metrics.\nService Monitoring We have some application using shared services and database instances. We used corresponding service management packs to auto-discover all KPI\u0026rsquo;s and segregate KPI\u0026rsquo;s based on Applications. For instance, RabbitMQ management pack was leveraged to discover all virtual host and queues. We grouped the queues based on applications to support overall health and operational dashboards.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-6---automation/4.6.2-outgoing-communication/",
      "title": "2. Outgoing Communication",
      "tags": [],
      "description": "",
      "content": "This chapter describes the available options to send information from vRealize Operations to another, so called north-bound, systems.\nWhen speaking about north-bound systems we usually refer to services like mail servers or SNMP trap receivers. Since the advent of 8.x versions of vRealize Operations, the product supports more and more REST services like ServiceNow and Slack natively. Starting with the version 8.4, vRealize Operations provides a Webhook plugin as a generic way to integrate any REST API endpoints.\nOutbound Plugins Out of the box vRealize Operations provides a set of Outbound Plugins. These plugins are used to create Outbound Instances. Every Outbound Instance is basically a connection to an external endpoint. The next picture shows the available plugins.\nThe configured Outbound Instances provide a one-way communication towards other systems. The first plugin type in this list is the Automated Actions Plugin. After initial installation and configuration of vRealize Operations, an Outbound Instance based on this plugin is automatically available for consumption. With actions in context of this particular plugin, we refer to actions run in the managed vCenter instances. A pre-requisite to enable such automated actions is enabling Operational Actions in the configuration of a Cloud Account adapter instance and sufficient permissions granted to the account used for the vCenter connection.\nAutomated Actions, as the name implies, can be used to automate execution of task as part of a Recommendation within an Alert Definition. Out-of-the-box vRealize Operations provides several Recommendations containing a vCenter actions, like shown in the following picture.\nThe first step towards a Self-Healing SDDC is to automate such actions. Of course, in a SDDC it needs more than just enabling automation. For example, we need to be compliant with change management processes, involve owners of the managed VMs or get approval. How to be compliant with such requirements is not part of this chapter but you will learn what options you have to get there.\nBefore I give you a short recipe how to enable action automation based on an easy example, let\u0026rsquo;s quickly recall the Alert Definition concept in a simplified form.\nThe following picture shows the relationships between the involved objects. An Alert Definition may have one or multiple Recommendations. A Recommendation may include an Action. This Action will be available within the Recommendation and can be executed manually from the details view on an alert.\nNow, there is only one step missing to introduce automation: enabling automated execution of the Action within the Policy controlling the behavior of any given object.\nThe next picture shows the corresponding part of a sample policy.\nNext time this specific Alert will be triggered, vRealize Operations will try to execute the configured Action automatically. I say \u0026ldquo;try\u0026rdquo; because some actions need appropriate inputs und simply cannot run without interaction with the administrator.\nThe Automated Action Plugin is a great and easy to use option to start automating tasks triggered by vRealize Operations alerts, but it has its limits. The available actions are pre-configured and cannot be customized to cover more complex scenarios.\nAnother plugin that may be used to automate tasks triggered by vRealize Operations is the SNMP Trap Plugin. Yes, you are right, SNMP traps are usually configured to trigger alerts or open tickets via systems running a SNMP receiver. With the help of vRealize Orchestrator you can utilize SNMP traps as part of automation workflow. In the next picture you can see how I have configured my SNMP Outbound Instance to send SNMP traps to my vRealize Automation integrated vRealize Operations instance.\nThe following link describes how to configure a SNMP trap receiver policy to start scripts or workflows anytime a SNMP trap has been received.\nOn the vRealize Operations site, the Notification element provides the required functionality to connect the \u0026ldquo;sensors\u0026rdquo; with the \u0026ldquo;actors\u0026rdquo;. As part of a Notification, we specify the Outbound Instance, like the SNMP-Plugin based one depicted in the next figure. This way we can utilize vRealize Orchestrator workflows as part of our automation setup.\nWith this information we can extend the model I have introduced earlier to also include Notifications and Outbound Instances as possible building blocks of automated operations.\nThese methods of automation, Automated Actions as well as Notifications utilizing Outbound Instances both represent the fire-and-forget or as described at the beginning, the open-loop variant of running automation tasks. If your use cases require more than that, like for example gathering additional data from vRealize Operations to make a more educated decisions, keep reading, you will learn how to master such challenges.\nWebhook The new Webhook Outbound Plugin provides a generic way to integrate any REST API endpoint and deserves its own chapter. Using notifications and the new Payload Templates, you can configure the desired outbound payload granularly down to single metric level. Following picture shows an example of the payload configuration which may be used with a webhook outbound connection.\nJohn Dias, one of our great Tech Marketing Architects, created a sample Webhook for MS Teams integration. To integrate MS Teams as target for vRealize Operations Notifications, first you need to create an incoming Webhook connector for your Teams channel. The configuration of the Webhook in MS Teams is not part of this chapter, but it is very well described in John\u0026rsquo;s post. To use the MS Teams connector in vRealize Operations, simply create an outbound plugin instance in vRealize Operations with the complete URL of the MS Teams incoming webhook as parameter as shown in the next picture:\nThe provided payload sample makes the creation of a Notification an easy task. The payload template describes the information vRealize Operations will send out to the target as soon as the specified notification rules apply. The next figure shows the template created by John for the MS Teams integration.\nThe new Webhook capabilities makes it possible to integrate vRealize Operations with systems we probably have not even considered until now, such as message queues.\nWith an instance of the Webhook plugin pointing to a RabbitMQ endpoint and an appropriate payload template vRealize Operations allows now to create notifications which will send data to RabbitMQ queues on certain events. Like in this example showing RabbitMQ queues for opened and canceled alerts.\nvRealize Operations Management Pack for vRealize Orchestrator The first version of the vRealize Operations Management Pack for vRealize Orchestrator was introduced back in 2018. It has undergone many enhancements and is available for free. It opens up possibilities to automate your SDDC by providing the following features:\nInsights into vRealize Orchestrator including various metrics, properties and predefined dashboards and alert definitions vRealize Orchestrator workflows as Actions within Recommendations The ingredients for self-driving SDDC are:\nvRealize Orchestrator instance. You can use a stand-alone vRealize Orchestrator or the instance deployed as part of the vRealize Automation installation. vRealize Operations. vRealize Operations Management Pack for vRealize Orchestrator. To describe the details let us focus on a simple use case: \u0026ldquo;If a VM (the OS) crashes, this VM should be hard-reset.\u0026rdquo;\nAs \u0026ldquo;seems to be crashed\u0026rdquo; or the exact description how to determine if a VM really crashed is not object of this chapter, we assume we have appropriate symptom and alert definitions in place.\nThe generic recipe from use case to auto-remediation is almost always applicable:\nCreate a vRealize Orchestrator workflow for your use case. Create or modify a vRealize Orchestrator package. Discover or re-discover vRealize Orchestrator package that includes our workflows in vRealize Operations. Optional - Configure workflow in vRealize Operations - in our case it is mandatory. Create or edit vRealize Operations recommendation. Add vRealize Operations recommendation to an alert definition. Optional - Manual remediation. Optional - Enable automatic remediation. I am not going to describe the content of the workflow itself or how to code in vRealize Orchestrator. The focus is how to integrate any given workflow in vRealize Operations and let it execute automatically as part of the alert remediation.\nFor our use case the vRealize Orchestrator workflow needs at least one input parameter to pass the vCenter VM object reference from vRealize Operations to vRealize Orchestrator. In the following picture you see a second input string parameter, vRealize Operations_alert_id. If this parameter is available, vRealize Operations will pass the internal alert ID to vRealize Orchestrator. This ID can be used for callbacks to retrieve more information from vRealize Operations. How to accomplish this will be part of the next subsection of this chapter.\nThe workflow inputs, as for the current version of the solution, are:\nvm as VC:\u0026lt;Datatype\u0026gt;, it will be populated with the object which triggered the alert. 1vRealize Operations_alert_id` as String, it will be populated with the actual vRealize Operations alert ID for further callbacks. To make the workflows which you would like to use be available in vRealize Operations you need to follow a certain process. You can easily find the details on my blog.\nThe following picture shows two custom vRealize Orchestrator workflows available in vRealize Operations. After the initial integration of the Management Pack there are pre-configured packages available which include a variety of workflows available in vRealize Orchestrator out-of-the-box.\nIf the use case requires the workflow to be executed on a specific vCenter object, like the VM in this example, it needs to be configured properly in vRealize Operations.\nvRealize Operations driven automation needs to know for what resource types within an alert definition as the type this specific alert will be triggered on and on what resource type in vRealize Orchestrator the configured workflow can be executed. The corresponding configuration process is to run \u0026ldquo;Create/Modify Workflow Action on vCenter Resources\u0026rdquo; in context of the specific workflow.\nThe alert specified in the example use case will be triggered on VM resource type and will be executed on a VM resource in vCenter. To accomplish this VM is exactly the type to configure as highlighted in the following picture. The last step is the \u0026ldquo;Add\u0026rdquo; Operation to actually configure the workflow as usable action.\nWith this configuration vRealize Operations has everything it needs to automate tasks using vRealize Orchestrator workflows. The very last step is to configure such workflow-based actions in the according Recommendation definition and enable the automation withing the respective policy.\nOn execution the properly configured vRealize Orchestrator workflow receives the vRealize Operations alert ID as depicted in the next figure. This ID can be used for further improvements of the automated actions.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-5---log-insight/4.5.2-vrealize-operations/",
      "title": "2. vRealize Operations",
      "tags": [],
      "description": "",
      "content": "vRealize Operations Log Insight sports out of the box dashboards that visualizes security-related activities in your vRealize Operation. It also has a dashboard to help you watch and troubleshoot upgrade.\nAuthentication Analysis Let\u0026rsquo;s go through some of its contents in-depth.\nThere are two privileged login ID that customers have access that audit requires compliance reporting: root and admin. Other privileged account such as MaintenanceAdmin is not accessible. How many times do admin ID login with the wrong passwords in a specific period? The following chart counts each time a login failure happens.\nThe count is possible because Log Insights create a field out of the log entries. The field is named vmw_vr_ops_admin_attempt and that\u0026rsquo;s what plotted over time. I\u0026rsquo;m showing two examples of actual log entries, with value added context by Log Insight.\nThe log entries themselves are in turn filtered using the following query. Log Insight has awareness of vRealize Operations via the variable vmw_vr_ops_appname.\nvRealize Operations has 2 UI that are accessed via separate URLs. The Admin UI is for platform administration such as upgrading vRealize Operations, so it\u0026rsquo;s important to track login activities. How many failed login attempts made in the Admin UI is also provided out of the box.\nWe\u0026rsquo;ve covered admin. How about root? As this is a Linux account as opposed to vRealize Operations account, check the Linux content pack. The concept is the same.\nWhat IP address do they login from? This helps you trace the location of the user who used the account. The following chart shows 6 different users and when they log in. We can drill down to any of them to see the exact time and the IP address used.\nAlternatively, you can present in table format to show the IP address information. If you want the time stamp, use the Field Table feature.\nUsers addition, especially unexpected ones, can be a cause of security concern. Audit team may ask for the lists of users added in certain period. Users deletion is typically not an audit concern, but could be useful in troubleshooting. You can figure who deleted the user account and when.\nThe widgets in the third row of the dashboard covers users creation, import and deletion. By now you can guess that we can plot this event over time too. The following shows the list of user accounts that got deleted and when. I cut the fullname as that\u0026rsquo;s part of actual product validation.\nThe query that produces the above chart is the following. To some extend, it\u0026rsquo;s actually human-readable!\nInsufficient permission access logs events where users tried performing activities that they do not have sufficient privilege. The following shows some example where users were denied access.\nIf user has the access, you will see something like this\nThe widget \u0026ldquo;Security related message\u0026rdquo; is my personal favourite, as it demonstrate the adhoc troubleshooting ability of Log Insight. The following shows the many security related messages. They are grouped by the vRealize Operations nodes, so you can exclude certain types or zoom into a particular type.\nHow was the above achieved? The following shows the actual query. Log Insight automatically group log entries of similar type and give them a unique event_type. This means you can filter out the types that are not relevant, like what I have done below.\nActivity Audit Use this dashboard to select a user and audit that user\u0026rsquo;s actions. The type of actions you can audit are\nDashboards, Views and Reports. This covers creation, update, deletion, import, schedule (report) and generate (report).\nAlerts. This covers alert definition, symptom definition, notification rules and recommendation.\nEnvironment. This covers Application, Custom Data Center and Custom Group activities\nInventory. This covers resource creation, resource deletion, resource changes, collection start, collection stop, maintenance mode start, maintenance mode end.\nConfiguration. This covers changes in global setting, cost settings, credential, collector groups, etc.\nThe widgets are separated as in the menu of vRealize Operations Manager UI, so you can easily to orientate.\nLet\u0026rsquo;s go through some of its contents in-depth.\nThe query that produces the above chart is the following. I\u0026rsquo;ve excluded dashboard_add_tab from the category as it dominates the chart.\nLet\u0026rsquo;s drill down into a specific task. Let\u0026rsquo;s say we have some views deleted and we need to know who deleted them and when. For that, we select the view_definition_delete and add it. Log Insight will automatically add the field name and operator. No need to manually type!\nSince we\u0026rsquo;re down into a single activity, we can now plot the chart over time, grouped by the user. We can see here that the user is the system account maintenanceadmin.\nLet\u0026rsquo;s take another example from the dashboard. This time we will take user management, where you can track things like user deletion, role creation, user password change and many others. The following shows some of those activities.\nI\u0026rsquo;ve filtered out user_archive event as its value dominates the chart. As mentioned earlier, no need to manually type. Simply click on one of the log entries, choose a filter from the pop-up menu and that\u0026rsquo;s it!\nAs usual, you can have a table of who did what when.\nLet\u0026rsquo;s take one last example. I will take the configuration activity as it shows a range of interesting events. As usual, I started with a bar chart as it lets me see the activity name. We can see that changes in global settings dominate the result.\nWe already know how to filter it, so I\u0026rsquo;ll show you another way. Go to the Event Types. You\u0026rsquo;ll see the log entries grouped by type of events. To filter out, simply click on the X icon.\nOnce filtered out, the following is what I get. Let us know if there are events that you need to be logged that\u0026rsquo;s not trapped.\nThe query to get the above is complex\nvmw_vr_ops_category value:\n.*POLICY.*|super_metric_.*|disk_rebalance|collector_group.*|global_settings_set|GLOBAL_SETTINGS_OVERRIDE|dynamic_threshold_.*|license.*|DESCRIBE|CREDENTIAL_.*|CERTIFICATE_.*|MAINTENANCE_SCHEDULE_.*|WLP_.*|SCHEDULE_.*|RIGHTSIZING_.*|RECLAIM.*|OUTBOUND_.*|LOG_CONFIGURATION_.*|COST_.*|REFLIB_UPDATE Delete Activity Audit Let\u0026rsquo;s dive into \u0026ldquo;Deletion activity per resource\u0026rdquo; widget by opening it in Interactive Analytics page. You get the same information shown on the widget, but this time you can adjust it. I\u0026rsquo;ve made each time block to be 10 minute instead of 1 hour so I can see the changes better.\nNote that not all activities show the actual resource name being added/modified/deleted. In the following screenshot, I\u0026rsquo;ve highlighted in green where the affected resource name being shown, and in orange where it is not captured.\nAll the columns above are Log Insight field, a type of variable. Each extracted field has its own rules for extraction. Log Insight scans events and extracts fields whenever predefined patterns get matched. Let\u0026rsquo;s take vmw_vr_ops_username as an example, and shows its extraction formula.\nAll the VMware extracted fields are prefixed with vmw_ followed by the product name.\nWe\u0026rsquo;re now ready to evaluate the filters used in the preceding chart. It requires three filters working together, meaning they all must be true. It\u0026rsquo;s an AND operator, not an OR operator.\nThe first filter uses vmw_vr_ops_category field to filter out the events which were generated as a result to some kind of deletion.\nThe second filter uses filepath filter, a special system wide filter, to track the name and the path of the file from where events are collected. In vRealize Operations, all audit related events are collected from analytics.audit log files.\nThe last filter uses vmw_vr_ops_username field to exclude logs generated by service and system users. We have to exclude automation admin, maintenance admin, migration admin and system as they are not accessible by users.\nUpgrade Troubleshooting You can monitor the above stages as they progress via Log Insight. Yup, pretty much like watching a live streaming, as the logs are streamed into the Log Insight dashboard. The dashboard sports 9 widgets arranged in 4 rows.\nThe \u0026ldquo;Upgrade Range\u0026rdquo; widget shows when the upgrade started and when it completed. It covers the time range of the upgrade process. If the process was successful, you\u0026rsquo;ll see two columns, one marking the start and one marking the end, as shown in the following.\nThis widget is actually capable of monitoring multiple upgrades running in parallel. You can filter to only show the environment or nodes you are going to monitor by specifying their values in the fields vmw_vr_ops_clustername, vmw_vr_ops_hostname, and vmw_vr_ops_nodename.\nThe actual query to produce the chart is this.\nWhen you see \u0026ldquo;uploaded into reserved\u0026rdquo; that means the upgrade process has started. When you see \u0026ldquo;Completed operation CLEANUP for pakID\u0026rdquo; that means the upgrade process for that node has been completed successfully. The following shows examples of actual messages you should expect to see.\nThe \u0026ldquo;Overall events over time\u0026rdquo; widget is showing the proportion of all logs generated during the upgrade.\nThe \u0026ldquo;Overall errors, warnings and exceptions\u0026rdquo; widget is showing the proportion of all logs with errors, warnings and exceptions generated during the upgrade.\nThe second row of the dashboard shows 2 widgets. They cover the main two services responsible for upgrade: PAK Manager and CaSa. The widget monitoring errors, warnings and exceptions generated from that services.\nThe query is as the following:\nThe third row of the dashboard covers errors, warning and exceptions separately. Ensure that the spikes here are not unusual high.\nAn example of the errors during the upgrade:\nSome examples of warnings during the upgrade:\nAn example of the exceptions:\nErrors, warnings and exceptions may be not critical in this case and upgrade process may not be affected.\nThe last row contains the list of queries which are based on known Knowledge Base articles. Use it to check if a particular KB article is relevant in your environment. The last widget covers all log entries with exit code: 1. This is typically the reason for the failure of the upgrade process.\nCollection Troubleshooting vRealize Operations collect data every 5 minutes by default. For metric, it will store the value. For property, it will only store if there is a change. That means for metric, you should see a consistent collection every 5 minutes, something like this.\nIf you see missing dots, that means there is no metric stored. That could be because there is no metric to begin with (e.g. the VM is powered off) or there is a collection failure.\nIf you suspect a problem in collection, dive in \u0026ldquo;VMware - vROps 6.7+\u0026rdquo; content pack and go to the \u0026ldquo;Cluster - Collector Overview\u0026rdquo; dashboard. Check under \u0026ldquo;Collector Service shutdown events by Node, Role\u0026rdquo; widget and \u0026ldquo;Collector Service error events by node, role\u0026rdquo; widget and see if there are error messages.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-4---super-metrics/4.4.2-how-to-create-a-super-metric/",
      "title": "2. How to Create a Super Metric",
      "tags": [],
      "description": "",
      "content": "Step 1 From the main menu, click Administration and in the left pane click Configuration -\u0026gt; Super Metrics.\nClick on \u0026ldquo;Add\u0026rdquo; to start Super Metrics creation wizard.\nStart with a meaningful name for the super metric and description.\nYou may also assign a unit from the available drop-down list, if required. (available only from version 8.1)\nStep 2 Start with Selecting \u0026ldquo;Functions\u0026rdquo; from the drop-down options available, followed by \u0026ldquo;Object Type\u0026rdquo; or \u0026ldquo;Object\u0026rdquo; ( typing in the name brings up suggestive text which can be selected) and followed by Metric or Property to use ( typing in the key words of required metric or property brings up suggestive text which can be selected). Further, you may add any operators as required in the super metrics workspace.\n\u0026ldquo;CTRL + Space\u0026rdquo; keyboard shortcut will activate search for key words while typing in the super metrics workspace.\nBy default, any expression ends with depth=1, which means that the metric is assigned to an object that is one level above the referred object in the relationship chain. If you would need to assign super metric to higher levels, accordingly, the depth level needs to be increased. For example, if you are creating a super metric to find maximum value of CPU Usage on all VMs in the vSphere World, the super metric which is created based on VM metric with \u0026ldquo;max\u0026rdquo; function will need to be applied on vSphere World object and with Depth=5 in the expression. The depth can also be negative, this happens when you need to aggregate the parents of a child object. For example, when aggregating all the VMs in a datastore, the metric expression ends with depth=-1, because VM is a parent object of datastore.\nOther options available in the page are:\nPreview: Shows the values of a super metric against any object without needing to save and apply.\nLegacy: This mode switches to the template to create a super metric formula without the suggestive text as it used to be in version 7.0 or older.\nStep 3 Add the object(s) to which the super metric needs to be applied.\nStep 4 The last step of creating super metric is to apply to relevant policy or policies.\nOnce the super metric is enabled, it will take one or two collection cycles (5-10 minutes) to start seeing the super metric for the object. For the assigned object, you will see all the super metrics applied under All Metrics -\u0026gt; Super Metric.\nAn example is shown below:\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-3---sddc-vs-iaas/4.3.2-sddc-vs-hddc/",
      "title": "2. SDDC vs HDDC",
      "tags": [],
      "description": "",
      "content": "We covered how a VM differs drastically to a physical server. Now let\u0026rsquo;s take a look at the big picture, which is at the data center level. A data center consists of three major functions-compute, network, and storage. Security is not a function on its own, but a key property that each function has to deliver. We use the term compute to represent processing power namely CPU and Memory. In today\u0026rsquo;s data centers Compute is also used when referencing converged infrastructure, where the server and storage have physically converged into one box. The industry term for this is Hyper-Converged Infrastructure (HCI). You will see later in the book that this convergence impacts how you architect and operate SDDC.\nVMware has moved to virtualize the network and storage functions as well, resulting in a data center that is fully virtualized and thus defined in the software. The software is the data center. This has resulted in the term SDDC. The book will make extensive comparison with the physical data center. For ease of reference, let\u0026rsquo;s call the physical data center Hardware-Defined Data Center (HDDC).\nIn SDDC, we no longer define the architecture in the physical layer. The physical layer is just there to provide resources. These resources are not aware of one another. The stickiness is reduced, and they become a commodity. In many cases, the hardware can even be replaced without incurring downtime to the VMs running on top.\nThe next diagram shows one possibility of a data center that is defined in the software. We have drawn the diagram to state a point, so don\u0026rsquo;t take this as the best practice for SDDC architecture. In the diagram, there are many virtual data centers (we draw three due to space in the book). Each virtual data center has its own set of virtual infrastructure (server, storage, network and security). They are independent of one another.\nA virtual data center is no longer contained in a single building bound by a physical boundary. Although long distance WAN bandwidth and latency are still limiting factors in 2021, the main thing here is you can architect your physical data centers as one or more logical data centers. You should be able to automatically, with just a few clicks in VMware Site Recovery Manager, move thousands of servers from data center A to data center B; alternatively, you can perform DR from four branch sites to a common HQ data center.\nIn our example, the virtual data centers run on top of two physical data centers. Large enterprises will probably have more than that (whether it is outsourced or not is a different matter). The two physical data centers are completely independent. Their hardware is not dependent on one another.\nIn the Compute function, there is no stretched cluster between 2 physical sites. Each site has its own vCenter. There is no need to protect vCenter with DR.\nIn the Network function, there is no stretched VLAN between 2 physical sites. You do not have to worry about spanning tree or broadcast storm hitting multiple data centers. The physical sites can even be on a different network. Site 1 might be 10.10.x.x network, while Site 2 might be 20.20.x.x.\nIn the Storage function, there is no array-based replication. Replication can be done independently from a storage protocol (FC, iSCSI, or NFS) and VMDK type (thick or thin). vSphere has built-in host-based replication via TCP/IP, named simply vSphere Replication. It can replicate individual VMs, and provides finer granularity than LUN-based replication. You might decide to keep the same storage vendor and protocol, but that\u0026rsquo;s your choice, not something forced upon you.\nWe have drawn two vendors for each layer to show the message that hardware does not define the architecture. They are there to support the function of that layer (for example, Compute Function). So, you can have 10 vSphere clusters: 3 clusters could be Vendor A, and 7 clusters could be Vendor B.\nWe are taking the \u0026ldquo;shared-nothing architecture\u0026rdquo; approach. This is a good thing, because you contain the failure domain. Ivan Pepelnjak, an authority on data center networking architecture, states here that \u0026ldquo;Interconnected things tend to fail at the same time.\u0026rdquo;\nLet\u0026rsquo;s summarize the key differences between SDDC and HDDC. To highlight the differences, We\u0026rsquo;re assuming in this comparison the physical data center is 0% virtualized and the virtual data center is 100% virtualized. For the virtual data center, we\u0026rsquo;re assuming you have also adjusted your operation, because operating a virtual data center with a physical operation mindset results in a lot of frustration and suboptimal virtualization. This means your processes and organization chart have been adapted to a virtual data center.\nAs data center wide Disaster Recovery (DR) is the litmus test that defines whether your data center is HDDC or SDDC, let\u0026rsquo;s start with this.\nHDDC SDDC Data center migration is a major and expensive project. The entire Virtual DC can be replicated and migrated. We have a customer who performed long distance vMotion over 8 weekends, hence achieving data center migration with 0 downtime. Architecturally, DR is done on a per-application basis. Every application has its own bespoke solution. DR is provided as a service by the platform. It is one solution for all applications. This enables data center-wide DR. The standby server on the DR site is required. This increases the cost. Because the server has to be compatible with the associated production server, this increases complexity in a large environment. No need for a standby server. The vSphere cluster on the DR site typically runs the non-production workload, which can be suspended (hibernate mode) during DR. The DR site can be of a different server brand and CPU. DR is a manual process, relying on a run book written manually. It also requires all hands on deck. An unavailability of key IT resources when disaster strikes can impact the organization\u0026rsquo;s ability to recover. The entire DR steps can be automated. Once management decides to trigger DR, all that needs to be done is to execute the right recovery process in VMware Site Recovery Manager (SRM). No manual intervention. A complete DR dry run is rarely done, as it is time consuming and requires production to be down. A DR dry run can be done frequently, as it does not impact the production system. This is made by possible by having a virtual network that isolate the VMs participating in DR dry run. As a result, the dry run can even be done on the day before the actual planned DR. The report produced after a DR exercise is manually typed. It is not possible to prove that what is documented in the Microsoft Word or Excel document is what actually happened in the data center. The report is automatically generated, with no human intervention. It timestamps every step, and provides a status whether it was successful or not. The report can be used as audit proof Compute Function HDDCSDDC1,000 physical servers (just an example, so we can provide a comparison).The number of VM will be more than 1,000. It may even reach 2,000 VMs . The number of VMs is higher for multiple reasons: VM sprawl; the physical server tends to run multiple applications or instances whereas VM runs only one; DR is much easier and hence, more VMs are protected.Growth is relatively static and predictable, and normally it is just one way (adding more servers).The number of VMs can go up and down due to dynamic provisioning.Downtime for hardware maintenance or a technology refresh is a common job in a large environment due to component failure.Planned downtime is eliminated with vMotion and storage vMotion.5% to 10% average CPU utilization, especially in the CPU with a high core count.~50% utilization for both VM and ESXi.Racks of physical boxes, often with a top-of-rack access switch and UPS. The data center is a large consumer of power.Rack space requirements shrink drastically as servers are consolidated and the infrastructure is converged. There is a drastic reduction in overall space and power, although power consumption per rack is higher.Low complexity. Lots of repetitive work and coordination work, but not a lot of expertise required.High complexity. Less quantity, but deep expertise required. A lot less number of people, but each one is an expert.Availability and performance monitored by management tools, which normally uses an agent. It is typical for a server to have many agents.Availability and performance monitoring happens via vCenter Server, and it's agentless for the infrastructure. All other management tools get their data from vCenter Server, not individual ESXi or VM. Application-level monitoring is typically done using agents within the Guest OS.The word cluster generally means two or more servers joined with a heartbeat and shared storage, which is typically SAN.\nIn another context, the word cluster means a single application using shared-nothing hardware. A typical example here is Hadoop cluster.\nThe word cluster has a different meaning. It's a group of ESXi hosts sharing the workload. Normally, 8 to 16 hosts, not 2 - 4.High Availability (HA) is provided by clusterware, such as Microsoft MSCS and Veritas. Every cluster pair needs a shared storage, which is typically SAN. Typically, one service needs two physical servers with a physical network heartbeat; hence, most servers are not clustered as the cost and complexity is high.HA is provided by vSphere HA. All VMs are protected, not just a small percentage. The need for traditional clustering software has reduced, and a new kind of clustering software emerges. It has full awareness of virtualization, and integrates with vSphere using vSphere API.Fault Tolerance is rarely used due to cost and complexity. You need specialized hardware to achieve it.Fault tolerance is an on-demand feature as it is software-based. For example, you can temporarily turn it on during batch jobs run.Anti-Virus is installed on every server. Management is harder in a large environment.Anti-Virus runs as an Agent VM per ESXi Host. It is agentless to the Guest OS and hence, is no longer visible by malware. A popular solution is Trend Micro Deep Security.\rStorage Function HDDC SDDC 1,000 physical servers (just an example, so we can provide a comparison), where IOPS and capacity do not impact each another. A relatively static environment from a storage point of view because normally, only 10 percent of these machines are on SAN/NAS due to cost. It has a maximum of 2,000 interdependent VMs, which impact one another. A very dynamic environment where management becomes critical because almost all VMs are on a shared storage, including distributed storage. Every server on SAN has its own dedicated LUN. Some data centers, such as databases, may have multiple LUNs. Most VMs do not use RDM. They use VMDK and share the VMFS or NFS datastore. The VMDK files may reside in different datastores. Storage migration is a major downtime, even within the same array. A lot of manual work is required. Storage migration is live with storage vMotion. Intra-array is faster due to VAAI API. Backup, especially in the x64 architecture, is done with backup agents. As SAN is relatively more expensive and SAN boot is complex at scale, backup is done via the backup LAN and with the agent installed. This creates its own problem as the backup agents have to be deployed, patched, upgraded, and managed. The backup service is provided by the hypervisor. It is agentless as far as the VM is concerned. Most backup softwares use VMware VADP API to back up by taking snapshot. Windows Volume Shadow Services (VSS) provides application-consistent backups through quiesing application during backup execution. Non-VSS environments can use pre-post thaw scripts to stop necessary services prior to VM snapshot to provide crash-consistent backups of applications and underlying OS. The backup process creates high disk I/O, impacting the application performance. Because the backup traffic is network intensive and carries sensitive data, an entire network is born for backup purposes. Because backup is performed outside the VM, there is no performance impact on the application or Guest OS. There is also no security risk, as the Guest OS Admin cannot see the backup network. Storage\u0026rsquo;s QoS is taken care of by an array, although the array has no control over the demand of IOPS coming from servers. Storage\u0026rsquo;s QoS is taken care of by vSphere Storage I/O Control, which has full control over every VM. Network Function HDDC SDDC The access network is typically 1 GE, as it is sufficient for most servers. Typically, it is a top-of-rack entry-level switch. The top-of-rack switch is generally replaced with the end-of-row distribution switch, as the access switch is completely virtualized. ESXi typically uses 10 GE, with some having 4x 10 GE connection. VLAN is normally used for segregation. This results in VLAN complexity. VLAN is not required (traffic within the same VLAN can be controlled) for segregation by NSX. Impacted by the spanning tree. No Spanning Tree. A switch must learn the MAC address as it comes with the server. No need to learn the MAC address as it\u0026rsquo;s given by vSphere. Network QoS is provided by core switches. Network QoS by vSphere and NSX. DMZ Zone is physically separate. Separation is done at the IP layer. IDS/IPS deployment is normally limited in DMZ due to cost and complexity. DMZ Zone is logically separate. Separation is not limited to IP and done at the hypervisor layer. IDS/IPS is deployed in all zones as it is also hypervisor-based. No DR Test network is required. As a result, the same hostname cannot exist on DR Site, making a true DR Test impossible without shutting down production servers. DR Test Network is required. The same hostname can exist on any site as a result. This means DR Test can be done anytime as it does not impact production. Firewall is not part of the server. It is typically centrally located. It is not aware of the servers as it\u0026rsquo;s completely independent from it. Firewall becomes a built-in property of the VM. The firewall policy follows the VM. When a VM is vMotion-ed to another host, the policy follows it and is enforced by the hypervisor. Firewall scales vertically and independently from the workload (demand from servers). This makes sizing difficult. IT ends up buying the biggest firewall they can afford, hence increasing the cost. Firewall scales horizontally. It grows with demand, since it is deployed as part of the hypervisor (using NSX). Upfront cost is lower as there is no need to buy a pair of high-end firewall upfront. Traffic has to be deliberately directed to the firewall. Without it, the traffic \u0026ldquo;escapes\u0026rdquo; the firewall. All traffic passes the firewall as it\u0026rsquo;s embedded into the VM and hypervisor. It cannot \u0026ldquo;escape\u0026rdquo; the firewall. Firewall rules are typically based on the IP address. Changing the IP address equals changing the rules. This results in a database of long and complicated rules. After a while, the firewall admin dare not delete any rules as the database becomes huge and unmanageable. Rules are not tied to the IP address or hostname. This makes rules much easier. For example, we can say that all VMs in the Contractor Desktop pool cannot talk to each other. This is just one rule. When a VM gets added to this pool, the rule is applied to it. Load Balancer is typically centrally located. Just like the firewall, sizing becomes difficult and the cost goes higher. Load Balancer is distributed. It scales with the demand. Adding hypervisor means adding load balancer capacity. People \u0026amp; Process How many people does it take to manage 1 rack worth of hardware?\nYour answer is likely \u0026ldquo;not many.\u0026rdquo; After all, it is just 1 standard rack. The entire thing barely occupies a small server room.\nIf your entire data center can fit inside 1 standard rack of equipment, that makes a small operation. It is indeed a small operation in physical world. However, in SDDC, you can achieve 2000 VM per rack from performance point of view. We are using a standard 30:1 consolidation ratio, which is possible with the latest Intel or AMD. From networking viewpoint, Ivan Pepelnjak has in fact shared back in October 2014 that \u0026ldquo;2000 VMs can easily fit onto 40 servers\u0026rdquo;. He elaborates the calculation here. He further updates that in November 2015.\nThe above calculation takes into account your Infrastructure VM. Infrastructure functions that used to be provided by hardware (e.g. storage replication, firewall, load balancer) are now delivered as VM. You may run 100 of such VMs, depending on the type of services that your SDDC needs to provide.\nHDDC SDDC There\u0026rsquo;s a clear silo between the compute, storage, and network teams. In organizations where the IT team is big, the DR team, Windows team, and Linux team could also be separate teams. There is also a separation between the engineering, integration (projects), and operations (business as usual) teams. The team, in turn, needs layers of management. This results in rigidity in IT. With virtualization, IT is taking the game to the next level. It\u0026rsquo;s a lot more powerful than the previous architecture. When you take the game to the next level, the enemy is also stronger. In this case, the expertise required is deeper and the experience requirement is more extensive. Relatively more headcount required in IT, with lower skills set. Earlier, you may have needed 10 people to manage 1,000 physical servers. With virtualization, you might only need three people to manage 2,000 VMs on 50 ESXi hosts. However, these 3 people have deeper expertise and longer experience than the 10 people combined. DevOps is a concept that applies to developers or application team. It does not apply to Infrastructure team. The IaaS team needs to have its own \u0026ldquo;DevOps\u0026rdquo; too. As the infrastructure becomes software, there is a need for continuous flow from Architect -\u0026gt; Engineer -\u0026gt; Implement -\u0026gt; Operate -\u0026gt; Upgrade I\u0026rsquo;ll end this chapter with a From the main menu, click Administration and in the left pane click Configuration -\u0026gt; Super Metrics.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-1---quiz-answers/4.1.2-part-2-metrics/",
      "title": "2. Part 2 - Metrics",
      "tags": [],
      "description": "",
      "content": "VM CPU Demand The reason why Demand metric jumps while Usage drops is contention. The VM experiences contention, which includes hyperthreading sharing. I should have included the screenshot of CPU Ready, CoStop, Overlap, VM Wait and Swap Wait.\nFrom the chart you can see that the formula for VM CPU Contention \u0026gt; Demand - Usage. Contention (%) is around 20% when Demand is 25% and Usage is 15%. The reason is Contention accounts for both CPU frequency and hyper threading, while the difference between Demand and Usage is hyper-threading.\nVM CPU vs ESXi CPU Metrics At the start of the test The VM runs 12 vCPU, but each vCPU was pinned to each ESXi core. So all cores are 100% utilized, but each running 1 thread.\nVM CPU Run (ms) is 240K milliseconds, which is 20K milliseconds x 12 (half of its 24 vCPU).\nVM CPU Used (ms) is also at 240K milliseconds. There is no loss from overlap, the VM does not do much IO, and no efficiency loss/gain due to HT.\nVM CPU Usage is 50%.\nSo at this point, all 3 counters of VM CPU are 50%.\nThe counter at ESXi tells a different story. The ESXi Core Utilization (%) immediately went up to 100% while Utilization went up to only 50%. The reason is Core Utilization measures whether the core is used or not. It\u0026rsquo;s unaware of HT.\nUsage (%) is identical to Core Utilization in this case.\nOn the other hand, ESXi Utilization (%) looks at if each thread HT is running or not. It does not care about the fact that the 2 threads share a core, and simply roll up to ESXi level directly from thread level. This is why it\u0026rsquo;s showing 50% as it only cares whether a thread is running or not, at any point in time.\nDuring Ramp Up period VM is being ramped up steadily. You can see all 3 counters went up in steps.\nVM CPU Run (ms) ramps up from 240K to 480K. All 24 vCPU has 20K ms value, which equals to 100%.\nVM CPU Used (ms) barely moved. From 240K to 300K. That\u0026rsquo;s 1.25x, demonstrating that Used understands HT only delivers 1.25x throughput.\nVM CPU Usage (%) ramp up from 50% to 62.5%, also demonstrating awareness of contention due to HT.\nUsed (ms) = Usage (%)\nESXi CPU Usage (%) counter stayed flat at 100%. The reason is all 12 cores were already busy. That means VM CPU Usage (%) is aware of HT, but ESXi CPU Usage (%) is not.\nESXi CPU Core Utilization (%) matches VM Run. Both went 2x.\nTowards the end of the run VM CPU Run is at 480K ms. This counter is suitable for VM Capacity sizing, as it correctly accounts that each vCPU is used by Guest OS.\nVM CPU Used is at 300K milliseconds, which is 62.5%\nVM CPU Usage (%) is at 62.5%. On average, each of the VM vCPU only gets 62.5%. If you use this for your VM capacity, you will get the wrong conclusion as it\u0026rsquo;s already running 100%\nESXi CPU Usage (%) is at 100%. This makes it suitable from Capacity viewpoint, albet too conservative. It is not suitable from Performance, as you can not tell if there is still room.\nESXi CPU Utilization (%) is at 100%. Because it tracks the ramp correctly, it can be used from Performance. You can use it for Capacity, but take note that 100% means you get performance hit from. In fact, at 50% the HT effect will kick in.\nVM Active Memory Active is lower than Consumed and Guest OS In Use counters because they do not actually measure how actively the page is used. They are measuring the disk space used, so it contains a lot of inactive pages. You can see it in the general pattern of Consume and Guest OS used counters. The following is vRealize Operations appliance VM. Notice how stable the metrics are, even over millions of seconds.\nESXi CPU Contention vs Utilization These are the reasons why they don\u0026rsquo;t match:\nOne looks at physical CPU, the other the virtual CPU. One looks at ESXi, while the other looks at VM. Limit may impact the VM, either directly or via resource pool CPU pinning, although this is rarely happen Unbalanced utilization. There are many VMs in this host. Their experience will not be identical. Mystery of VM Memory This behaviour confuses me so if you know the answer let me know please. This 64-bit CentOS VM runs My SQL and is configured with 8 GB of RAM. However, a limit is set at 2 GB hence you saw consumed does not exist 2 GB.\nCan you explain the dip in Consumed at around 9:30 pm? It went down from 2.09 GB to 1.6 GB, and then slowly going back up. Why did it suddenly consume 400 MB less in the span of 20 minutes? Both the configured limit and the runtime limit do not change. They are main at a constant 2 GB. This makes sense, else the Consumed would not be able to slowly go up again.\nMy guess is there must be activity by the VM and pages were compressed to make room for the newly requested pages. The Non Zero Active counter shows that there are activities.\nThe pages that are not used must be compressed or swapped. The Swapped value is negligible, but the Compressed metric shows the matching spike.\nBut what puzzles me is why did balloon go down by around 400 MB but then goes up immediately?\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-9---other-dashboards/3.9.2-multi-tier-applications/",
      "title": "2. Multi-Tier Applications",
      "tags": [],
      "description": "",
      "content": "A business application typically spans multiple tiers, with each tier consisting of multiple VMs. I\u0026rsquo;ve worked with a large telco application spanning 5 tiers and 120 VMs. Since you typically have multiple business applications, you need a quick way to check the overall health before diving into each tier and VM.\nWhile all production applications are important, some are definitely more important than others. You monitor these critical applications 24 x 7, display them on the big screen, and want to be ahead of your customers in detecting their health. The health of the apps should be color coded for ease of visualization on the NOC screen.\nThere are 3 parts that make up the health of an application:\nIs it up? Is it fast? Is it secured? The following dashboard focuses on Performance. To some extent, if the Guest OS is down, the dashboard below will detect it. If you enhance it to include availability and compliance, let me know!\nA multi-tier application can suffer from either horizontal or vertical problem:\nBy horizontal, I mean a tier has problem. When the web tier is slow, it can slow down the entire application. The speed of a convoy is determined by the slowest car. By vertical, I mean something that cut across tier. Storage, for example. If the slowness is caused by something common, there is no need to troubleshoot individual VM, as they are simply victim. That means we need to check both angles when an application had performance problem:\nWhich tier had the problem? Since when? How bad? What was the problem? What infra problem did the app had? Storage, Network, CPU, RAM? The above check makes a good starting point in your analysis. Don\u0026rsquo;t zoom into a particular VM until you know the overall picture. No point firefighting the kitchen if the whole house is on fire.\nLogical Design The following is the logical design of the dashboard. I\u0026rsquo;ve not include the vertical problem to keep it simple.\nAt the top of the dashboard, the list of critical applications is shown across. The logical design shows 6. The actual dashboard can handle more. I\u0026rsquo;ve seen a large customer showing forty, as the list is just limited by your screen real estate.\nIf an app is not green, you can click on it. The dashboard will list all its VMs automatically. It\u0026rsquo;s plotting a line chart, so you can see the history. You can see how long, how bad and how often the problems happen. This is why I prefer line chart over a single number. A single number hides too many things, and can result in false impression.\nKPI Modelling First step in performance dashboard is modelling the KPI. This is required so we show a single number for each business applications, and then drill down from it.\nThe health of a tier is the average health of its member. This is because a tier scales out. We are not taking the minimum value. This is not a convoy.\n\u0026ldquo;Hold on!\u0026rdquo; you might say. Since it is scale out, App Team has catered for this. If they only need 3 web servers, they will deploy 4 or even 5. So both performance and availability are not affected if one web server goes down. The tier performance has to take into account this extra capacity, and not simply doing an average.\nThis logic sounds reasonable. But is it correct?\nIt is not actually. This is not about Availability. This is about Performance. All web servers are still up, but if node no 4 is slower than usual, user experience will be affected.\nThe VM KPI is turn an aggregation of its key performance metrics. As each metric has their own units, we need to convert them into a unit-less range. I picked 0 - 100 range as that\u0026rsquo;s easier to understand.\nThe threshold is designed to support proactive, not alert based operations. Hence, the red range does not mean emergency and you must drop everything. It means you need to take a look within the next 24 hours.\nResult Using vRealize Operations 8.2, the dashboard looks like the following:\nThe top part of the dashboard shows 4 mission critical applications. Each of them is color coded for ease of visualization. Selecting one of them will automatically shows the trend chart of each tiers in the app. In the example above, I\u0026rsquo;ve selected one of the business applications. I did not have enough space for the VMs, so I\u0026rsquo;ve placed the VMs in the selected tier below the tier. I selected the DB Tier, which had 5 VM (4 of them being shown below). Selecting any of the VM will show all the KPI that make up the VM. There are 28 counters that make up the VM KPI, and we can quickly see that Free Memory has turned from green to yellow.\nImplementation You can create your own object and assign metrics to it in vRealize Operations. In the following screenshot, I\u0026rsquo;ve created Tiered Applications object, which has the Application Tier object as its children.\nYou set the relationship making the Application Tier object as the group member. In the following screenshot, notice the group membership is dynamic. If you follow a naming convention, you will not need to hardcode each member one by one. The number of members can be dynamic.\nFor the KPI metrics, you will need three super metrics. The first one is at the business application object. This is simply the minimum of its tier KPI.\nThe second super metric is assigned to the application tier object. The formula is simply the average of its member VM KPI.\nThe third and last super metric is the KPI of each VM. I use a nested IF Statement to assign each value to the respective color.\nI added the blue line. It sets the value to 100 when it\u0026rsquo;s detecting -1.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-8---true-visibility-suite-dashboards/3.8.2-cisco-ucs-fabric-interconnect/",
      "title": "2. Cisco UCS Fabric Interconnect",
      "tags": [],
      "description": "",
      "content": "The Cisco UCS Fabric Interconnect Details dashboard is used by System Administrators (SAs) to find Fabric Interconnects (FIs) with the most traffic. It is used in cooperation with the other dashboards in the vRTVS management pack for Cisco UCS to troubleshooting problems and find busy FIs and FI Ports, both ethernet and fiber channel.\nThis is a custom dashboard. You can download it here on VMware {code}:\nThe Cisco UCS Fabric Interconnect Details dashboard was designed to show traffic flowing through FIs. By many SAs, FIs are considered the most important piece of the Cisco UCS architecture. Acting as a gateway from the UCS hardware itself (chassis, blades, etc), the FIs serve as a network switch distributing both ethernet and fibre channel traffic out to networks.\nHow to Use The top two rows provide the user with Top-N widgets showing which FIs are more heavily used. Both ethernet and fibre channel traffic are shown here.\nI\u0026rsquo;ve included the Management IP and Power Status for each FI for ease of use, giving the consumer visibility into each property. I\u0026rsquo;ve taken the default blue/grey colors to avoid red/yellow/green, but the user can adjust as they wish. Simply edit the widget and go here.\nThe second half of the dashboard includes three views, showing the FIs and their ethernet and fiber channel ports.\nI\u0026rsquo;ve configured these such that the user will select an FI which will drive the other five widgets. The widget interaction looks like this.\nIt\u0026rsquo;s important to note that Ethernet Ports and Fiber Channel Ports are children of the Fabric Interconnect. This is documented here in the TVS guide.\nIt can be seen visually by going to the FI Summary Page and exploring the Metrics tab.\nYou\u0026rsquo;ll notice the FI above has several child objects, Ethernet Ports and Fiber Channel Ports are the two we are interested in there from a traffic perspective.\nLooking in detail at the FI and Port Views, the user is presented with Health, Power Status, Admin State, Operational State, and other metrics to provide some detail around each object.\nYou\u0026rsquo;ll notice that I\u0026rsquo;ve used custom colors in the underlying Views to highlight degraded Health, Power Status, Admin State, and Operational State. The user can adjust these colors and thresholds in the Views themselves, here\u0026rsquo;s the Cisco UCS FI Details View.\nI\u0026rsquo;ve configured the Ethernet Port and Fiber Channel Port Views to auto select the first row, such that their respective Scoreboard widgets are populated upon selection of the FI.\nLooking at the Scoreboards in detail gives the user visibility into both current and historic traffic details. This will allow the user to determine if/when traffic started to increase or decrease. Hovering over any metric gives the user the same ability to see more detail described previously in the MS SQL section.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-7---executive-summary-dashboards/3.7.2-inventory-summary/",
      "title": "2. Inventory Summary",
      "tags": [],
      "description": "",
      "content": "This dashboard is used by the Ops team to provide insight the IT Management team on the inventory. This dashboard works together with the Capacity Summary dashboard. The inventory provides details on available resources and what is running on these resources. The capacity provides details on the resources remaining capacity and time remaining to act.\nSee the Executive Summary Dashboards page for common design consideration among all the dashboards for IT senior management.\nHow to Use The dashboard is designed top down, starting with a banner scoreboard.\nThe Summary scoreboard provides a quick view into the key inventory numbers.\nThe scoreboard is interactive. It drives both the following 3 tables and the 8 pie charts under the table. The table in turn drive the 8 pie charts. It looks complicated in static image, but feels natural when used as you will expect the interaction.\nSince all the information is at vSphere World level, clicking any of them will show break down of this total inventory. The Datacenter table lets you drill down, showing the clusters and storage in the DC.\nSelect a data center from the \u0026ldquo;Data centers\u0026rdquo; table. It drives Clusters and Datastores, so that you can quickly view what you have in a given Data center and related capacity.\nFor a small environment, the vSphere World is provided so you can see all the VMs in the environment.\nTo sort by any of the columns in the table, simply click on the column title.\nAbout the 8 pie charts\nThey provide break down of the inventory. They are driven by 3 tables above them and by the Summary scoreboard Points to Note Be aware of the relationship hierarchy in vSphere. For example, Compute (Cluster) is not a parent of Storage (Datastore), so logically it is not possible to display Datastores in a Cluster. Data centers consist of Compute (Cluster), Network (Distributed Switch), and Storage (Datastore). If you have screen real estate, add Network. Datastores do not drive the pie chart Widgets. This is a known limitation in the View Widget as it can\u0026rsquo;t handle multiple traversal spec. If your senior management wants to see the largest VM in a given environment, add a Top-N widget to list Top 10 largest consumers so that CPU, Memory, Disk details are highlighted. If required, you can drill down into specific cluster or datastore for performance. You need to build the dashboard to dashboard navigation. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-6---noc-dashboards/3.6.2-live-cluster-performance-dashboard/",
      "title": "2. Live! Cluster Performance Dashboard",
      "tags": [],
      "description": "",
      "content": "This dashboard provides live information on whether the requests of the VMs are met by their underlying compute clusters. This dashboard focuses on the compute resources (CPU or Memory), and show if the cluster is performing well (i.e. meeting the demand). Use this dashboard to view if there is any problem in meeting the demands of the VMs.\nThis the primary dashboard for performance. It is complemented by the Live! Cluster Performance dashboard. This secondary dashboard complements it by showing if the performance problem (read: contention) was caused by high utilization. The primary dashboard answers the question \u0026ldquo;Is our IaaS performing?\u0026rdquo;, while the secondary dashboard answers the question \u0026ldquo;Is our IaaS working hard?\u0026rdquo;.\nDesign Consideration The dashboard shows 3 heat maps side by side. They complement each other and should be used together. The location of each cluster and ESXi hosts within those clusters is identical in all heat maps. This fixed positioning enables viewers to compare if the problem is caused by memory contention, CPU ready or CPU CoStop.\nThe size of each cluster and ESSi hosts are designed to be constant. Variable sizing creates a distraction, as the focus here is not capacity. Variable sizing can potentially result in small boxes, making it hard to read from a far.\nThe focus of performance is on population, not a single VM. This is not a single VM troubleshooting dashboard. We are looking at infra problem, not a single VM problem. As the infra counter is mathematically an aggregation of VM counters, we need to pick the right roll up strategy. As the goal is to provide early warning, we\u0026rsquo;re not using average as the roll up technique, as it is too late as early warning. We use percentage of population exceeding a threshold. The threshold is set to be stringent so we can get early warning.\nHow to Use Look at the 3 heat maps and see if there is any color other than green.\nWhile each box is an ESXi, the counter is coming from all the VM in the host. It\u0026rsquo;s not taking ESXi level counter at all. The counters used are % VMs facing CPU Ready, % VMs facing CPU CoStop, % VMs facing RAM Contention. The color is by percentage of VMs not being served well. We are not using Max among the VM as it\u0026rsquo;s too extreme, placing too much focus on a single VM. On the other hand, we\u0026rsquo;re not doing ESXi wide average, as that will be too late. Green indicates that almost 100% of the VMs are getting the CPU and memory they are asking. The threshold is set such that if 10% of the VM population is not getting the resources they are asking, the heat map will turn full red. Red indicates an early warning. Stringent thresholds are used to enable proactive attention \u0026amp; remediation operations. Because high standard is applied, it is possible that the heat map is showing red, but there is no complaint from VM owner yet. Light grey likely means there is no VM running on the host, hence the metric is not computing. Check if there is unbalanced.\nThere are 2 types of unbalanced: cluster unbalance and resource type unbalance The ESXi hosts are grouped together by the cluster, so unbalanced within a cluster can be seen easily. Cluster unbalance is a real possibility that is best monitored and not just assumed. If the 3 heat maps are quite different, there is resource unbalanced. For example, if the memory contention is mostly red, but the 2 CPU heat maps are green, that means you have unbalance between memory and CPU. If a single ESXi host is displaying a different color across 3 heat maps, it indicates imbalance between CPU and memory resources in the host. For NOC Operator, drill down by selecting one of the ESXi on the heat map\nThe \u0026ldquo;Trends of selected ESXi Host\u0026rdquo; will automatically show the performance counters It\u0026rsquo;s showing from all 3 heat maps, so you can correlate. To hide any metric, simply click on its name on the legend. As part of the deployment, it is best that you configure auto rotate among the NOC dashboard. If you only want to show 1 dashboard, you can remove vRealize Operations menu by using URL sharing feature. This will make the overall UI clean, enabling viewers to just focus on the dashboard.\nPoints to Note If you have the screen real estate, add a Heat Map for Disk Latency. Use the counter \u0026ldquo;Percentage of Consumers facing Disk Latency (%)\u0026rdquo;. It is part of datastore object, not cluster, as a VM in a cluster can have disks across multiple datastores. Organize this storage performance by data center and not by cluster.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-5---availability-dashboards/3.5.2-vsphere-availability/",
      "title": "2. vSphere Availability",
      "tags": [],
      "description": "",
      "content": "There are two layers of Availability, that is, the Consumer layer and the Provider layer. The vSphere Availability dashboard covers the Provider layer. This dashboard includes a cluster and not an ESXi host because the cluster is operationally a single compute provider. This dashboard considers the N+1 design, where the cluster can withstand one host failure. Logically, a cluster with fewer hosts has a higher risk.\nThe dashboard is designed to help you analyze and report the uptime, as availability is typically part of official business SLA. It\u0026rsquo;s also often required in the monthly operational summary report.\nThe dashboard is not designed for live monitoring of the uptime. An NOC style of dashboard is better suited for that use case. Tools such as vRealize Log Insight should also be leveraged as fault is typically preceded with soft errors.\nHow to Use The table Clusters lists all the clusters in your environment. In a very large environment, creating a filter for the list of clusters can make it more manageable. One is is to group the clusters by their class of services. Group your clusters into Gold, silver, and bronze and default the selection to Gold. In this way, you can see your Gold clusters more easily.\nIt is sorted by the lowest uptime, so your attention is drawn to the cluster with the lowest uptime in the last 1 month. The column is based on the average of the last 1 month as availability SLA is should be calculated per month (but reported much more frequently).\nThe metric used is Summary \\ Cluster Availability (%), which assumes N+1 design. That means if there is 1 node failure, the metric is still showing 100%.\nThe column Running Hosts are color coded as logically a smaller cluster has higher risk. A single host failure results in relatively higher capacity degradation.\nThe column vSAN? is added as hyper-converged means you need to consider both the compute part and the storage part.\nThe Admission Control Policy is based on the property Cluster Configuration \\ DAS Configuration \\ Active. The mapping between code to name is:\n-1 = Disabled 0 = Cluster Resource percentage 1 = Slot Policy (Powered-on VMs) 2 = Dedicated Failover Hosts The cluster failover percentage columns map to the following values in vCenter client UI.\nSelect a cluster from the above\nThe cluster uptime will be automatically plotted. It\u0026rsquo;s using 25%, 50%, and 75% as the threshold for red, orange and yellow respectively. The reason for low threshold is the 5 minute window. A complete 5 minute downtime is only 0.0116% when measured against a 30-day SLA. If the uptime was 100%, it will only go down to 99.9884% The ESXi in the selected cluster table will be automatically filled up. For more context, you can add a property widget that lists the selected ESXi Host properties. The \u0026lsquo;Connected to vCenter\u0026rsquo; and \u0026lsquo;Maintenance State\u0026rsquo; columns are not the average values, as both are string. However, they display the last state in the selected period. This allows you to go back to a specific point in time and view availability at that point. About the \u0026ldquo;Datastore not available\u0026rdquo; list\nIt filters to only those datastores with status powered off. This covers both local and shared datastore. To add context, consider adding extra column such as the data center where it resides, and the datastore type (e.g. NFS, VMFS) About the Port Group availability list\nThis lists port groups which at present has uptime of less than 100%. To add context, consider adding extra column such as the data center where it resides, used number of ports and maximum number of ports Points to Note Consider adding vCenter Server availability and NSX components availability. This requires the VMware SDDC Health monitoring solution.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.2-vm-configuration/",
      "title": "2. VM Configuration",
      "tags": [],
      "description": "",
      "content": "Use the VM Configuration dashboard to view the overall configuration of VMs in your environment, especially for areas that need attention.\nSee the Configuration Dashboard page for common design consideration among all the dashboards for configuration management.\nHow to Use Select a data center from the Data center table\nIn a large environment, loading thousands of VMs increase the web page loading time. As a result, the VM is grouped by data center. In addition, it may make sense to review the VM configuration per data center. For a small environment, the vSphere World is provided so you can see all the VMs in the environment. The dashboard is organized into 3 sections for ease of use.\nAll 3 sections will automatically display the VM configuration in the selected data center The first section covers limit, share and reservation\nLimit should not be used, as explained previously here. Their share and reservation values can easily become inconsistent among VMs, especially in an environment with multiple vCenter Servers. The following shows an environment with far too many variations in shares. Shares should be mapped to a service level, to provide a larger proportion of shared resources to those VMs who pay more. This means that you should only have as many shares as your service levels. If your IaaS provides Gold, silver, and bronze, then you should have only three types of shares. The value of share is relative. If you move a VM from one cluster to another (be it in the same or different vCenter Server), you may have to adjust the shares. Reservation impacts your capacity. Memory reservation works differently from CPU reservation, it\u0026rsquo;s more permanent. The second section covers VMware Tools\nTools is a key component of any VM, and should be kept running and up to date. The distribution chart shows the various versions. You should keep them minimal The third section covers other VM key configuration\nKeep the configuration consistent by minimizing variants. This helps to reduce complexity. Pay attention to VMs with many virtual disks or many virtual network cards. Keep the number of VM hardware versions minimal, and keep them current. VM Network Card widget. It you suspect your environment may have VM with no NIC card, consider adding it as dedicated bucket. The last part of the dashboard is collapsed by default.\nIt shows all the VMs with their key configuration. You can sort the columns and export the result into spreadsheet for further analysis. Points to Note The number of buckets on the pie chart or bar chart are balanced between the available screen estate, ease of use and functionality. Modify the buckets to either reflect your current situation or your desired ideal state. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/3.3.2-cluster-capacity/",
      "title": "2. Cluster Capacity",
      "tags": [],
      "description": "",
      "content": "The Cluster Capacity dashboard is designed for Capacity Team, not day to day Operations team. It provides long term and top down view, enabling the capacity team to better plan future expansion and ageing hardware technological refresh.\nDesign Consideration See the Capacity Dashboards page for common design consideration among all the dashboards for capacity management.\nThe dashboard considers all factors that impact capacity:\nUtilization Allocation Reclamation Contention Utilization is the primary counter for capacity, as it reflects the actual, live usage of the resources. If utilization is high, it does not matter if the overcommit ratio is far below your target, the cluster is full. On the other hand, if utilization is very low, that is not a good thing either. Unless it\u0026rsquo;s a newly provisioned cluster, that could indicates wastage.\nAllocation complements utilization as not all workload is real. This is covered in the Capacity chapter, under Allocation Model.\nReclamation is included as that can impact your decision, and wastage is pretty common. Capacity can be low, but if you can reclaim a sizeable chunk of wastage, you can defer hardware purchase.\nWastage is shown by a new color. Dark grey indicates wastage as capacity is not used. In fact, there can be performance problem is the low utilization was caused by bottleneck somewhere else.\nContention is included as it directly measures performance. If your cluster is unable to serve its existing workload, then it is unwise to add new workload. By definition, if the cluster does not have room for new workload, then its capacity is full. The ideal scenario is the cluster is running at 100% utilization but 0% contention, because it\u0026rsquo;s working as productively as possible. You get your investment well used.\nHow to Use The dashboard is layered, gradually providing details as you work top down in the dashboard.\nThe first layer shows 2 distribution charts\nBar charts summarize the clusters based on capacity remaining and time remaining. Just because you are running low on capacity does not mean you are running out of time. Cluster with a cyclical loads that hits high utilization but never trends toward 100% will have low capacity remaining, but plenty of time remaining. The two bar charts work together. The ideal situation is low Capacity Remaining and high Time Remaining. This means your resources are cost effective and working as expected. The second layer shows a heat map\nThe three heat maps are Time Remaining, Capacity Remaining, and VM Remaining. The cluster size has been made constant for ease of use and better focus on the action to be taken. If your cluster sizes are not standardized, consider using the number of ESXi hosts to show the size difference. The third layer shows a table, accompanied by other widgets to show details of selected cluster\nClusters Capacity List. If any cluster needs attention, then select the cluster to view the related details. Utilization displayed for three months and not one week. The daily average is displayed and not the hourly average and the focus is on consumed memory and not active memory. Reservation can impact the efficiency of your cluster. If your cluster size varies, complement the reservation number by showing relative value. You will need a super metric for that. No. of VM are shown because newly provisioned may not yet be active. They are often mistaken as idle, as they can remain unused for months. If you see VM growing but demand remains low, that\u0026rsquo;s a sign of potential demand coming up in the future.\nWorkload can be low, but is overcommit ratio high? Newly provisioned VMs tend to be idle for weeks, and suddenly grow. Use the VM Count to see if there was recent growth. Why is it low on capacity? Is it because of real workload, or just reservation? Points to Note If you find it useful, add a drill-down to the ESXi Capacity dashboard and VM Capacity dashboard. A logical place to initiate this drill down is in the Cluster Capacity List widget. Link this widget into the table of ESXi Host in the destination dashboard. If you have the screen real estate, add cluster size information. Small clusters are less efficient from a capacity perspective due to higher overhead and the inability to support larger VMs. The peak is defined as the highest among any ESXi hosts. If the peak is higher than the cluster-wide average, then it is unbalanced and is a common reason for suboptimal capacity. You can add a peak to complement the average utilization. Find out the cause of unbalance and optimize it. Add peak to complement average utilization. This lets you focus on unbalance, a common reason for suboptimal capacity. Find out the source of unbalance, which can be opportunity for optimization. This dashboard is not designed for stretched cluster, as this needs its own capacity model. You will need to have an object or custom group for each site, and then displays them side by side. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.2-cluster-contention/",
      "title": "2. Cluster Contention",
      "tags": [],
      "description": "",
      "content": "The Cluster Contention Dashboard is the primary dashboard for vSphere Cluster performance. It\u0026rsquo;s designed for VMware Architects, and can be used in both monitoring and troubleshooting. Once you determine there is a performance issue, use the Cluster Utilization dashboard to see if the contention is caused by utilization near 100%.\nDesign Consideration This dashboard is designed to be used as part of your Standard Operating Procedure (SOP). It is meant to be used daily, hence the views are set to show data in the last 24 hours. The dashboard provides performance metrics for VMs in the selected data center.\nUtilization metrics are not shown in this dashboard at all. There are two reasons behind it:\nSeparate the 2 concepts (utilization and contention) as they tend to get mixed. Keep the level of complexity manageable. A large and complex dashboard will also take longer to load. Both CPU and Memory are shown separately, because you can have one problem and not the other. CPU problems tend to be more common than Memory problems, due to lower overcommit ratio in memory in practice among customers. It is common to see customers do 4:1 CPU overcommit and only 2:1 memory overcommit. This conservative practice was due to the inherent higher value of memory counter. vSphere cluster shows high memory value as memory, giving the impression the actual utilization is high. And the reason for high value is modern Operating Systems like ESXi VMkernel uses memory as disk cache.\nSee the Performance Dashboard chapter for common design consideration among all the dashboards for performance management.\nHow to Use Look at the \u0026ldquo;Average Cluster Performance (%)\u0026rdquo; health chart at the top of the dashboard. In a high performing environment, where all the clusters are doing well, you will see something like this.\nThere was only one occurrence where the color is not green. At that time, the actual value is also relatively good.\nOn the other hand, if the clusters are unable to serve the VMs well, you will see something like this.\nThe average among all the clusters is no longer green, with a few occurrences of reds. The good part is the value does not trend downwards.\nAs this KPI takes into account every single running VM in your environment, the number should be steady, especially in a large environment. The analogy in real life is the stock market index. While individual stocks can be volatile on a 5 minute by 5 minute basis, the overall index should be relatively steady. A big drop is called a market crash and that\u0026rsquo;s not something you want in your environment.\nThe relative movement of the metric is as important as the absolute value of the metric. Your absolute number may not be as high you wish it to be, but if there have been no complaints for a long time, then perhaps there is no urgent business justification to improve it.\nAs the chart shows all the clusters, it uses the vSphere World object. This object is the parent of vCenter object, so it will show all clusters from all vCenter, making it suitable when you want to show everything.\nThe actual metric used is Performance \\ Clusters Performance (%), as shown in the following dialog box. This is the primary KPI for your entire IaaS. It plots how your IaaS is performing every 5 minutes, giving you the trend view of overall performance.\nThe metric itself is simply the average of Cluster KPI \\ Performance (%) metric. This performance metric in turn averages the VM Performance \\ Number of KPIs Breached metric from all running VMs in the cluster. Hence a value of 100% indicates that every single running VM in the cluster is served well. Based on this formula, when do you want the cluster performance to turn red?\nLet\u0026rsquo;s take an example of a cluster with 500 VM. Each VM consumes 4 IaaS resource (CPU, Memory, Disk, Network), hence there are 500 x 4 = 2000 KPI instances that the cluster must deliver. As a result, the counter will turn yellow if one of these two happens:\nIt can\u0026rsquo;t serve 1% of the VM population, which is 5 VMs. None of these VMs get the 4 IaaS resource within the KPI threshold. In mission critical environment, You are expected to serve all the VMs well. In development environment, you may be able to get away with lower service level. It fails to deliver one of the IaaS resources (CPU, Memory, Disk, Network) to 20 VM. More details on the formula were covered earlier here as it\u0026rsquo;s an important foundation of IaaS performance KPI.\nThe counter will turn orange if one of these two happens:\n3% of the VM population, which is 15 VMs, do not get any of the 4 IaaS resource within the threshold. The cluster fails to deliver one of the IaaS resources to 60 VM. Review the Clusters Performance table\nIt lists all the clusters, sorted by the least performing in the last 1 week. You can change this time period. The Worst Performance shows the lowest number in the time period. As vRealize Operations collects every 5 minutes, there are 12 x 24 x 7 = 2016 data points in a week. This column shows the worst point among 2016 datapoints. If the chart is showing green, then all is good. If not, you want to know which clusters are not performing. This is where the table comes in.\nThe table lists all the clusters, starting with the lowest performance. By default, it\u0026rsquo;s showing data from the last 24 hours as this dashboard is designed to be part of your daily SOP.\nThe Worst Performance column shows the lowest performance in the last period, specified under Time Settings.\nThe problem with functions like Minimum() and Maximum() is their value can be extreme. All it takes is a single 5-minute collection to show bad data and the entire 24 hours (which is 288 data points) becomes bad. This is where the Percentile() function comes in. It tells you if the Worst Performance is something you should look further into or not.\nCan you figure out why we don\u0026rsquo;t show average instead?\nAverage() is too late. It\u0026rsquo;s covered previously here.\nSelect a row (not the cluster name) to see the trend over time. All the health charts will automatically show the KPIs of the selected cluster.\nFor performance, it\u0026rsquo;s important to show both the depth and breadth of the performance problem, as explained here. A problem that impacts 1-2 VMs requires a different troubleshooting process than a problem that impacts all VMs in the cluster.\nThe depth is shown by reporting the worst among any VM counter. So the highest value of VM CPU Ready, VM Memory contention, VM Disk Latency among all the running VMs are shown. If the worst number is good, then you do not need to look at the rest of the VM.\nA large cluster with thousands of VM can have a single VM experiencing poor performance while \u0026gt;99.9% of the VM population is fine. The depth counter will not be able to report that most VMs are fine. It only reports the worst. This is there the breadth counters comes in.\nThe breadth counters report the percentage of the VM population that is experiencing performance problems. The threshold is set to be stringent, as the goal is to provide early warning and enable proactive operations.\nVM CPU CoStop is included, but placed at lower priority than Ready because high CoStop does not mean the ESXi is struggling to serve the VMs. CoStop can be reduced by right-sizing an oversized VM, so the remediation action is not always on the ESXi Host. CPU Overlap is included as it can happen when there are many active VMs in the cluster.\nHere is an example where the performance problem is clearly shown. You can see the cluster performance has regular drop in the last 7 days.\nWhat\u0026rsquo;s the problem?\nThe next 2 widgets show that CPU is a problem.\nMemory is not an issue\nPoints to Note For network dropped packets, there are 2 types: physical (ESXi) and virtual (VM). The physical counter is used as that better represents infrastructure problems. The VM counter may suffer from a false positive. I recommend you customize this dashboard and add it anyway, for completeness.\nCertain settings such as DRS automation level and the presence of many resource pools can impact performance. Consider adding a property widget to show relevant property of a selected cluster, and a relationship widget to show resource pools.\nFor a very large environment with many clusters, add a grouping to make the list more manageable. Group it by class of service, so you can focus on the more critical clusters. You can then adjust the threshold accordingly. For example, add the column 99th percentile to complement Worst and 95th Percentile. This is useful if you have clusters with large number of VMs.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.2-the-art-of-dashboard/",
      "title": "2. The Art of Dashboard",
      "tags": [],
      "description": "",
      "content": "To a few of us who love visualizing information with vRealize Operations, we see the dashboard as a canvas. Granted, the widgets have limitation but that\u0026rsquo;s part of the art.\nCreating dashboards is an art as you need to balance many conflicting requirements, such as:\nCan the dashboard be understood within 5 seconds? If yes, you buy yourself a few more minutes. The user understands what the dashboard does, and is willing to spend more time mastering it. To pass this test, think of which information, object, metric can you take away from the dashboard? See the KISS Principle, because an uber-dashboard that tries to please everyone and cover all scenarios will end up not being used.\nBegin with the end in mind. The purpose dictates the dashboard design. 2 dashboards can have an identical target role, purpose, and use case (e.g. performance), but if the size of the environment differs, the 2 dashboards will be different. An environment with 50,000 VMs is managed differently with an environment of 50 VMs.\nA small environment with 100 VMs in just 8 hosts in 1 cluster (hence 1 data center, 1 vCenter) needs less dashboards than an environment with 10,000 VM spread over 800 ESXi hosts, 100 clusters, 10 data centers and 3 vCenters.\nDashboard Design Method This section introduces us to a few considerations surrounding dashboard design. We will walk through a method where we are able to understand the user, the activity, the workflow and the other aspects needed to understand the context before we start.\nWhen we create dashboards that are used by others in our team we have to consider a few aspects that are helpful in making information useful, usable and delightful.\nWho Who (Role/ Persona) is going to use the dashboard? Start by creating a list of all users who would be accessing and using information in the dashboard Against this list mention the kind of information they would find useful for the specific persona. What What is the type of activity (granular vs. high level) they will perform? List next to the task if the information needs to be granular or high level. Sometimes users are looking for just a KPI number, sometimes they are looking for trends. Sometimes users might want to interact with the information, create drill downs etc. The complexity of the activity will help you identify if you need a complex widget or a simple one. How How (workflow) will they use the dashboard? List down what happens after they view the information, do they need to use another application, another visualisation. Plan accordingly and place navigation to enable this to happen. When How often (hourly, daily, weekly, monthly, quarterly) will they use the dashboard? Think about the usage of the dashboard, is it a frequent use case needed for daily use to perform work, or is it for monitoring on an irregular basis. Why Why (outcome) do they need the dashboard? Also list down outcomes from the dashboard usage. What is the usefulness of using the dashboard and what goals or outcomes the user is likely to achieve. Once we get this information we can better design dashboards based on the needs of the users. One way could be to plot it on a grid to understand the impact better. Let\u0026rsquo;s start with a grid like this one.\nNow if take the example of Who from different roles/personas\nAn executive might use the dashboard less frequently and the type of tasks they would perform could be high level. If you make a dashboard that is very granular and requires a lot of effort the executive might not have the time to use the dashboard.\nA manager might use the dashboard once a week, or on a monthly timeline, might need information on both granular or high-level.\nSimilarly an admin agent might use it on a daily basis and might need information at times that needs a lot of effort and at other times just a metric number would do.\nOnce you have reached a visualisation like this, you can better judge. If it needs to be a single dashboard or multiple based on the persona. What items should you prioritise and what kind of complexity is necessary based on the timeframe and time available with the stakeholder\nClean Layout Divide the screen into sections visually. This makes the dashboard easier to read. Here are some examples of how you can divide the screen.\nHere is a good example of layout1. Notice how simple it is. It is clear that it has 4 layers as layout is consistent among them.\nPast vs Present The past is harder to visualize as it has \u0026gt;1 data points. Ideally, you show the data as a line chart so you can see the trend. Showing a single data such as the maximum or average can miss critical information such as \u0026ldquo;is it trending upwards or downwards\u0026rdquo; and \u0026ldquo;how long did the peak last?\u0026rdquo;. The problem with line chart is it takes up screen real estate.\nIf you need to show a lot of objects or metris, then you need to summarize. As covered in Leading Indicator, you may need to show 2 numbers, especially if one of them is an average.\nCredit belongs to the Blue Medora team. Can\u0026rsquo;t recall who gave this to me. Brock or Mike?\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-6---other-metrics/2.6.2-vmkernel/",
      "title": "2. VMKernel",
      "tags": [],
      "description": "",
      "content": "There are two types of counters here: reservation and actual consumption.\nReservation in turn has 2 parts: minimum and maximum. The minimum is guaranteed and the maximum is the limit that the resource group can go. Actual consumption is a value within this range.\nAll these counters are grouped by their respective resource group, because each process running on ESXi belongs to one these four top-level resource group:\nSystem (host/system resource pool) IO Filter (host/iofilter resource pool) VIM (host/vim resource pool). This includes hostd, vpxa, etc. User (host/user resource pool) All the running VMs are children of the User resource pool. This includes the VM overhead as it\u0026rsquo;s part of the VM.\nReservation This is more of a property than a metric, as it does not change often. The formula is Overhead = CPU Total Capacity - CPU Capacity Available to VMs.\nWhere capacity available to VMs is the capacity reserved by and available for VMs.\nSince it is just a reservation (allocation), its not included in the calculation of the parent cluster usable capacity.\nIf you are curious about the actual values, they sort of map to the actual size of the ESXi. Based on a sample of almost 400 ESXi in production environment, here is what I got. By far the majority of the value is 6-10 GHz.\nTheir values tend to be stable over days, although from time to time I see fluctuating counters. I’m unsure why they are fluctuating so frequently as it’s a reservation, so if you know let me know. The following chart shows both the fluctuating pattern and steady pattern (most common). They are from 2 ESXi hosts.\nConsumption What if you want to know the actual consumption? vCenter provides visibility into the VMkernel utilization. It\u0026rsquo;s available under System, and you can get CPU and memory usage and reservation (allocation).\nYou need to select host/iofilters, host/system, and host/vim.\nEverything else runs under one of the three resource pools. You can plot their values in vCenter by stacking up their values, as shown below.\nFor memory, choose the metric Resource Memory Consumed. Stack them, and you see something like this. The system part typically dwarf the other 2 resources.\nDo not take the value from Memory \\ VMkernel consumed counter. That’s only the system resource. You can verify by plotting this and compare against host/system resource. You will get identical charts.\nThe above is for one ESXi Host. If you have many and want to see all the values in one go, create a view in vRealize Operations. Here is a sample from ~400 ESXi hosts, where I shot the top 7 from highest System usage.\nThe bottom two rows show the summary. The first summary is the average among all the hosts, while the last row is the highest value.\nBTW, a high CPU Ready in system group in esxtop is perfectly normal as this group includes idle threads.\nYou can see from the following that Idle accumulates 2400% CPU Ready:\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-5---network-metrics/2.5.2-sddc-network-monitoring/",
      "title": "2. SDDC Network Monitoring",
      "tags": [],
      "description": "",
      "content": "The arrival of software-defined infrastructure services also changes the way you monitor your network. The following diagram shows a simplified setup of an ESXi host.\nIn a single ESXi host, there are 4 areas that need to be monitored for a complete network monitoring:\nVM network VMkernel network ESXi kernel modules Agent VMs In the preceding example, we have 3 VMs running in the host. VM 1 and VM 2 are connected to the same VXLAN (or VLAN). VM 3 is on a different VXLAN (or VLAN), hence it is on a different port group. Monitoring at port group level complements monitoring at VM level and ESXi level.\nTraffic at Distributed Switch level carries more than VM traffic. It also carries VMkernel traffic, such as vMotion and VSAN. Both VMkernel network and VM network tend to share the same physical uplinks (ESXi vmnic). As a result, it\u0026rsquo;s easier to monitor at port group level.\nSounds good so far. What is the limitation of monitoring at distributed port group level?\nThe hint is at the word distributed.\nYes, the data is the aggregate of all the ESXi hosts using that distributed port group!\nBy default, VM 1 and VM 2 can talk to each other. The traffic will not leave the ESXi. Network monitoring tools that are not aware of this will miss it. Traffic from VM 3 can also reach VM 1 or VM 2 if NSX Distributed Logical Router is in place. It is a VMkernel module, just like the NSX Distributed Firewall. As a result, monitoring these kernel modules, and the host overall performance, becomes an integral part of network monitoring.\nThe 4th area we need to monitor is Agent VM. An Agent VM is mapped to 1 ESXi Host. It does not need HA protection as every ESXi host has one, hence it typically resides on the host local datastore.\nThe above example shows an ESXi host with 3 agent VMs. The first VM provides a storage service (an example is Nutanix CVM), the second VM provides Network service, and the 3rd VM provides a Security VM.\nLet\u0026rsquo;s use the Security service as an example. A popular example here is Trend Micro Deep Security virtual appliance. It is in the data path. If the Business VMs are accessing files on a fileserver on another network, the files have to be checked by the security virtual appliance first. If the agent VM is slow (and it could be due to factor that is not network related), it will look like a network or storage issue as far as the business VMs are concerned. The Business VMs do not know that their files have been intercepted for security clearance, as it is not done at the network level. It is done at the hypervisor level.\nSource of Data A complete network monitoring requires you to get the data from 5 different sources, not just from vSphere. In SDDC, you should also get data from the application, Guest OS, NSX and NetFlow/sFlow/IPFIX from VDS and physical network devices. For VDI, you need to get data at application level. We have seen packet loss at application-layer (Horizon Blast protocol) when Windows sees no dropped packet. The reason was the packet arrives out of order and hence unusable from protocol viewpoint.\nThe following shows a simplified stack. It shows the five sources of data and the 4 tools to get the data. It includes a physical switch as we can no longer ignore physical network once you move from just vSphere to complete SDDC.\nThe network packet analysis comes in 2 main approaches: Header analysis and full packet analysis. The header analysis is certainly much lighter but lack the depth of full analysis. You use this to provide overall visibility as it does not impose heavy load on your environment.\nThe impact of virtualization on network monitoring goes beyond what we have covered. Let\u0026rsquo;s add NSX Edge into the above, so you can see the traffic flow when the edge services are also virtualized. You will see that a network problem experienced by a VM on one ESXi could be caused by another VM running on another ESXi. The following diagram is a simplified setup, showing a single NSX Edge residing on another cluster.\nIn the above example, let\u0026rsquo;s say VM 1 needs to talk to outside world. An NSX Edge VM provides that connectivity, so every TCP/IP packet has to go through it. The Edge VM has 2 virtual NICs, one for each network. If the NSX Edge VM has CPU issue, or the underlying ESXi has RAM issue, it can impact the network performance of VM 1.\nNSX Edge You may be wondering if an Edge VM does a lot of processing. Let\u0026rsquo;s look at a real example. How much traffic do you think this Edge VM is doing? The number is kilobytes not kilobit, so don\u0026rsquo;t forget to multiply by 8.\nAt near 1 million KBps, the application VM is processing a total of 8 Gbps worth of data on both network cards, 4 Gbps incoming from one vNIC and 4 Gbps outgoing on another vNIC at the same time. This number is the sum of Receive and Transmit, so the theoretical limit is 20 Gbps as this VM uses a 10 Gbps NIC. Notice the pattern for both Receive and Transmit is identical, as NSX Edge is practically a gateway.\nThis NSX Edge happens to be the only VM on a host. This means we can expect the data at the Host level to mimic that. The host does not run distributed storage (e.g. VSAN) so there is no other traffic other than this VM. The following chart below confirms that.\nThere are practically 2 lines, even though we actually plot 8 line charts. What do the 2 lines map to?\nYes, they map to North-South traffic and South-North traffic. An end user requesting data from a web server would be South to North, while the web server response would be North to South.\n\u0026ldquo;Wait!\u0026rdquo; you might say. There should only 4 lines. Why do we have 8 lines?\nCan you figure it out from the following diagram?\nThe above 8 arrows map to the 8 lines. There is 1 line chart for every arrow. There are 4 NICs, and each has Receive and Transmit.\nIf you use NSX, there is a good chance that you will have multiple NSX Edge VMs. We have a customer with \u0026gt;100 VMs. On the same host, you may also run distributed storage (e.g. VSAN) as an Edge cluster is typically isolated. We have customers with multiple Edge VMs, and monitoring the health of these Edge VMs becomes an integral part of network monitoring.\nGood network management is about understanding the application. In a way, we should treat vCloud Suite as an application. There are now two layers of applications in SDDC:\nInfrastructure applications (e.g. Virtual SAN, NSX, F5, Trend Micro) Business Applications (e.g. your company intranet or website) This is consistent with the fact that you will have two layers of network, when the network is virtualized. You will use VXLAN for your VM and VLAN for your infrastructure.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-4---storage-metrics/2.4.2-vm/",
      "title": "2. VM",
      "tags": [],
      "description": "",
      "content": "A VM does not see the underlying shared storage. It sees local SCSI disks only. So regardless of whether the underlying storage is NFS, VMFS, VSAN or RDM, it sees all of them as virtual disks. You lose visibility in the physical adapter (for example, you cannot tell how many IOPSs on vmhba2 are coming from a particular VM) and physical paths (for example, how many disk commands travelling on that path are coming from a particular VM).\nAt the VM level, you can look at counters at the individual virtual disk level, at the datastore level, and at the disk level. Which ones should you when?\nUse the virtual disk counters to see VMFS vmdk files, NFS vmdk files, and RDMs. However, you don\u0026rsquo;t get data below the virtual disk. For example, if the VM has snapshot, the data does not know about it. Also, a VM typically has multiple virtual disks (OS drive, swap drive, data drive), so you need to add them manually if you use vCenter. In vRealize Operations, you use the \u0026ldquo;aggregate of all instances\u0026rdquo;.\nUse the datastore counters to see VMFS and NFS, but not RDM. Because snapshots happen at Datastore level, the counter will include it. Datastore figures will be higher if your VM has a snapshot. You don\u0026rsquo;t have to add the data from each virtual disk together as the data presented is already at the VM level. It also has the Highest Latency counter, which is useful in tracking peak latency.\nUse the disk counters to see VMFS and RDM, but not NFS. The data at this level should be the same as at Datastore level because your blocks should be aligned; you should have a 1:1 mapping between Datastore and LUN, without extents. It also has the Highest Latency counter, which is useful in tracking peak latency.\nVMs consume storage in 3 different ways:\nVirtual disk. This can be VMFS, vSAN, vVOL, NFS, RDM. If it\u0026rsquo;s vmdk files, they can reside in different datastores and/or RDM Network mount point, from inside Windows or Linux. This is not feasible by the hypervisor. Both the space, and the IO are not visible. It goes out as network throughput. Overhead. This is not visible to the Guest OS. They are shown in blue in the following diagram. There are more file types than shown above. However, from monitoring and troubleshooting viewpoint, the above is sufficient.\nOutstanding IO vSphere also provides information about the number of I/Os that have been issued, but not yet completed. The Number of Outstanding I/O counter tracks these, and it provides a separate counter for read and write. Certainly, the higher the number of outstanding I/Os is, the higher the latency becomes.\nOutstanding IO tracks the IO requests that are not yet executed. They are waiting in the queue, hence this counter is a good counter to track if the storage subsystem is unable to cope with demand. The number is provided for each virtual disk, meaning it can cover RDM disk. There is also a separate number for read and write.\nWhat should be the threshold value?\nThe range varies widely. Use the profiling technique to establish the threshold that is suitable for your environment. In the following analysis, we take more than 63 million data points (2400 VM x 3 months worth of data)\nSnapshot Impact Snapshot requires additional read operations, as the reads have to be performed on all the snapshots. The impact on write is less. I\u0026rsquo;m not sure why it goes up so high, my guess is there are many files involves. Based on the manual, a snapshot operation creates .vmdk, -delta.vmdk, .vmsd, and .vmsn files. Read more here.\nFor Write, ESXi just need to write into the newest file.\nThe pattern is actually identical. I take one of the VM and show it over 7 days. Notice how similar the 2 trend charts in terms of pattern.\nYou can validate if snapshot causes the problem by comparing before and after snapshot. That\u0026rsquo;s exactly what I did below. Notice initially there was no snapshot. There was a snapshot briefly and you could see the effect immediately. When the snapshot was removed, the 2 lines overlaps 100% hence you only see 1 line. When we took the snapshot again, the read IOPS at datastore level is consistently higher.\nHow I know that\u0026rsquo;s IOPS effect as the throughput is identical. The additional reads do not bring back any data. Using the same VM but at different time period, notice the throughput at both levels are identical.\nAnd here is the IOPS on the same time period. Notice the value at datastore layer is consistently higher.\nFor further reading, Sreekanth Setty has shared best practice here.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-3---memory-metrics/2.3.2-guest-os-vs-vm/",
      "title": "2. Guest OS vs VM",
      "tags": [],
      "description": "",
      "content": "The following diagram compares the memory counters between VM and Guest OS,\nRight off the bat, you will notice that popular counters such as Consumed, Shared, and Reservation do not exist in Windows. The reason is VM and Guest OS have different vantage points.\nLet\u0026rsquo;s take an example with a simple Microsoft Windows server running Active Directory. It has 4 GB of memory as it\u0026rsquo;s just serving a small number of objects in the Singapore office lab. Take a look at the following table, where I compared the counter from inside the Guest OS and the VM memory active counter.\nThere are four periods above where I made changes inside Windows. Let\u0026rsquo;s step through them.\nPeriod What happened A Microsoft AD server in normal running condition. vCenter is reporting low utilization, around 15-20%. Note vCenter users the Active metric, not Consumed. B I installed the vRealize Operations agent, which is based on the open source Telegraf. This gives the Guest OS metric, which is shown by the blue color. The agent collects data every 5 minutes, hence the regular spike. So far so good.\nNotice the value from VM Active metric jumps to 100%. That\u0026rsquo;s fine, but then it stays at 100% for more than 12 hours. All I did was installing a small collection agent and that\u0026rsquo;s it.\nI actually got an alarm in vCenter, even though the VM does not need the RAM obviously. What happened here prove that the Active counter is based on sampling, and that sampling could be wrong.More on that here. C The next morning, I decided to generate some load as the pattern does not change at all. Since Windows has not been patched for a long time, I started Windows patch. The entire process is mostly downloading and installing, which last for several hours.\nThe two metrics show no correlation at all. D After several hours, the entire Windows update process is completed. Let\u0026rsquo;s now look inside the VM. I will use another VM to show a different example. This time around, I will take an idle VM so we can see how the counters behave. An idle VM will have minimal or 0 activity.\nYou can see that this Windows Server 2016 VM has 16 GB, but 0 GB is active. It is expected as we know the Guest OS is idle as nothing is installed. vCenter is showing the data correctly. So far so good\u0026hellip;\nWhat do you think you will see inside Windows? Will the In Use counter show that it\u0026rsquo;s using 0 GB or somewhere near there?\nYou know that it won\u0026rsquo;t show 0 GB as it\u0026rsquo;s impossible that any OS does not use any memory while it\u0026rsquo;s running. But what number will the In Use counter show?\nIt\u0026rsquo;s showing 7.2 GB. If you look at the chart, it portrays that it has been constantly or actively using that much of memory. In reality, we know it\u0026rsquo;s idle. The other proof is Windows actually compressed 1.5 GB of this 7.2 GB.\nI hope the above simple experiments shows that you should use the right counter for the right purpose.\nThe following diagram shows that the Guest OS and VM counters do not map to each other. Neither the VMkernel nor the Guest OS have full visibility into each other.\nESXi Host cannot see how the Guest OS manages its memory pages, how it classifies the pages as Use, Modified, Cache and Free. ESXi also cannot see the virtual memory (page file).\nESXi can only see when the Guest OS performs reads or writes. That\u0026rsquo;s why vSphere VM main counters are basically what is active recently and what has been active. The first one is called Active, the second is called Consumed. All other counters are about ESXi memory management, and not about VM memory utilization. VM memory utilization impacts ESXi memory management, but they are clearly not the same thing.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-2---cpu-metrics/2.2.2-vm/",
      "title": "2. VM",
      "tags": [],
      "description": "",
      "content": "Counters is essentially an accounting of systems in operation. To understand the counter hence requires a knowledge of how the system works. Without internalizing the mechanics, you will have to rely on memorizing.\nESXi Scheduler keeps in mind the following goals:\nTo balance load across physical (PCPUs). To preserve cache state, minimize migration cost. To avoid contention from hardware (HT, LLC, etc.) and sibling vCPUs (from the same VM). To keep VMs or threads that have frequent communications close to each other. At the most basic level, a VM CPU is either being utilized or not being utilized by the Guest OS. At any given moment, it either runs or it does not, there is no walk state.\nWhen it\u0026rsquo;s being utilized, the hypervisor must schedule it. A multi vCPU VM has multiple schedules, 1 for each vCPU. For each vCPU: If VMkernel has the physical CPUs to run it, then the vCPU gets to Run. The Run counter is increased to track this. If VMkernel has no physical CPUs to run it, then the vCPU is placed into Ready State. The VM is ready, but the hypervisor is not. The Ready counter tracks this. When it\u0026rsquo;s not being utilized, there are 2 possible reasons: The CPU is truly idle. It\u0026rsquo;s not doing any work. The Idle Wait counter accounts for it. The CPU is waiting for IO. CPU, being faster than RAM, waits for IO to be brought in. There are 3 sub cases here (CoStop, VM Wait and memory wait), and they will be covered later. With the above understanding, we\u0026rsquo;re ready to examine the following state diagram. The diagram shows a single schedule (1 vCPU, not the whole VM). It\u0026rsquo;s showing the view from hypervisor (not from inside the Guest OS):\nESXi places each vCPU of the VM in one of the 4 above states. A vCPU cannot be in 2 states at the same time. This is fundamental in understanding the formula behind CPU counters.\nRun is when the Guest OS gets to run. It does not check how fast it runs (frequency) or how efficient it runs (hyperthreading). Run measures how long it runs, hence the counter is in milliseconds, not GHz. Ready and Co Stop. They are mutually exclusive states. If a vCPU is in CoStop, it is not in Ready state. Wait handles both Idle and Wait. The reason is the hypervisor cannot tell whether the Guest OS is waiting for IO or idle. As far as the hypervisor concern, it\u0026rsquo;s not doing anything. This also measures the state where the wait is due to hypervisor IO. Those of you familiar with Operating Systems kernel will notice that the diagram is similar with a physical OS scheduler state diagram. I\u0026rsquo;m taking Huawei Harmony OS as an example as it\u0026rsquo;s the newest OS and it\u0026rsquo;s designed for a range of device1.\nBack to our VMkernel 4 possible states, you can conclude that:\nRun + Ready + CoStop + Wait = 100%\nThe above is at any given moment. To measure over time and report it (say every 20 seconds), we need to add a time dimension. The following example shows the above state diagram repeated over time, where each block is 1 second.\nvCenter happens to use 20000 milliseconds as the reporting cycle, hence 20000 milliseconds = 100%.\nThe above is per vCPU. A VM with 24 vCPU will have 480,000 as the total every 20 seconds. It matters not if the VM is configured with 1 vCPU 24 vCores or 24 vCPU with 1 vCore each.\nYou can prove the above by stacking up the 4 counters over time. In this VM, the total is exactly 80000 ms as it has 4 vCPU. If you wonder why CPU Ready is so high, it\u0026rsquo;s a test VM where we artificially placed a limit.\nReady Ready tracks the time when a VM vCPU wants to run, but ESXi does not have a physical thread to run it. VMkernel places the VM vCPU into Ready state. Ready also accounts when Limit2 is applied, as the impact to the vCPU is the same (albeit for a different reason altogether). When a VM is unable to run due to Limit, it accumulates limbo time when sitting in the limbo queue. Be careful when using a Resource Pool, as it can unintentionally cause limits.\nTake note that Ready is unaware of contention due to hyperthreading. The vCPU is not placed in ready state because both threads can execute at the same time. The contention for shared resources happens at low level hardware and essentially transparent to ESXi scheduler. If you are concerned about this certain degradation in throughput when two worlds execute at the same time on the same core, what counter should you use?\nYou\u0026rsquo;re right. It\u0026rsquo;s CPU Contention. Different purpose, different counter.\nTake a look at the high spikes on CPU Ready value. It hits 40%!\nNotice the overall pattern of the line chart correlates very well with CPU Usage and CPU Demand. The CPU Usage hit 3.95 GHz but the Demand shot to 6.6 GHz. This is a 4 vCPU VM running on a 2.7 GHz CPU, so its total capacity is 10.77 GHz. Why did Usage stop at 3.95 GHz?\nWhat\u0026rsquo;s causing it?\nIf your guess is Limit you are right. This VM had a limit set at 4 GHz.\nReady also includes the CPU scheduling cost (normally completed in microseconds), hence the value is not a flat 0 on idle VM. You will notice a very small number. Ready goes down when Guest OS is continually busy, versus when a process keeps waking up and going to sleep, causing the total scheduling overhead to be higher. The following shows Ready is below 0.2% on an idle VM (running at only 0.8%). Notice CoStop is basically flat 0.\nIn rare case where the application has a lot of micro bursts, CPU Ready can be relatively higher to its CPU Run. This is due to the CPU scheduling cost. While each scheduling is negligible, having too many of them may register on the counter. If you suspect that, check esxtop, as shown below:\nCPU Ready tends to be higher in larger VMs, because Ready tends to hit all vCPU at the same time. Instead of thinking of CPU ready in 2D (as shown in the first chart below), think in 3D where each vCPU moves across time. The 2nd chart below shows how the 8 vCPUs move across time better.\nCo-Stop CoStop is a different state, hence different counter, than Ready because the cause is different.\nCoStop only happens on Simultaneous Multi Processor (SMP) VMs. SMP means that the OS kernel executes parallel threads. This means CoStop does not apply to 1 vCPU VMs, as there is only 1 active process at any given time. It is always 0 on single vCPU VM.\nIn a VM with multiple vCPUs, ESXi VMkernel is intelligent enough to run part of the VM vCPUs when it does not have all physical cores to satisfy the large VM demand. At some point, it needs to stop the vCPU, as it\u0026rsquo;s too far ahead of its sibling vCPU (which it cannot serve). This prevents the Guest OS from crashing. The CoStop counters track the time when the vCPU is paused due to this reason. This explains why CoStop tends to be higher on a VM with more vCPUs.\nIf only one or some vCPU are in ready state, then the remaining ones will soon be co-stopped, until all the vCPU are co-started.\nThe value of CoStop should be \u0026lt;0.5% in healthy situation. This is based on 63.9 million datapoints, as shown on the following pie chart.\nNote that the value of CoStop tends to be larger for large VM. Its value also tends to be smaller than Ready, as shown below. Ready and CoStop may or may not corelate with Usage. In the following chart you can see both the correlation and lack of correlation.\nJust like Ready, CoStop happens at the vCPU and not the VM level. When a VM vCPU experiences co-stop, it\u0026rsquo;s because its sibling\u0026rsquo;s vCPU experienced Ready. The sibling vCPU could be Run or still in Ready, but it was behind because it was unable to run. Since it\u0026rsquo;s not CoStop, then it must be Ready.\nGuest OS is not aware of both CoStop and Ready. The vCPU freezes. \u0026ldquo;What happens to you when time is frozen?\u0026rdquo;3 is a great way to put it. As far as the Guest OS is concerned, time is frozen when it is not scheduled. Time jumps when it\u0026rsquo;s scheduled again.\nThe metric Guest OS CPU Usage isn\u0026rsquo;t aware of stolen time. For this counter to be aware, its code has to be modified. If you know that Microsoft or Linux has modified this counter, let me know in which version they make the change.\nThe metric Guest OS Stolen Time accounts for it. But that\u0026rsquo;s in Linux, not Windows. And Linux only measures Ready, not CoStop.\nThe time it spends under CoStop or Ready should be included in the Guest OS CPU sizing formula as the vCPU wants to run actually.\nBy the way, there is a performance improvement in the VMkernel scheduler in handling CoStop in ESXi 7.0 Update 1. Prior to the improvement, the application performance dropped after 384 vCPU.\nWait There are 3 sub-counters that make up Wait, as seen by the hypervisor.\nIdle. This could be a genuine idle. The Guest OS itself is not running workload on that vCPU Swap Wait VM Wait CPU is the fastest component among infrastructure resources, so there are times it must wait for data. The data comes from memory, disk or network. There are also times when there is nothing to do, so the CPU is idle. Whether the Guest OS vCPU is idle or waiting for IO, the VMkernel does not have this visibility. It can only see it as idle. The Idle counter tracks this. Regardless, Idle should not be included in Guest OS sizing as the vCPU is not running.\nBecause there are 2 levels of IO processing, there are 2 levels of Wait.\nInside the Guest. Guest OS tracks this as Wait. As the IO is Hypervisor tracks this as VM Wait. Outside the Guest. ESXi VMkernel is performing IO. The 2nd level is again not visible to the Guest OS. Swap Wait tracks the time CPU is waiting for Memory page to come in from ESXi swap.\nVM Wait tracks the time CPU is being blocked by other things, such as IO and vMotion. For example, the VMM layer is trying to do something and it\u0026rsquo;s blocked. Snapshot is a common reason here.\nBoth values of Swap Wait and VM Wait should be near 0%.\nGuest OS isn\u0026rsquo;t aware of both VM Wait and Swap Wait. It again experiences freeze. The time it spends under VM Wait and Swap Wait should be included in the Guest OS CPU sizing formula as the VM wants to run actually.\nRun + CoStop + Ready + Wait = 100\nThey represent the 4 possible states. This means 20000, as vCenter reports every 20 seconds. vRealize Operations averages 15 of these 20-second averages into a 5-minute average.\nVM 2 can run when VM 1 is on CoStop state, Ready state, or Wait state. This is because the physical thread is available.\nRun Run is when the Guest OS gets to run and process instruction. It is the most basic counter among the 4 CPU utilization counters. It\u0026rsquo;s the only counter not affected by CPU frequency scaling and hyper threading. It does not check how fast it runs (frequency) or how efficient it runs (SMT).\nRun at VM level = Sum of Run at vCPU levels\nThis means the value of CPU Run at VM level can exceed 20000 ms in vCenter.\nThe following screenshot shows CPU Run higher than CPU Used. We can\u0026rsquo;t tell if the difference is caused by power management or hyperthreading, or mix of both.\nIf the above was all we need to know, monitoring VMware vSphere would have been easy. You wouldn\u0026rsquo;t need a book like this. In reality, the following factors must also be considered:\nInterrupt System time Power Management or CPU Frequency Scaling Simultaneous Multithreading (Hyper Threading as Intel calls it) Because CPU Run do not take into account this external work, and not aware of CPU speed and HT, we will see in the right-sizing section that this property makes it suitable as input to size the Guest OS.\nOverlap Time the VM vCPU was interrupted to perform system services on behalf of itself or other VM. Notice the word system services, a process that is part of VMkernel. This means it is not for non-system services, such as vCPU world. That\u0026rsquo;s why the value in general is lower than CPU Ready or even Co-Stop.\nWhen ESXi is running a VM, this activity might get interrupted with IO processing (e.g. incoming network packets). If there is no other available cores in ESXi, VMkernel has to schedule the work on a busy core. If that core happens to be running VM, the work on that VM is interrupted. The counter Overlap accounts for this, hence it\u0026rsquo;s useful metric just like Ready and CoStop counter.\nSome documentation in VMware may refer to Overlap as Stolen. Linux Guest OS tracks this as Stolen time.\nWhen VM 1 was interrupted, the Run counter is unaware of this and continues tracking. To the Guest OS, it experiences freeze. Time stops for this vCPU, as everything is paused. The clock on motherboard does not tick for this vCPU. Used and Demand do account for this interruption, making them useful in accounting the actual demand on the hypervisor. When the VM 1 runs again, the Guest OS experiences a time jump.\nThe Overlap counter is useful to troubleshoot performance problem, complementing Ready, CoStop, VM Wait and Swap Wait. Ready does not include Overlap as the VM remains on the Run State (see the CPU State Diagram).\nUnit is ms, and it\u0026rsquo;s the summation of the entire 20 seconds, but averaged over 300 seconds. So the amount at 300 seconds is max 20000 (this is 100%), and must be multiplied by 15 if we want to see the actual average in the 300 second period.\nThe amount is the sum of all vCPU, so you need to divide by the number of running vCPU. There is also counter at each vCPU level.\nThe following is a 68 vCPU VM running Splunk. In the last 7 days, it experienced a low but sizeable CPU overlap. 10K is relatively low for a 68 vCPU VM, but it still represents half a vCPU worth of interruption.\nOverlap should be included in Guest OS sizing as the Guest OS wants to run actually. It is essentially an unmet Demand.\nA high overlap indicates the ESXi host is doing heavy IO (Storage or Network). Look at your NSX Edge clusters, and you will see the host has relatively higher Overlap value versus non IO-intensive VM.\nSystem A VM may execute a privilege instruction, or issue IO commands. These 2 activities are performed by the hypervisor, on behalf of the VM.\nIO processing differs to non-IO processing as it has to be executed twice. It\u0026rsquo;s first processed inside the Guest OS, and then in the hypervisor network and storage subsystems. ESXi typically uses another core for this work instead of the VM vCPU. ESXi is also performing IOs on behalf of all VMs that are issuing IOs on that same time, not just VM 1. This work has to be accounted for and then charged back to the associated VM. The System counter tracks this. System counter is part of VMX counter.\nRegardless, the work has to be charged back to the VM, since CPU Run does not account for it. Since this work is not performed by any of the VM CPU, this is charged to the VM CPU 0. The system services are accounted to CPU 0. You may see higher Used on CPU 0 than others, although the CPU Run are balanced for all the VCPUs. So this is not a problem for CPU scheduling. It\u0026rsquo;s just the way VMKernel does the CPU accounting.\nThe System counter is not available per vCPU. Reason is the underlying physical core that does the IO work on behalf of the VM may be doing it for more than 1 vCPU. There is no way to break it down for each vCPU. The following vCenter screenshot shows the individual vCPU is not shown when System metric is selected.\nAs of vSphere 6.5, Sotrage vMotion effort for the VM being moved is no longer charged to vCPU 0.\nMajority of VMs will have System value less than 0.5 vCPU most of the time. The following is the result from 2431 VMs.\nOn IO intensive VM like NSX Edge, the System time will be noticeable, as reported by this KB article. In this case, adding more vCPU will make performance worse. The counter inside Linux will differ to the counter in vSphere. The following table shows high system time.\nSimultaneous Multithreading CPU SMT (Hyper Threading as Intel calls it) is known to deliver higher overall throughput. It increases the overall throughput of the core, but at the expense of individual thread performance. The increase varies depending on the load.\nAccounting wise, ESXi records this overall boost at 1.25x regardless of the actual increase, which maybe less or more than 1.25x. That means if both threads are running at the same time, the core records 1.25x overall throughput but each thread only gets 62.5% of the shared physical core. This is a significant drop from the perspective of each VM. From the perspective of each VM, it is better if the second thread is not being used, because the VM could then get 100% performance instead of 62.5%. Because the drop could be significant, enabling the latency sensitivity setting will result in a full core reservation. The CPU scheduler will not run any task on the second HT.\nThe following diagram shows 2 VMs sharing a single physical core. Each run on a thread of the shared core. There are 4 possible combinations of Run and Idle that can happen:\nEach VM runs for half the time. The CPU Run counter = 50%, because it\u0026rsquo;s not aware of HT. But is that really what each VM gets, since they have to fight for the same core?\nThe answer is obviously no. Hence the need for another counter that accounts for this. The diagram below shows what VM A actually gets. The allocation is fixed.\nThe CPU Used counter takes this into account. In the first part, VM A only gets 62.5% as VM B is also running. In the second part, VM A gets the full 100%. The total for the entire duration is 40.625%. CPU Used will report this number, while CPU Run will report 50%.\nIf both threads are running all the time, guest what CPU Used and CPU Run will report?\n62.5% and 100% respectively.\nUsed | Usage | Demand As covered earlier, CPU Run does not account for the following:\nHow fast is the \u0026ldquo;run\u0026rdquo;? All else being equal, a 5 GHz CPU is 5x faster than a 1 GHz CPU. Throughput impacts utilization. The faster it can complete a task, the shorter it has to work. That\u0026rsquo;s why you see some counters in MHz, because they account for this speed. How efficient is the \u0026ldquo;run\u0026rdquo;? If there is competing thread running in the same core, the 2 threads have to share the core resource. ESXi accounting records this as 1.25x overall gain, hence each thread drops to 62.5% only. This is a significant drop that should be accounted. IO work. IO performed by hypervisor has to be charged to the VM. This is where Used and Demand come in. vCenter then adds Usage (MHz) and Usage (%) counters. The following table shows the 5 VM utilization counters.\nCounter Available at Unit Source CPU Frequency SMT Run vCPU level Millisecond ESXi No No Used vCPU level\nVM level (include System) Millisecond ESXi Yes Yes Usage vCPU level MHz vCenter Yes Yes Usage VM level % vCenter Yes Yes Demand VM level MHz ESXi Yes No Used CPU Used covers uses cases that CPU Run does not.\nVM Migration. Moving VM to another ESXi requires that you know the actual footprint of the VM, because that\u0026rsquo;s what the destination ESXi needs to deal with. VM Chargeback. You should charge the full cost of the VM, and not just what\u0026rsquo;s consumed inside the VM. In fairness, you should also charge the actual utilization, and not rated clock speed. Here is how Used differs to Run:\nBased on the above, you can work out the formula for VM level Used, which is:\nVM level Used = Run + System - Overlap + VMX +/- E\nWhere E is the combination of:\nefficiency gained from CPU Turbo Boost or efficiency loss from power savings. For example, if the frequency is dropped to 40% of the nominal frequency, we consider 60% of the CPU time was stolen. 37.5% efficiency loss from CPU SMT. VMX is typically negligible. It accounts for CPU cycles spent on things like consoling to the VM. In esxtop, System time is charged to the VM VMX world.\nBecause Used accounts for the actual frequency, you may expect it to be measured in GHz and not millisecond. Think of the number of cycles completed instead of simply frequency. You then convert it back to time. I know it requires a bit of mental mathematics.\nQuiz:\nWhy does the formula state VM level, and not individual vCPU level. What\u0026rsquo;s the reason? How will Used compare with Run in general? Do you expect it to be higher or lower? If it\u0026rsquo;s higher, what can cause it? The impact of Power Management can be noticeable. For example, a physical chip comes with 2 GHz as its standard speed. ESXi may increase or decrease this speed dynamically, resulting in Turbo Boost or power saving. If ESXi increases the clock speed to 3 GHz, Used counter will be 50% higher than the Run counter. The Guest OS (e.g. Windows or Linux) is not aware of this performance boost. It reports a value based on the standard clock speed, just like Run does. On the other hand, if ESXi decreases the clock speed to 1.5 GHz, then Used will report a value that is 25% lower than what Run reports.\nLet\u0026rsquo;s take an example. What do you notice?\nAs you can see from the preceding chart, the impact is noticeable. The System and Overlap counters hovers averages \u0026lt;10 ms (negligible as this VM is basically idle), but the gap between Used and Run averages around 20% Used is ~20% higher than Run, likely due to Turbo Boost.\nLet\u0026rsquo;s take another example, this time from a busy VM. I\u0026rsquo;ve removed System and Overlap as they are also negligible in this example. This is a 32 vCPU VM running Splunk. Notice Used is consistently higher than Run.\nNow let\u0026rsquo;s look at the opposite scenario. This VM is a 64 bit Ubuntu running 4 vCPU. Used (ms) is around 44% of Run (ms). The VM had minimal System Time (ms) and Overlap (ms), so Used is basically lowered by both power savings and CPU SMT. In this example, if Run is far from 100% and the application team want faster performance, your answer is not to add vCPU. You should check the power management and CPU SMT, assuming the contention counters are low.\nCPU Used has a different formula at VM level and vCPU level. At vCPU level, it does not include System Time. At VM level, it includes the work done by VMkernel that is charged at VM level, such as System and other worlds.\nUsage There are two counters: Usage (MHz) and Usage (%). These 2 counters do not exist in ESXi, meaning they only exist in vCenter. I\u0026rsquo;m not able to figure out if Usage (%) = Usage (MHz) / VM Static CPU Speed, as I don\u0026rsquo;t have the need yet to use both counters. From the chart below, it appears that they are not 100% identical, but they are very similar.\nLet\u0026rsquo;s compare Usage with Used instead. We will compare Usage MHz as that\u0026rsquo;s the raw counter. The percentage value is derived from it.\nFrom the preceding chart, we can see they are basically the same, with the difference due to y-axis scales. Formula wise, Usage (MHz) includes all the VM overhead, such as the time spent by VMX process.\nvRealize Operations Usage (MHz) and Usage (%) metrics map 1:1 to the respective counters from vCenter.\nNote that Usage (%) is capped at 100%. The following is a single vCPU production Windows Server. Both CPU Usage (MHz) and Demand jump to over 100%. Their values are identical for almost 30 days. The VM had near 0% Contention (not shown in chart), hence the 2 values are identical.\nHowever, when we plot the value in %, we see a different number. Usage (%) is strangely capped at 100%.\nThe VM experienced some contention around May 12. That\u0026rsquo;s why Demand was higher than Usage.\nDemand CPU Demand includes System time, so it reflects the full picture of what VM consumes. It also includes efficiency loss because of frequency scaling. For example, if the frequency is dropped to 40% of the nominal frequency, we consider 60% of the CPU time was stolen. Usage value will be lower by 60% to Demand, all else being equal.\nDemand is typically higher than Used by 1.25x. This makes sense as the HT effect is fixed at 1.25x. This means Demand is a the counter to use when you suspect the performance drop is caused by hyper threading. If the issue coincides with a sharp gap between Usage and Demand, that\u0026rsquo;s hyperthreading.\nHow can Usage be higher than Demand then? Take a look at this vSphere Replication appliance. It replicates every 5 minutes, hence the spike. Notice the spike for Usage is higher but thinner. What\u0026rsquo;s going on?\nWe\u0026rsquo;ve disabled hyperthreading in the underlying ESXi, so we can isolate and compare better. Notice the pattern is similar. Demand is averaged over a longer time, giving it a more steady value. That\u0026rsquo;s why the peak is shorter but wider.\nDemand could be lower than Run if there is power management savings, as it accounts for speed \u0026amp; efficiency of the run.\nDemand (MHz) and Usage (MHz) can exceed 100%. The following is a 32-vCPU hadoop worker node. Notice it exceeds the total capacity multiple times. Demand and Usage are identical as it\u0026rsquo;s the only VM running and the has more than 32 cores, hence there is 0 contention.\nOkay, now that you have some knowledge, let\u0026rsquo;s test it.\nQuiz Time! Looking at the chart below, what could be causing it?\nNotice Demand jump while Usage dropped. VM CPU Contention (%) jumped even more. What is going on?\nAnd why is that Contention is much more than Demand - Usage?\nAnswer at the end of the book!\nIn older releases of vRealize Operations, this counter used to be computed as:\nMaximum (CPU Utilization for Resources / CPU Active (1 min. average) / Configuration / Hardware / Number of CPUs, CPU Usage) * CPU Total Capacity / 100.\nThis is no longer the case as vRealize Operations now simply maps to the vCenter metric.\nContention This vRealize Operations metric maps to vCenter CPU Latency (%) counter, which in turn maps to ESXi #LAT_C counter. The diagram below shows what it includes. LAT_C excludes \u0026ldquo;Max Limited\u0026rdquo; in Ready, but it includes CoStop even if the CoStop was the result of Limit. Notice that HT and CPU Frequency are effect and not metrics. You can see the impact of CPU Frequency in esxtop %A/MPERF counter.\nIt measures the full possible contention a VM may have, that is not intentionally imposed on the VM by the vSphere Administrator. It considers CPU SMT effect. In ESXi CPU accounting, Hyper Threading is recorded as giving 1.25x throughput. That means when both threads are running, each thread is recorded as only getting 62.5%. This will increase the CPU Contention to 37.5%. All else being equal, VM CPU Contention will be 37.5% when the other HT is running. This is done so Used + Latency = 100%, as Used will report 62.5% when the vCPU has a competing thread running.\nIn the above scenario, what\u0026rsquo;s the value of CPU Ready?\nYup, it\u0026rsquo;s 0%.\nCPU Contention also accounts for power management. What happens to its value when frequency drops by 25%. It can\u0026rsquo;t go to negative right? If you know the answer, let me know!\nBecause of these 2 factors, its value is more volatile, making it less suitable as a formal Performance SLA. Use CPU Ready for Performance SLA, and CPU contention for performance troubleshooting. You can do a profiling of your environment by calculating the value of CPU Ready at the time CPU Contention hits the highest, and vice versa. The following table only shows 5 VM out of 2500 that I analyzed. These 2 counters do not have good correlation, as they are created for different purpose.\nIn many cases, the impact of both threads running is not felt by the application running on each thread. If you use CPU Contention as formal SLA, you may be spending time troubleshooting when the business does not even notice the performance degradation.\nThe following screenshot shows CPU Contention went down when both Ready and CoStop went up.\nHow about another scenario, where Contention is near 0% but Ready is very high? Take a look at this web server. Both CPU Demand and CPU Usage are similar identical. At around 1:40 am mark, both Demand and Usage showed 72.55%, Contention at 0.29%, but Ready at above 15%. What\u0026rsquo;s causing it?\nThe answer is Limit. Unlike CPU Ready, it does not account for Limit (Max Limited) because that\u0026rsquo;s an intentional constraint placed upon the VM. The VM is not contending with other VMs. VMware Cloud Director sets limit on VM so this counter will not be appropriate if you aim to track VM performance using Contention (%) metric.\nA better and more stable metric to track the contention that a VM experience is Ready + Co Stop + Overlap + VM Wait + Swap Wait. Note that the raw metric for all these are millisecond, not GHz.\nWhere do you use CPU Contention then?\nPerformance troubleshooting for CPU-sensitive VM.\nIf the value is low, then you don\u0026rsquo;t need to check CPU Ready, CoStop, Power Management and CPU overcommit. The reason is they are all accounted for in CPU Contention.\nIf the value is high (\u0026gt;37.5%), then follow these steps:\nCheck CPU Run Queue, CPU Context Switch, \u0026ldquo;Guest OS CPU Usage\u0026rdquo;, CPU Ready and CPU CoStop. Ensure all the CPU counters are good. If they are all low, then it\u0026rsquo;s Frequency Scaling and HT. If they are not low, check VM CPU Limit and CPU Share. Check ESXi power management. If they are set to Maximum correctly, then Frequency Scaling is out (you are left with HT as the factor), else HT could be at play. A simple solution for apps who are sensitive to frequency scaling is to set power management to max. Check CPU Overcommit at the time of issue. If there is more vCPU than pCore on that ESXi, then HT could be impacting, else HT not impacting. IMHO, it is rare that an application does not tolerate HT as it\u0026rsquo;s transparent to it. Simplistically speaking, while HT reduces the CPU time by 37.5%, a CPU that is 37.5% faster will logically make up for it. There is a corner case accounting issue in %LAT_C that was resolved in ESXi 6.7. VMs with Latency Sensitive = High on ESXi 6.5 or older, will show any \u0026ldquo;guest idle\u0026rdquo; time of vCPUs as LAT_C, for those VMs the counter should not be relied on. This is a corner case because majority of VM should not be set with this, as it impacts performance of other VMs.\nCPU Usage Disparity This metric is required to convince the owners of the VM to downsize their large VMs. It\u0026rsquo;s very common for owners to refuse sizing it down even though utilization is low, because they have already paid for it or cost is not an issue.\nLet\u0026rsquo;s use an example. This VM has 104 vCPU. In the last 90 days, its utilization is consistently low. The Usage (%) counter never touches 40%. Demand is only marginally higher. Idle (%) is consistently ~20%.\nAll the key performance counters such as Guest OS CPU Run Queue are low.\nObviously the VM does not need 104 vCPU. How to convince the owner if he is not interested in refund? The only angle left is performance. But then we\u0026rsquo;re faced with the following:\nCPU Run Queue inside the Guest OS is low. Decreasing CPU will in fact increase it, which is worse for performance. CPU Context Switch is high from time to time. CPU Co-Stop is very low (max of 0.006% in the last 90 days). Decreasing CPU may or may not make it lower. Regardless, it\u0026rsquo;s irrelevant. Same goes with VM Wait and Swap Wait. CPU Ready is very low (max of 0.14% in the last 90 days). The only hope we have here to convince VM owner is to give insight on how the 104 vCPU are used. There are 2 ends of the spectrum:\nIn 1 extreme end, all 104 are balanced. All are running at that low 20%. This triggers an interesting discussion on why the application is unable to even consume a single vCPU. Is this inefficiency the reason why the app vendor is asking for so many vCPU? Commercially, it\u0026rsquo;s wasting a lot of software license. Unbalanced. Some are saturated, while others are not. The Peak among vCPU metric will capture if any of them is saturated. This is good insight. The Min among vCPU is not useful as there is bound to be 1 vCPU among 104 that is running near 0%. The delta between Max and Min will provide insight on the degree of the usage disparity. Does it fluctuate over time? This type of analysis helps the app team. Without it they have to plot 104 vCPU one by one. In reality, there could be many combinations in between the 2 extremes. Other insights into the behaviour of the 104 vCPU are:\nJumping process. Each vCPU takes turn to be extreme high and low, as if they are taking turn to run. This could indicate process ping pong, where processes either do frequent start/stop, or they jump around from one vCPU to another. Each jump will certainly create context switch, like the cache needs to be warm up. If the target CPU is busy, then the running process was interrupted. CPU affinity. For example, the first 10 vCPU is always much busier than the last 10 vCPU. This makes you think why, as it\u0026rsquo;s not normal. Naming wise, vCPU Usage Disparity is a better name than Unbalanced vCPU Usage. Unbalanced implies that they should be balanced, which is not the case. It\u0026rsquo;s not an indication that there is a problem in the guest OS because vRealize Operations lacks the necessary visibility inside the guest OS\nEntitlement Unlike a physical server, you can configure a Limit and a Reservation on a VM. This is done outside the Guest OS, so Windows or Linux does not know. You should minimize the use of Limit and Reservation as it makes SDDC operations more complex.\nEntitlement means what the VM is entitled to. In this example, the hypervisor entitles the VM to a certain amount of CPU. Entitlement is not a fixed value. It\u0026rsquo;s a dynamic value determined by the hypervisor. It varies every second, determined by Limit, Entitlement, and Reservation of the VM itself and any shared allocation with other VMs running on the same host.\nObviously, a VM can only use what it is entitled to at any given point of time, so the Usage counter cannot go higher than the Entitlement counter.\nIn a healthy environment, the ESXi host has enough resources to meet the demands of all the VMs on it with sufficient overhead. In this case, you will see that the Entitlement and Usage counters will be similar to one another when the VM is highly utilized.\nThe numerical value may not be identical because of reporting technique. vCenter reports Usage in percentage, and it is an average value of the sample period. vCenter reports Entitlement in MHz and it takes the latest value in the sample period. This also explains why you may see Usage a bit higher than Entitlement in highly-utilized vCPU. If the VM has low utilization, you will see the Entitlement counter is much higher than Usage.\nVM Counters in the Guest You can provide visibility into the underlying VM to the application team by enabling some CPU counters. The counters are described in this KB article.\nUnmet Demand This is not a built-in counter. You can create it using vRealize Operations super metric.\nWhile the need for such counter sounds logical, the detail is more complex. What do we need this counter for?\nIf it\u0026rsquo;s for Cluster Capacity, then CPU Ready caused by Limit should not be considered. You intentionally place the limit, so the CPU Ready is not caused by the inability of the host. If it\u0026rsquo;s for VM Performance, then it\u0026rsquo;s debatable. If you do not include it, you may miss it. If you include it, the solution is to remove the limit. The problem is the limit could be caused by setting in the resource pool where the VM belongs to. For example, if customer only wants to pay for 10 GHz of resource but insists on running more than that, well, performance will definitely take a hit. The above 2 counters are for CPU slowness. CPU, being the fastest component, typically wait for RAM, Disk and Network.\nCPU Swap Wait. CPU is waiting for Memory. Had RAM were faster, it would have been executed. For example, adding RAM may result in higher CPU usage. CPU VM Wait. CPU is waiting for IO (Disk or Network) and other things (e.g. vMotion stun time). Had they been faster, it would have been executed. For example, replacing storage subsystem with much lower latency would result in CPU completing the task in less time. A 10 hour batch job may take 1 hour, so the CPU usage would be 10x. If disk is outside the ESXi, changing the array can have ramification on ESXi usage. So we should account for it. Should we account for this wait? They are not real demand. It\u0026rsquo;s not an unmet demand. It\u0026rsquo;s a potential demand, which would happen if the other component is improved. Let me know your thought!\nCPU Unmet Demand should only care about whether the VM gets to run or not. It should not care about how fast it will run when it gets to run, because it does not know. As a result, we should not account for HT. The demand was met, albeit at efficiency dropped by 37.5% due to HT effect.\nThe formula I\u0026rsquo;d propose is Ready + CoStop + Overlap + Swap Wait + VM Wait.\nDesigning an OS for multiple hardware classes is hard. Notice Apple MacOS, iPhone OS, and iPad OS. Google has Android and ChromeOS.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLabelled as MLMTD in esxtop. That\u0026rsquo;s Max Limited, not some Multi Level Marketing scam.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAsked to me by Valentin Bondzio in one of the VMworld where we got to meet. Those were the days!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-1---overview/2.1.2-guest-os-vs-vm/",
      "title": "2. Guest OS vs VM",
      "tags": [],
      "description": "",
      "content": "Guest OS and VM are 2 closely related but different entities. They are adjacent layers in SDDC stacks. The two layers are distinct, each provide unique visibility that the other layer may not be able to give. Resource consumed by Guest OS is not the same as resource consumed by the underlying VM. Other factors such as power management and CPU SMT also contribute to the differences.\nThe following diagram uses the English words \u0026ldquo;demand\u0026rdquo; and \u0026ldquo;usage\u0026rdquo; to explain the concept, where demand consists of usage and unmet demand. It does not mean the demand and usage counters in vSphere and vRealize Operations, meaning don\u0026rsquo;t assume these counters actually mean this. They were created for a different purpose.\nI tried adding Application into the above diagram, but that complicated the whole picture that I removed it. So just take note that some applications such as Java VM and database manage their own resources. Another virtualization layer such as Container certainly takes the complexity to another level.\nWe can see from the above that area A is not visible to the hypervisor.\nLayer A Queue inside the Guest OS (CPU Run Queue, RAM Page File, Disk Queue Length, Driver Queue, network card ring buffer). These queues are not visible to the underlying hypervisor as they have not been sent down to the kernel. For example, if Oracle sends IO requests to Windows, and Windows storage subsystem is full, it won\u0026rsquo;t send this IO to the hypervisor. As a result, the disk IOPS counter at VM level will under report as it has not received this IO request yet.\nLayer B What the Guest actually uses. This is visible to the hypervisor as a VM is basically a multi-process application. The Guest OS CPU utilization somehow translates into VM CPU Run. I added the word \u0026ldquo;somehow\u0026rdquo; as the two counters are calculated independently of each other, and likely taken at different sampling time and roll up technique.\nLayer C Hypervisor overhead (CPU System, CPU MKS, CPU VMX, RAM Overhead, Disk Snapshot). This overhead is obviously not visible to the Guest OS. You can get some visibility by installing Tools, as it will add new counters into Windows/Linux. Tools do not modify existing Windows/Linux counters, meaning they are still unaware of virtualization.\nFrom VMkernel viewpoint, a VM is group of processes or user worlds that run in the VMkernel. There are 3 main types of group:\nVM Executable (VMX) process is responsible for handling I/O to devices that are not critical to performance. The VMX is also responsible for communicating with user interfaces, snapshot managers, and remote console. VM Monitor (VMM) process is responsible for virtualizing the guest OS instructions, and manages memory mapping. The VMM passes storage and network I/O requests to the VMkernel, and passes all other requests to the VMX process. There is a VMM for each virtual CPU assigned to a VM. Mouse Keyboard Screen (MKS) process is responsible for rendering the guest video and handling guest OS user input. When you console into the VM via vCenter client, the work done is charged to this process. This in turn is charged to the VM, and not specific vCPU. If you want to see example of errors in the above process, review this KB article.\nLayer D Unmet Demand (CPU Ready, CPU Co-Stop, CPU Overlap, CPU VM Wait, RAM Contention, VM Outstanding IO).\nThe Guest OS experiences a frozen time or slowness. It\u0026rsquo;s unaware what it is, meaning it can\u0026rsquo;t account for it.\nI\u0026rsquo;ve covered the difference in simple terms, and do not do justice to the full difference. If you want to read a scientific paper, I recommend this paper by Benjamin Serebrin and Daniel Hecht.\nAs we cover the CPU, Memory, Disk, Network metrics in their respective sections later in the book, we will explain the differences in more detail. For now, we will provide some examples to drive the point.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-7---availability-management/1.7.2-multi-component-system/",
      "title": "2. Multi Component System",
      "tags": [],
      "description": "",
      "content": "Nowadays we rarely deal with a standalone solution. Even the solutions we think are standalone consists of multiple smaller components. For example, a physical server consists of multiple smaller parts, such as power supply and disks. To calculate the availability of servers we need to consider the availability of each component and the impact it has on the overall availability.\nComponents in Series A series is a serial connection. Think of web server -\u0026gt; application server -\u0026gt; database server.\nThe availability of the overall system with multiple subcomponents in series is calculated as per the following formula:\nLet\u0026rsquo;s consider an example, in this scenario, we have three individual components in series with each other and has 99.9% availability each. The availability of overall system = 99.9 * 99.9 * 99.9 = ~99.7 %\nIn conclusion, we can see that for components in series, the overall availability reduces.\nComponents in Parallel The availability of the overall system with multiple subcomponents in parallel is calculated as per the following formula:\nwhere 1 - Availability of Component i gives us the unavailability of the component.\nLet\u0026rsquo;s consider an example, in this scenario, we have three individual components in parallel with each other and has 99.9% availability each.\nAvailability of the overall system:\nMixed Components Let us consider a more practical system which has both serial and parallel components. For this example, let\u0026rsquo;s take a three tier application with 4 web servers, 2 application servers and 1 database servers. Let\u0026rsquo;s consider availability of all of them to be 99.9% and see what the overall availability will be.\nFirst, we need to calculate the overall availability of the parallel components first. Using the above-mentioned formulas we see the overall availability of Application servers are 99.99% and Web Servers are 99.9999%.\nNext, we need to calculate the overall availability of the components in series. Applying the above-mentioned formula we get the overall availability of ~99.89%.\nThis is the reason we avoid a single point of failure in series with other systems as such components reduces the overall availability.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-6---compliance-management/1.6.2-security-approach/",
      "title": "2. Security Approach",
      "tags": [],
      "description": "",
      "content": "Security in an organization or in a data center specifically is an approach which can be divided into two main areas.\nSecure configuration of the components Security practices or process in place The first point is all about making changes in the environment or products and securely configuring them. For example, if a program expects an input from users, then use proper input validation to protect against unwanted inputs. Another example is using different roles and then Role Based Access Control (RBAC) to ensure only authorized persons get proper levels of access to an environment.\nThe second point is all about process. For example, if you want to make changes to a server, proper approval channel needs to be followed and the changes needs to be documented. The purpose of that is to avoid any unnecessary changes and to track who did what. Typically, organization would have a proper \u0026ldquo;Change Management\u0026rdquo; process in place.\nHere we are covering the first area \u0026ldquo;secure configuration of the components\u0026rdquo;. Within this area there are two different phases. They are detailed below.\nThe first phase is where the initial configuration is done. This includes securely configuring the data center environment (less frequent task) to configuring security for the individual applications (more frequent task). The second phase is all about maintaining and ensuring security on an ongoing basis.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-5---cost-management/1.5.2-price/",
      "title": "2. Price",
      "tags": [],
      "description": "",
      "content": "Price is simply Cost adjusted with margin, discount and penalty. Use price to drive the right behaviour and encourage adoption.\nAs an internal cloud provider, what business problems do you want to solve with pricing?\nOversized VM is a problem that is best solved before the VM hits production. So design your pricing model to encourage the right size from the beginning. Right size, right from the start. Create a progressive pricing and apply discounts for smaller VM sizes. The following diagram shows an example of tiered pricing. Premium pricing is applied on VMs larger than 16 vCPU, while discounted pricing is applied on VMs smaller than 8 vCPU.\nHow do you apply the progressive pricing above into different Classes of Service? How much of a premium should you put on the big VM? How deep should you discount the small VM? The multiplier effect (the progressive tax) cannot be too high because public cloud does not have such tax. They follow a linear pricing. If you use a high multiplier, your price will be too high, or you will absorb a deep loss.\nThe following table provides an example of multiplier.\nWe apply the same principle for RAM.\nKeep your pricing model simple. The more complex your bill, the more you have to explain. The following table provides a suggestion of what to charge and what to bundle. Bundling means you include it in your overall cost but not charge explicitly for it. You are certainly trading off accuracy with simplicity.\nOverly simplified pricing could be unfair to customers, but that\u0026rsquo;s common in other industries. Take the airline industry, where my favourite airline is Singapore Airlines. I notice they have at least 4 generations of planes. The new plane is more efficient, costs less to operate and is more enjoyable to customers. On the other hand, if you take into account depreciation, the old plane is already fully depreciated. And yet, the price is the same across all generations.\nBreak Even When planning your pricing, think of the time required to reach the breakeven point. That period should leave enough time for you recoup your expenses. It should be way before the depreciation ends.\nThe break-even point depends on the break-even level. You may not be able to fully sell all the resources at the end. So if your plan is based on 80% sold, then the price of this 80% has to be able to cover the cost of everything.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-4---configuration-management/1.4.2-review-flow/",
      "title": "2. Review Flow",
      "tags": [],
      "description": "",
      "content": "There are literally thousands of settings that you need to manage to ensure security, performance and availability. To ensure the critical ones are tracked and resolved first, consider prioritizing them. vRealize Operations 8.2 uses a 4-step check, starting from the most urgent.\nStep 1 Address settings that are incorrect, insecure, not following your corporate standards or against best practice. You should correct them as appropriate.\nThis is typically the most urgent step.\nStep 2 The settings are correct, but on older version. It\u0026rsquo;s hard to keep up with all the vendors releases, so you should prioritize those oldest versions, especially those no longer supported.\nA typical SDDC or EUC architecture spans many components. While each can run the latest version, they may not be compatible or supported.\nStep 3 The settings are correct and up to date, but they complicate your IaaS operations. Since you are unlikely to eliminate them all, establish policy that minimize them as part of simplifying your operations.\nStep 4 The last step is about cost and capacity, as there is nothing wrong already. You want to maximize the usage of your resources while minimizing your cost. It\u0026rsquo;s a balancing act!\nNote that each customer runs their operations in unique way. Each operation is like a human fingerprint. So what is right for other customers, may not be right for you. Even in the same environment, what is right for development environment may not be appropriate for production.\nThe following table lists some of the possibilities. Use them as an input to tailor the configuration dashboards to your need. It provides examples of what to check in the IaaS Consumer layer. This layer consists of VM and everything that runs inside the VM, such as process, applications, Guest OS and Container.\nThe next table covers the IaaS Provider layer. This layer consists of the software and hardware infrastructure, such as Telegraf, ESXi, compute cluster, datastore \u0026amp; datastore cluster, resource pool, distributed virtual switch and port group, vSAN, NSX and certainly hardware.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.2-end-to-end-capacity/",
      "title": "2. End-to-End Capacity",
      "tags": [],
      "description": "",
      "content": "Capacity Management becomes easier if you begin with the planning stage. This is where you define your offering, setting the price and performance expectation. Without expectation being set, your customers will demand high performance that you cannot meet with your current infrastructure.\nCapacity Management requires an end-to-end plan and adjustment, because at the end of the day it is about comparing the reality you face with the plan you set. Balancing demand and supply require you to look at these 6 components below. Steps 1 and 2 are done together, and the remaining 4 steps can be done in parallel.\nUnlike Performance Management, this pillar of operations does not require deep technical knowledge. Let\u0026rsquo;s check your technical skills if you don\u0026rsquo;t trust me.\nCan you architect a cluster where the performance matches physical? Easy, just don\u0026rsquo;t overcommit, or put 100% reservation for that VM. Can you architect a cluster that can handle monster VMs? Easy, just get lots of cores per socket. Easy, just get lots of core in the box. Can you architect with very high availability? Easy, just have more HA hosts, more vSAN FTT with failure domains spread across different racks. Easy, just have more HA hosts. Can you architect a cluster that can run lots of VMs? Easy, just get lots of big hosts. Can you optimize the performance? Sure, follow performance best practices and configure for performance. Can you squeeze the cost? Sure, minimize the hardware and software cost, and choose the best bang for the buck. You know all the vendors and their technology. You know the pro and cons of each. The above is not hard to do if you do it right from the start, which is why we need to begin at the planning phase. If you start from Step 6 and ignore Step 1 and 2, you will play the lead role in a Mission Impossible movie.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.2-the-3-realms/",
      "title": "2. The 3 Realms",
      "tags": [],
      "description": "",
      "content": "In the big picture, there are three main realms of enterprise applications. Each realm has its own set of teams. Each team has a set of unique responsibility and hence skills required. The following diagram explains the three realm, alongside with typical layers within each realm and questions being asked.\nPerformance troubleshooting is largely an exercise in elimination. The methodology slices each layer and determines if that layer is causing the performance problem. Hence it is imperative to have a single metric to indicate if a particular layer is performing or not. This primary metric is aptly named Key Performance Indicator. We will cover it more here.\nThe upper layer depends on the layer below it, and hence the infrastructure layer is typically the source of contention. As a result, focus on the bottom layer first, as it serves as the foundation for the layer above it. The good part is this layer is typically a horizontal layer, providing a set of generic infrastructure services, regardless of what business applications are running on it.\nNow, we don\u0026rsquo;t know the impact to the application when there is latency in the infrastructure. That depends on the application. Even on the same identical software, e.g. SQL Server 2019, the impact may differ as it depends on how you use that software. Different natures of business workload (e.g. batch vs OLTP) get impacted differently even on the identical version of the software.\nDepending on the application and infrastructure architecture, there can be more stacks or layers. The following example shows 5 layers. The challenge in performance troubleshooting is the layers may not share context.\nUsing the example above, we can demonstrate how the lack of visibility is making troubleshooting virtually impossible. Let\u0026rsquo;s run through the above. The story starts with a complain as that resonates better.\nAt the Business Layer, you can see the performance of each business transaction. You not only know which user was affected, you know what transaction was affected as the metric has transaction ID. You can trace it in the code as you know how long each function calls take place, assuming you log for every single transaction.\nThe problem starts when you move beyond your code and into Commercial of the Shelves (COTS) software. The software may show that its queue is 10000, which is 5000 more than what the manual say it can handle. But you have no idea if user Joko transaction was in that queue or not. The COTS software metrics do not relate to users anymore, let alone individual transactions. The red explosive icon marks where context is lost.\nMoving from application to infrastructure resulted in another loss of context. Windows or Linux has no idea what applications you\u0026rsquo;re running. As far as the OS is concern, every application is just a process. It will report basic CPU, Memory, Disk and Network utilization per process. More advanced counters are reported at OS-level, system wide. For example, you do not know if your process was the one experienced network packet loss. The packet counter loss is a system-wide metric.\nMoving from individual EC2 or VM to the shared infrastructure results in another loss of context. In the case of public cloud, you may not get visibility into the physical layers at all.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/acknowledgements/",
      "title": "Acknowledgements",
      "tags": [],
      "description": "",
      "content": "Below is a list of the initial VMware staff involved in writing and contributing to the original content on this site. This list is no longer updated, as we are only accepting and tracking contributions via GitHub.\nCredit Sajal Debnath Mehmet Hakan Can Brock Peterson Varghese Philipose Brandon Gordon Andy Bidlen Thomas Kopton Norman Goh Sean Lambert Sunny Dua Additional contributors:\nHakob Arakelyan Felix Azizyan Tigran Mkrtchyan Anna Grigoryan Anahit Serobyan Artur Aghabekyan Gagik Manukyan Vahan Tadevosyan Tigran Avagimyants Tigran Matevosyan Robert Mesropyan Arman Mkrtchyan Kim Ramirez Nareg Kirkian Lusine Dashtoyan Varun Gajjar Abhishek Chouksey Valentin Bondzio Richard Xunjia Lu Ming Hua Zhou Paul James Tas Tareq Sajag Chaturvedi Jodi Shely Julian Foo Claud Antao Jesus Velasco Luciano Gomes Lerpong Intaraworrapath "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-2---operational-maturity/",
      "title": "Chapter 2 - Operational Maturity",
      "tags": [],
      "description": "",
      "content": "Chapter 2 Operational Maturity 1. Gap Analysis\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-3---sddc-vs-iaas/",
      "title": "Chapter 3 - SDDC vs. IaaS",
      "tags": [],
      "description": "",
      "content": "Chapter 3 SDDC vs. IaaS What you architected is SDDC, but what you operate is IaaS. You buy system, you sell service.\nThis chapter provides an introduction to how IaaS management differ to the physical infrastructure management. It is placed at the end as this is now considered a basic knowledge. I still find it useful in explaining why the complexity goes up significantly. IDC actually predicts this back in 2012. The link from APM Digest website states that \u0026ldquo;operational complexity in virtualized, scale-out, and cloud environments and composite Web-based applications will drive demand\u0026rdquo; for a new type of tools that can \u0026ldquo;rapidly sort through hundreds of thousands of monitor variables, alerts and events\u0026rdquo;.\n1. VM, it is not what you think!\r2. SDDC vs HDDC\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-4---super-metrics/",
      "title": "Chapter 4 - Super Metrics",
      "tags": [],
      "description": "",
      "content": "Chapter 4 Super Metrics I\u0026rsquo;ve used the product since 1.0. When I first saw super metrics, it was one of those \u0026ldquo;is this created for me?\u0026rdquo; moment. The ability to analyze hundreds of metrics by creating my own metrics enabled me to do my job better. I was a pre-sales engineer but I spent a lot of time helping my customers troubleshooting and optimizing their environment.\n1. What Is a Super Metric?\r2. How to Create a Super Metric\r3. Examples\r4. Advanced Examples\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-9---infrastructure-architect/4.9.3-delivering-a-lasting-presentation/",
      "title": "3. Delivering a Lasting Presentation",
      "tags": [],
      "description": "",
      "content": "As an infrastructure architect, I get to present a lot. It can be public speaking in large events such as VMworld, or presenting to a small group. Certainly, all of us who have been working with VMware for a long time can just stand up and present, especially if it\u0026rsquo;s a technical topic. After all, the content is all in the brain.\nHowever, I learned that the difference between a great presentation and a good presentation is much larger than what I thought. Much larger than the different between a good presentation and an average presentation.\nA great presentation has that lasting impact. It goes beyond educating. It changes the listener\u0026rsquo;s paradigm. They remember the key message long after they have forgotten the specific content. It gets put deep into their heart. Another word, you\u0026rsquo;ve calibrated their thinking with yours.\nSo what makes a great presentation?\nA great presentation\u0026hellip;\nlooks natural (as if you speak from your heart, not your brain) is both humble and authoritative is both funny and deep is both engaging and relaxing is both entertaining and enlightening and truly leaves a moment of truth. I find that delivering a great presentation is very hard. I normally take around 40 hours to prepare a 40 minute presentation. The less technical the topic, the longer it takes. The less technical the audience, the longer it takes. The less interaction I have (e.g. due to large size), the longer it takes.\nI created all the slides manually, I typed every word I want to say in the speaker notes section of Power Point, Then I rehearsed, rehearsed and rehearsed. I time myself if time is a constraint. For an important event, you are right to guess, pretty much the whole thing is memorised from so much of darn rehearsal!\nSo anytime you see me speak naturally, it was more like virtually natural.\nTo me, a great presentation is like an entertainment. How long does a singer practice and rehearse for that 4 minute song? Much more than we vrealize or will ever know!\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.3-object-model/",
      "title": "3. Object Model",
      "tags": [],
      "description": "",
      "content": "A critical foundation in managing a mission critical VDI is the object model. This means the objects and relationship among the objects. It will be impossible to roll up if the correct hierarchy is not in place. The object model also plays a critical role in navigating the structure of a large Horizon set up. It complements the tabular presentation by showing relationship and hierarchy clearly.\nvRealize Operations 8.4 sports a new adapter, replacing the previous adapter (called V4H). It sports a revamped object model, blending vSphere and Horizon objects as one traversal path, as shown in the following diagram.\nThe object model introduces a new super parent object called Horizon World, to make dashboard creation easier and support cloud provider who provides Horizon as a service.\nBecause of the revamped object model, there is no migration from the old adapter (V4H) to this new adapter.\nTake note of a special object called Application Session. This object can be RDS or VDI. If it\u0026rsquo;s RDS, naturally it has less metrics.\nHorizon + vSphere The following shows an example of how the implementation is vrealized. Notice how vSphere objects and Horizon objects are blended in a single hierarchy. The object in blue is Horizon, while the object in green is vSphere.\nThe interwoven hierarchy is required for summarizing information.\nNotice the farm name Site02-Fram. Why is it directly under a Pod?\nThe answer is it\u0026rsquo;s a manual farm. The hierarchy is aware that you can have manual pool across vCenter and will show it accordingly.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-7---vmware-it-operations/4.7.3-post-implementation-review/",
      "title": "3. Post-Implementation Review",
      "tags": [],
      "description": "",
      "content": "When we measured system performance three months after implementation, the alerts to actionable alert ratio for infrastructure monitoring had improved by 20% whereas proactive monitoring had helped us reduce incidents by 10%.\nIn addition to eliminating the cost for a third-party monitoring tool, vRealize Operations delivers:\nMonitoring tool isolates issues quickly Application owners self-check their application health Application owners can create their own application specific dashboards Operations team works on the system proactively Infrastructure team uses monitoring data to plan for capacity use Application management packs provide a deeper level of application-specific metrics. Ease of plugging in objects for auto-discovery by using various adaptors and API suites to automate operational work Overall, we\u0026rsquo;re providing an improved monitoring solution to our service owners. It is customized to meet their specific application requirements, including when to generate system alerts and notifications.\nOur new monitoring posture enables us to accommodate future growth requirements and prepares us to embrace migration from on-prem to cloud monitoring solutions such as vRealize Operations Cloud.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-6---automation/4.6.3-incoming-communication/",
      "title": "3. Incoming Communication",
      "tags": [],
      "description": "",
      "content": "With the almost limitless capabilities of the vRealize Orchestrator adapter we are able to build sophisticated automation tasks and yet it is still an open loop.\nOf course, we can implement the actual workflow to execute other workflows and possibly include other systems to contribute to the overall automation process but how do we close the loop back to vRealize Operations? And yes, you are right if you now say: \u0026ldquo;Hold on Thomas, we closed the loop, the action may influence the behavior of a certain object in vCenter, which in turn has impact on metrics collected by the adapter instance.\u0026rdquo; This in fact may close the loop, but I would like to have something more tightly connected to the entity executing the action, something more powerful working really in context of my automated actions, giving me all options to quickly get back to vRealize Operations and immediately check the impact my actions have. Having the control over what objects I need to inspect, or retrieve additional data from to take more sophisticated actions.\nWhat options do we have to get back to vRealize Operations and retrieve more information? Can we extend what vRealize Operations is managing with custom object types and metrics? Let\u0026rsquo;s find out!\nREST API vRealize Operations provides a comprehensive REST API for interaction with the solution. Since the 8.2 release the REST API documentation is accessible as Swagger UI and available on every vRealize Operations instance via: https://vrops-fqdn/suite-api\nSwagger UI makes it easy to try out the available methods before the actual implementation in code. The first step, no matter if using the Swagger UI or within the actual implementation is the authorization. In the actual code we vRealize Operations requires the usage of the acquire POST method to retrieve an object that includes token and its validity. This token is used in the subsequent REST calls. The next picture shows the acquire token method in the Swagger UI.\nThe Swagger UI provides an easy way to find the appropriate method - just type in your search term and see what is available. In the next picture you can see the available methods around Alerts (shortened).\nThe REST API provides access to all managed objects, their metrics and properties as well as to vRealize Operations constructs like Alert and Symptom Definitions, Recommendations etc. With appropriate permissions one can not only read information, but new information can also be added to vRealize Operations. \u0026ldquo;New information\u0026rdquo; means entirely new custom object types with own set of metrics and properties as well as custom metrics and properties added to existing objects collected by vRealize Operations adapter instances.\nThe next picture shows the REST API POST method for adding custom metrics to existing resources specified by their vRealize Operations ID.\nIt is important to know that the available methods are divided into a group of definition of public API and an internal API. Please not, that the internal API should be used at own risk as the available methods may be changed or dropped in any upcoming release without further notice whereas the public API is considered stable.\nAn amazing use case building upon the vRealize Operations REST API is the vRealize Operations Export Tool (vrops-export) written by Pontus Rydin. It is a utility for exporting data from vRealize Operations.\nThe newest version, as for the time of writing these words, can be found here.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-4---super-metrics/4.4.3-examples/",
      "title": "3. Examples",
      "tags": [],
      "description": "",
      "content": "I will provide some examples demonstrating the various features of super metrics functions and operators. More is covered in the manual.\nThere are also many examples in the repository of super metrics.\nBasic Functions The maximum, minimum, average and sum functions are simple functions that can quickly summarize a large number of objects.\nMaximum CPU Ready (%) among VMs within a group of clusters providing same class of service: max( ${ adaptertype=VMWARE, objecttype=VirtualMachine, metric=cpu|readyPct, depth=3 } )\nMaximum Memory Balloon (%) among VMs within a group of clusters providing same class of service: max( ${ adaptertype=VMWARE, objecttype=VirtualMachine, metric=mem|balloonPct, depth=3 } )\nDepth=3 is used since the super metric is applied at a custom group level which is 3 levels up the VM object whose metric is used. The hierarchy is Group -\u0026gt; Cluster -\u0026gt; ESXi Host -\u0026gt; VM.\nIf you use the same super metric for different levels, specify the deepest one.\nSum of vCPUs provisioned on all VMs in a group of VM: sum( ${ adaptertype=VMWARE, objecttype=VirtualMachine, metric=cpu|corecount_provisioned, depth=1 } )\nDepth=1 is sufficient as the VM is directly under the group. No need to manually change the depth.\nAverage of CPU Usage with all VMs in a custom group: avg( ${ adaptertype=VMWARE, objecttype=VirtualMachine, metric=cpu|usage_average, depth=3 } )\nReturn CO2 Emission if the metric exists. If not, return 0.744 by default ${this, metric=CustomProperty\\|CO2 Emission, defval=0.744} The above is handy if the metric may not exist and you want to specify a default value.\n\u0026lsquo;Where\u0026rsquo; Clause Things get more powerful and complex once you need to specify a condition.\nUse Case: Count of all VMs in the environment which has CPU usage greater than 60% at that time.\ncount( ${ adaptertype=VMWARE, objecttype=VirtualMachine, metric=cpu|usage_average, depth=5, where=($value \u0026gt; 60) } ) You specify 60 not 60% or 0.6. It has to match the metric value.\nThe above formula requires version 8.1 or later.\nUse Case: Count of all Microsoft Windows VMs.\nThat means you need to do a string comparison. You also need to know the actual values used by the property field.\ncount( ${ adaptertype=VMWARE, objecttype=VirtualMachine, attribute=summary|guest|fullName, depth=5, where=\u0026#34;summary|guest|fullName startsWith Microsoft Windows\u0026#34; } ) Use Case: Identify the percentage of VMs with CPU Ready \u0026gt; 1%.\nThat means you need to divide the number of VM against the total number of running VM.\ncount( ${ adaptertype=VMWARE, objecttype=VirtualMachine, metric=cpu|readyPct, depth=8, where=\u0026#34;\u0026gt;1\u0026#34; } ) / ${ this, metric=summary|running_vms } * 100 The last line in the code is to manually convert into percentage.\nUse Case: Count of all VMs with CPU usage \u0026gt; 70% OR memory usage \u0026gt; 60%\nThis is a double comparison, with an OR clause. The formula gets complex as super metric is actually a run time code that gets executed directly. There is no translation!\ncount( ${ adaptertype=VMWARE, objecttype=VirtualMachine, metric=cpu|usage_average, depth=8, where= ( $value \u0026gt; 70 || ${ metric=mem|usage_average } \u0026gt; 60 ) } ) Notice the first comparison simply uses the variable $value, because it\u0026rsquo;s actually defined in the metric=.\nUse Case: Count of all VMs which are not Windows based or Redhat based.\nThis means you need to negate the comparison. The negation has to be done outside the two comparison.\ncount( ${ adaptertype=VMWARE, objecttype=VirtualMachine, metric=summary|guest|fullName, depth=5, where= (! ($value contains \u0026#39;Microsoft Windows\u0026#39; || $value contains \u0026#39;Redhat\u0026#39;) ) } ) If Then Else This takes you deeper into Java programming\nUse Case: Count of provisioned vCPUs and if it is equal to 4, return value \u0026ldquo;1\u0026rdquo; and if it is not equal to 4, return a value \u0026ldquo;0\u0026rdquo;.\ncount( ${this, metric=cpu|corecount_provisioned, depth=1, where= ($value == 4)} ) ? 1 : 0 Above formula requires version 8.1 or later.\nUse Case: Find the \u0026ldquo;Actual Recommended vCPU\u0026rdquo; for a VM.\nWhile using the rightsizing feature, vRealize Operations provide the vCPUs to be removed or added based on if it is an oversized or undersized VM. The following logic can be used find the actual recommended values:\nIf the value of Recommended vCPUs to add is 0,\nthen Actual Recommended vCPU = Provisioned vCPUs - Recommended vCPUs to remove (as an Oversized VM ),\nelse Actual Recommended vCPU = Provisioned vCPUs + Recommended vCPUs to add ( as an Undersized VM ).\n${this, metric=summary|undersized|vcpus} == 0 ? ( ${this, metric=cpu|corecount_provisioned} - ${this, metric=summary|oversized|vcpus} ) : ( ${this, metric=cpu|corecount_provisioned} + ${this, metric=summary|undersized|vcpus} ) This formula uses the $this, a reference to the object itself. So the context is not other object.\nFor completeness, let\u0026rsquo;s do the same for memory. Since the default unit is KB, we would like to convert into GB.\nIf the value of Recommended Memory to add is 0,\nthen Actual Recommended Memory = Provisioned memory - Recommended Memory to remove (as an Oversized VM),\nelse Actual Recommended Memory = Provisioned Memory + Recommended Memory to add (as an Undersized VM)\n( ${this, metric=summary|undersized|memory} == 0 ? ( ${this, metric=mem|guest_provisioned} - ${this, metric=summary|oversized|memory} ) : ( ${this, metric=mem|guest_provisioned} + ${this, metric=summary|undersized|memory} ) ) / 1048576 "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-1---quiz-answers/4.1.3-part-3-dashboards/",
      "title": "3. Part 3 - Dashboards",
      "tags": [],
      "description": "",
      "content": "Dashboard: NOC The heat map is showing dark grey and light grey to convey wastage and data error, respectively. While the use case is performance, there is a need to educate that oversized VM cause performance issue.\nSee this for more.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-9---other-dashboards/3.9.3-vm-migration/",
      "title": "3. VM Migration",
      "tags": [],
      "description": "",
      "content": "When you are migrating your customers workload to another infrastructure, the onus is on you to prove that You are not causing problems to the VMs or Applications. This is especially true if it\u0026rsquo;s your idea to migrate, and You are not giving them a choice.\nThere are many examples of migration. Popular ones are:\nFrom old DC to new DC. From on-prem to VMware Cloud on AWS. From on-prem to Cloud. This is typically VMware-based cloud as you can simply move without changing VM. In the above, you typically change all infrastructure. New server, new network, new storage, new vSphere. You may virtualize network by adding NSX. You may also virtualize storage by going vSAN.\nRegardless, your Application Team do not and should not care. It\u0026rsquo;s transparent to them. In fact, it should be better as You are using faster \u0026amp; bigger hardware. You have more CPU cores, faster RAM, faster storage, bigger network, less network hops, etc.\nAnd that\u0026rsquo;s exactly where the problem might start.\nA VM that takes 8 hours to complete its batch job may now take 2 hours, all else being equal. So it completes the same amount of work, doing as many disk, network, CPU, memory operations in 4x shorter duration.\nSo what happens to the VM IOPS? Yes, it went up by 400%, all else being equal.\nWhat happens to VM CPU Usage? It also went up by 400%. It has to, as it completes the same amount of logic. Suddenly, a VM that runs relatively idle at 20% becomes highly utilized 80%.\nAll the above is fine, if not for the next factor. Can you guess what is it?\nHint: it\u0026rsquo;s how you justify the budget to your management.\nYes, you promise higher consolidation. You have more CPU cores, more RAM, so logically you use higher over-commit ratio. As Mark Achtemichuk said in this article, use it carefully.\nSince you have to increase overcommit ratio, how do you then prove that performance will not be affected as you drive utilization higher?\nThe answer is to look at what KPI can impact a VM performance. A VM Owner looks at her VM performance, not your IaaS utilization. The VM Contention dashboard is designed for that.\nMoving a busy VM to another ESXi only needs to see the VM external footprint. It matters not if Guest OS is doing excessive memory paging or has long CPU run queue. None of these internal works are visible by the hypervisor, hence they are irrelevant.\nBefore vs After comparison cannot be done immediately after a VM is migrated. The First VM will experience greatest performance improvement. It is the only VM in the VMC cluster, so it has 0 contention. The Last VM will experience greatest performance degradation. It was the only VM in the on-prem cluster, so it had 0 contention.\nThe following table shows a sample design of a comparison dashboard. It has two identical columns, allowing you to do show before vs after comparison.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-8---true-visibility-suite-dashboards/3.8.3-netapp-storage/",
      "title": "3. NetApp Storage",
      "tags": [],
      "description": "",
      "content": "The NetApp FAS \u0026amp; AFF Aggregate Details is generally used by storage administrators to explore the health, capacity position, and performance of their NetApp FAS \u0026amp; AFF Aggregates. It can be used as an environmental overview type dashboard, showing capacity managers their current capacity position. It can also be used to find potential performance issues.\nThis is a custom dashboard. You can download it here on VMware {code}:\nThe NetApp FAS \u0026amp; AFF Aggregate Details dashboard was designed to show the performance and capacity position of all NetApp FAS \u0026amp; AFF Aggregates. It is designed to flow from top left to the bottom, allowing the user to select an Aggregate and all other widgets will be populated. The widget interaction looks like this.\nHow to Use Select an Aggregate in the top left View widget, which will drive all other widgets. The top left View was configured to show a list of Aggregates, their Health, State, and Status. The View uses red/yellow/green colors to reflect the spectrum from bad to good. Here is the View showing the Health metric colors.\nOnce an Aggregate has been chosen, all other widgets will be populated. Just below the list of Aggregates you will see Aggregate state and status. To the right you will see all Alerts. The vRTVS management pack for NetApp FAS \u0026amp; AFF consumes all NetApp OCUM/AIQUM generated alerts. The Alert List widget here shows all Alerts (both active and inactive) for the Aggregate and any child objects, but this is configurable. If you only want to see active alerts, edit the widget, go to Output Filter - Alert Related, and select the Active box.\nThe Status Scoreboard has been configured to show the immediate value of the metric and its history. Hovering over a metric gives you the details behind it and the ability to double click for more details.\nDouble clicking gives you a timeline for that particular metric and the ability to see things like dynamic thresholds, adjust timelines, and more.\nNext is a row of Metric Chart widgets showing IOPS, Latency, and Throughput for the selected Aggregate, giving the user visibility into the current performance of the Aggregate and how it compares historically.\nIn the top right of each Metric Chart widget there are two buttons, one graph icon and the ellipses (three vertical dots) for more detail. Hovering over the graph indicates that it\u0026rsquo;s for Correlation.\nCorrelation gives us the opportunity to correlate the existing metric with other metrics on this particular object or against other metrics on peer objects. Choosing the Self-Metrics tile will show you other metrics on the same object that are behaving similarly.\nThe final row in this dashboard is a Scoreboard widget showing capacity metrics over time. All features previously discussed are applicable here as well.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-7---executive-summary-dashboards/3.7.3-capacity-summary/",
      "title": "3. Capacity Summary",
      "tags": [],
      "description": "",
      "content": "This dashboard is used by the Ops team to explain capacity to the IT Management team. It works together with the Inventory Summary dashboard. The inventory provides details on available resources and what is running on these resources. The capacity provides details on the remaining capacity and time.\nDesign Consideration See the Executive Summary Dashboards page for common design consideration among all the dashboards for IT senior management.\nHow to Use The dashboard has 2 sections.\nThe top section provides summary at the vSphere World level. The bottom section enables drill down into individual compute or storage capacity The weekly average of VM growth is displayed to provide holistic visibility of overall growth across all Data centers for both running and powered off workloads. If the increase in VM count is not accompanied by corresponding increase in utilization, these newly provisioned VMs are likely not yet used.\nOvercommit Ratio highlights the efficiency gained by vSphere virtualization running multiple workloads on shared infrastructure. It is important to note that overcommitment needs to be further reviewed in conjunction with elevated resource contention (refer to contention dashboards) to understand the performance impact when running VMs competing for resources. In general, Overcommit is required to be financially more economical than the public cloud. As a reference, AWS typically overcommits CPU 2:1 by counting the hyper-threading and does not overcommit memory. Note: vRealize Operations uses Physical CPU Cores not Logical Cores (Hyper-threading) for all CPU-based capacity calculations\nThe bottom part of the dashboard is split into 2 columns:\ncompute storage Network is not added due to its nature. It\u0026rsquo;s an interconnect, not nodes, so capacity is much harder to compute.\nThe dashboard uses the term compute (and not vSphere Cluster) and storage (and not vSphere datastore) to keep the visual simple.\nThe two columns have identical design. The heat map displays capacity by size and colored by time remaining. However, for compute the size of each box in the heat map is fixed as there is no single metric to represent the size. A cluster size can be measured in 4 different ways (No of ESXi Hosts, Total CPU GHz, Total CPU cores, and Total Memory).\nHere is what the compute portion looks like. The heat map is interactive. By selecting one of the cluster, you can further drill-down to clearly understand remaining capacity and time (in days).\nHere is what the storage portion looks like. They are designed to be similar\nPoints to Note Capacity Remaining is not shown at the world level as it could be misleading, especially in global or large infrastructure. Clusters also tend to serve different purpose, and they are not interchangeable. If you are using both on-prem and external cloud, for example, VMware on AWS, consider splitting the dashboard into 2 columns. You would need extra screen real estate though. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-6---noc-dashboards/3.6.3-live-cluster-utilization-dashboard/",
      "title": "3. Live Cluster Utilization Dashboard",
      "tags": [],
      "description": "",
      "content": "This dashboard complements Live! Cluster Performance dashboard. Use this dashboard to view the clusters and ESXi hosts within those clusters that are working excessively and are close to their physical limit. This dashboard displays ESXi hosts which have CPU or Memory saturation, and which can lead to performance issues for the VMs running on the host.\nAs this dashboard is designed to complement the Live! Cluster Performance dashboard, it shares the same design consideration.\n2 counters for Memory are used as Consumed metric alone is not enough. It could be mostly cache or historical data. Balloon also persist (past data), but at least it gives an insight of ESXi under memory pressure.\nHow to Use As this dashboard has identical design with the Live! Cluster Performance dashboard, it has the same usage procedure.\nThe dashboard help answer the following questions:\nIs the IaaS running very high utilization right now? Do we size ESXi correctly, meaning balanced usage of CPU and Memory? Are the clusters balanced? Are load distributed equally among member ESXi hosts? Is all ESXi contributing? Light grey box indicates that the host is part of the cluster but there is no utilization. It is likely the host is in maintenance mode or is powered off. The following heat maps are designed to work as one set. Notice the arrangement of the boxes are identical across the 3 heat maps. If you guess that an object is placed in the same location in all the heat maps, you are right! This identical position means you can quickly see if a particular ESXi or cluster is having what problem.\nUnlike the heat maps in the Live! Cluster Performance dashboard, the 3 heat maps in this dashboard has a different scale, reflecting the different nature of the counters.\nLogically, memory is a form of storage. It acts as a cache to disk as it\u0026rsquo;s much faster. Hence a high utilization is better, as that means more data is being cached. The ideal situation is when ESXi Consumed metric is red but ESXi Ballooned metric is green. When Ballooned is red and Consumed is grey, it means it was likely high in the past but not anymore. The reason the ballooned stays red because the ballooned pages were never requested back.\nBallooned memory counter was chosen over the swapped or compressed memory counters as it\u0026rsquo;s a better leading indicator. Because all 3 can co-exist at the same time, all 3 are shown in the line chart. Ballooned is shown in absolute amount and not percentage, as the higher the size the higher the chance it might impact a VM. If you feel using percentage is easier for your operations, create a super metric to translates the value.\nQuiz Time: why is the heat map showing grey and light grey?\nPoints to Note ESXi choose swapping over compression if the compression ratio is less than 4x. If you have the screen real estate and your network is highly utilized, add a Heat Map to check the ESXi physical NIC Network Throughput. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.3-cluster-configuration/",
      "title": "3. Cluster Configuration",
      "tags": [],
      "description": "",
      "content": "Use this dashboard to view the overall configuration of vSphere clusters in your environment, especially the configuration that need attention.\nThe dashboard is designed with the same considerations that are common among all the configuration management dashboards.\nHow to Use The dashboard is organized into sections for ease of use.\nThe first section shows 3 bar charts. They correspond to the 3 main features of vSphere clusters, namely High Availability HA, Dynamic Resource Scheduler DRS and Distributed Power Management DPM.\nHA: The best practice is to enable HA admission control. You can specify the Admission control Policy in vCenter and the threshold for failover shares. DRS: The best practice is to have DRS enabled. Think of a vSphere cluster as a single logical computer that balance within itself. DPM: The best practice is to enable DPM in an environment where environmental concern is the top priority or the high peak rarely occurs (most of the time You are running very low utilization). The second section of the dashboard shows 8 pie charts. They show the relative distribution of key configurations.\n2 bar charts cover Admission Control. You should enable admission control. The pie chart displays the policy code instead of the policy name, as it is based on the property Cluster Configuration | Das Configuration | Active Admission Control Policy. The mapping between code to name is: -1 = Disabled 0 = Cluster Resource percentage 1 = Slot Policy (Powered-on VMs) 2 = Dedicated Failover Hosts 2 bar charts cover the HA Failover Share, one for CPU and one for memory. 2 bar charts cover DRS setting. Generally speaking, you want to have DRS fully automated, meaning no operator intervention is required for both initial VM placement and subsequent load balancing, but with a moderate migration threshold (value = 3.0). The value range from 1.0 to 5.0. There are 2 pie charts showing reservation, one for CPU and one for memory. Minimize the total reservation value as it prevents overcommit of resources and hence results in a less optimal utilization. Memory reservation can remain and occupy the memory space of the ESXi host even though the VM does not use the memory anymore. Consider the analogy of unused files that you have not opened for months in your laptop c:\\ drive. They still take up space of the hard disk. Keep the number of distinct shares below three (or at a minimum), matching the distinct classes of service. The third section of the dashboard shows 2 bar charts. They show the absolute distribution of cluster.\nThe first shows the cluster grouped by the number of ESXi Hosts. Ensure this matches your plan and cluster sizing standards. Small clusters (defined as having less ESXi hosts) have higher overhead while large clusters have a higher risk in case of cluster-wide outages. For large cluster, have a disaster recovery plan an unexpected cluster-wide outage can impact many VMs. Performance risk is lower in large clusters partly because there are more nodes that DRS can tap on, but if there is an actual problem troubleshooting can be harder (because there are more nodes to analyze). In large environment, small clusters can result in cluster sprawl. The fourth section of the dashboard lets you drill down into individual cluster.\nIt begins with a table listing all the clusters with their key configuration. You can export this list as a spreadsheet for further analysis or reporting. Select a cluster. The list of ESXi Hosts under the cluster, along with shares and resource pools information, is automatically filled up. Ensure as all its ESXi Hosts have identical configuration. Keep the number of distinct shares below three (or at minimum), matching the distinct classes of service. You should avoid giving different service level to individual VMs as that increase the complexity of the cluster performance. Verify that Shares are used consistently throughout your entire vSphere environment. Do note that they are relative numbers, not absolute. Ideally, avoid using it altogether as it\u0026rsquo;s easy to overlook. When you move VM to another cluster or vCenter, you may forget to set the new share appropriately. Keep the number of resource pools minimal. Resource Pools can impact performance, if the number of VMs in the pool do not match its intended shares. The new Scalable Shares feature in vSphere 7 automates this adjustment, which has to be done in older version. More about it here. Some of the columns are color coded to facilitate quick reviews. Adjust their threshold to either reflect your current situation or your desired ideal state Points to Note The number of buckets on the pie chart or bar chart are balanced between the available screen estate, ease of use and functionality. Modify the buckets to either reflect your current situation or your desired ideal state. In a large environment, create a filter for this dashboard. Group by the class of services such as, Gold, silver, and bronze. Default the selection to Gold. In this way, your monitoring is not cluttered with less critical workloads. You might notice that the DRS Migration Threshold widget is using the property DRS vMotion Rate. This is the correct property. We will correct the property name so it\u0026rsquo;s less confusing. The HA Memory Failover Shares widget should be named HA Memory Failover percentage. This is a known typo. The HA CPU Failover Shares widget should be named HA CPU Failover percentage. This is a known typo. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/3.3.3-esxi-capacity/",
      "title": "3. ESXi Capacity",
      "tags": [],
      "description": "",
      "content": "The ESXi Capacity dashboard supports the Cluster Capacity dashboard by providing the next level of details. It is also required for the non-clustered ESXi.\nSee the Capacity Dashboards page for common design consideration among all the dashboards for capacity management.\nHow to Use The Summary heat map provides an overall view of ESXi Hosts capacity, grouped by their clusters.\nEach ESXi Host is represented by a box, showing their capacity remaining. The ESXi host size has been made constant for ease of use. If your ESXi sizes are not standardized, consider using the number of physical cores or Total CPU GHz to show the size difference. Check that the smallest ESXi does not become too small. About the ESXi Hosts Capacity table\nThe table lists all the ESXi hosts in your environment, grouped by their parent cluster. Standalone ESXi will be shown at the bottom under \u0026ldquo;No Group\u0026rdquo; In a large environment with many data centers, you can zoom into specific vCenter or Data center. You can also filter or search for specific ESXi hosts matching certain names. The 99th percentile Performance column takes the 99th percentile value of the ESXi Performance (%) metric. The reason we\u0026rsquo;re not taking the worst performance (which is equivalent to 100thpercentile) is to rule out outlier. In addition, the performance threshold has been set to be stringent. Select one of the ESXi\nAll the 3 line charts will automatically show the trend of selected ESXi Host. Both total and usable utilization in terms of memory and CPU are displayed Utilization displayed for three months and not one week. The daily average is displayed and not the hourly average and the focus is on memory consumed and not memory active. Note that memory consumed includes the total memory consumed, so it includes memory consumed by VMkernel. Points to Note If you find it useful, add a drill-down to the VM Capacity dashboard. A logical place to initiate this drill down is in the ESXi Hosts Capacity widget. Link this widget into the table of ESXi Host in the destination dashboard. A technology refresh is often used to address capacity shortage. Consider adding a property widget that shows the hardware model and specification to help you determine the age of the hardware. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.3-cluster-utilization/",
      "title": "3. Cluster Utilization",
      "tags": [],
      "description": "",
      "content": "The Cluster Utilization dashboard complements the Cluster Contention dashboard. Together, their goal is to help VMware Administrator in performance management.\nDesign Consideration This dashboard is designed to support the Cluster Contention dashboard. Use it to identify vSphere clusters with high utilization in a selected data center. When utilization exceeds 100%, performance can be negatively impacted especially when VMs experience contention. By default, vRealize Operations has a 5-minute collection interval. For 5 minutes, there may be 300 seconds worth of data points. If a spike is experienced for a few seconds, it may not be visible if the remaining of the 300 seconds is low utilization.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nHow to Use Review the 2 distribution charts\nThey give an overview of all the clusters CPU utilization and memory utilization. The highest metric in the last 1 week is used. Average or 95thpercentile is not used as this is utilization, not contention. High utilization does not mean bad performance. 1 week is used instead of 1 day to give you a longer time horizon and cover the weekend. Adjust the timeline as you deem fit for your operations. Expect memory to be higher than CPU, as it\u0026rsquo;s a form of cache. The Memory Consumed counter is used, as it\u0026rsquo;s more appropriate than the Memory Active counter. Low utilization can actually indicate bad performance, as not much of real work got done. The chart uses the color dark grey for low utilization. Review the Clusters Utilization table\nIt lists all the clusters, sorted by the highest utilization in the last 1 week. If the table is all showing green, then there is no need to analyze further. You can change the time period to the period of your interest. The maximum number will be reflected accordingly. Select a cluster from the table\nAll the utilization charts will automatically show the key utilization metrics of the selected cluster. For memory, the high utilization counters are explicitly shown. Balloon, Compressed, Swapped. Notice they exist even though utilization is not even 90%, indicating high pressure in the past. If you look at only utilization, you\u0026rsquo;d think you are safe! The line charts shows both average and highest among ESXi host in the cluster. The reason is unbalanced is not rare. There are many settings that can contribute to it (e.g. DRS settings, VM Reservation, VM - Host Affinity, Resource Pool, Stretched Cluster, Large VM). So check all these as unbalanced cluster is quite common, especially in large clusters. The disk IOPS is split into read \u0026amp; write to gain insight into the behaviour. Some workloads are read-oriented, while others are write-oriented. The disk throughput is not shown as it sums all the traffic. In reality, each ESXi has its own limit. The vMotion line chart is added as a high number of vMotion can indicate the cluster load is volatile, assuming the DRS Automation level is not set to the most sensitive setting. Points to Note If your operations team has a standard that utilization should not exceed a certain threshold, you can add that threshold value into the line chart. The threshold line will help less technical teams as they can see how the real value compares with the threshold. See the Points to Note section of Cluster Contention dashboard as this dashboard is designed to complement it. Consider adding a 3rd distribution chart. Show the balloon counter in this 3rd chart, as it complements the consumed counter. As long as there is no ballooning, a very high consumed value is in fact better than a lower value. The Workload metric can exceed 100% because it\u0026rsquo;s demand / usable capacity * 100. So this could happen if you have 4 hosts in a cluster with each host running at 100% demand and admission control is set to 50%. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.3-interaction/",
      "title": "3. Interaction",
      "tags": [],
      "description": "",
      "content": "Take advantage of the interaction while ensuring they remain logical and consistent. Logically design the dashboard first using any drawing tools so you can see the flow of information.\nA rich interaction will increase the functionality of the dashboard. If possible, aim for a symmetrical interaction as it\u0026rsquo;s easier for the dashboard consumer to understand. The following shows 4 heat maps driving 4 line charts. It looks complicated but feels natural when used.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-6---other-metrics/2.6.3-vsphere-cluster/",
      "title": "3. vSphere Cluster",
      "tags": [],
      "description": "",
      "content": "The metrics at cluster level is basically an aggregation of its ESXi plus cluster specific features, such as HA, DRS and capacity buffer.\nThis means by definition the metrics are averaged numbers. So be careful as there can be ESXi or VM that has issue but obscured in the cluster wide average. Even the so-called total or summation is mathematically an average. For example, the Total CPU Wait counter is the sum of all ESXi CPU Wait counters, which in turn is the sum of all the VMs. At the end you get a large number, which you need to normalize and convert into average. Since you divide it against the cluster total, you get average.\nvRealize Operations sports a few leading indicators to help you detect problem early.\nCPU Worst VM CPU Ready (%) Worst VM CPU Overlap (ms) Worst VM CPU Co-Stop (%) Percentage of VMs facing CPU Ready (%) (CPU Ready \u0026gt; 1%) Percentage of VMs facing CPU Co-Stop (%) Memory Worst VM Memory Contention (%) Percentage of VMs facing Memory Contention (%) Disk Worst VM Disk Latency (ms) Percentage of VMs facing Disk Latency is not included as that should be a percentage of the datastore, not the cluster. The reason is if there is a population problem, you troubleshoot the datastore not the cluster(s) mounting it.\nPerformance Troubleshooting There is a common misconception that you cannot have performance issue when cluster has low utilization. We introduced that problem here.\nPerformance is unmet demand. VM01 can face very high contention when all other VMs on the same cluster face no contention.\nIt is possible for VMs in the cluster to suffer from poor performance, while the cluster utilization is low. One main reason is cluster utilization looks at the provider layer (ESXi), while performance looks at individual consumer (VM). The following cluster has 32 ESXi supporting 2357 VM. The average demand across the cluster is \u0026lt;40%. Since it has 32 ESXi and 2357 VM, we can retire 8 ESXi or add 1K VM.\nAnd yet the VMs in the clusters are facing contention. Both VM CPU Ready and CPU CoStop are high.\nCluster and Disk A shared datastore is typically shared by all the ESXi in a cluster, so the VMs can around without doing storage vMotion. Some datastores are further shared by multiple clusters, and a cluster in turn may have multiple datastores. This can cause confusion on what numbers to show at different levels.\nThe same approach has to be applied to IOPS. Cluster A should report IOPS that it performs, and not the total IOPS from all clusters.\nProjection Usable Capacity = Total Capacity - (vSphere HA reservation + capacity buffer). Total Capacity = The sum of all the physical cores in MHz. It does not take into account Hyper-Threading, meaning turning in on does not increase the value. It does not take into account CPU Power Management. Capacity buffers defined in vRealize Operations policy (default 0%).\nCPU Usable Capacity\n= CPU \\ Demand \\ Usable Capacity after HA and Buffer (GHz) = Sum ( ESXi CPU \\ Capacity Available to VMs ) * ( 100 - Cluster HA CPU Failover ) % Memory Usable Capacity (KB) = Memory \\ Demand \\ Usable Capacity after HA and Buffer (GB) = ( Sum ESXi Memory | Capacity Available to VMs ) * ( 100 - Cluster HA Memory Failover) % Capacity Remaining Capacity Remaining = Usable Capacity - (MAX Value of upper confidence interval of Long Term Forecast within a user defined Planning Window)\nLong Term Forecast = Forecast of (Usage and Contention (aka Demand) + Overhead (if applicable). Forecast is based on ARIMA, DFT, Spike and Plateau models. A year\u0026rsquo;s worth daily aggregated (currently average) data is used, with more weight given to more recent data (this feature is called exponential decay). A limitation is it won\u0026rsquo;t handle workload with annual cycle.\nNote that the value of will be set to 0 if during the given collection cycle the demand breaches the usable capacity. This is because at that moment there is really no capacity. This can cause fluctuating value of Capacity Remaining metric if the load regularly touches the usable capacity threshold.\nTime Remaining Time from now to when the upper confidence interval of Long Term Forecast intersects/crosses Usable Capacity. If no intersection is seen, then the value is set to 366 days\nCluster Demand Cluster CPU Demand contain only limits, Memory utilization contains limits and reservations. CPU Reservation is excluded as it\u0026rsquo;s on demand.\nESXi CPU overhead ESXi CPU overhead = CPU \\ Overhead (MHz)\nThis reservation is actually a raw counter from vCenter. ESXi needs to guarantee that the kernel has the resources for itself and does it by reservation (as opposed to by priority).\nThere is another counter that tracks the actual VMkernel overhead\nESXi memory overhead = Memory \\ ESX System Usage (KB)\nESXi usable memory = CPU \\ Capacity Available to VMs\nESXi usable CPU = Memory \\ Capacity Available to VMs\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-5---network-metrics/2.5.3-guest-os/",
      "title": "3. Guest OS",
      "tags": [],
      "description": "",
      "content": "Understanding network counter at Guest OS level is important as the data inside the guest provides better visibility. The following screenshot shows Windows 10 Resource Monitor. You will notice quickly that a lot of this information is not available at the hypervisor layer. The VM does not report process level information. Looking at the columns in the table, what critical counters are missing at the VM layer?\nWindows reports the packet loss (%) and latency (ms) counters per TCP connections. This is crucial in troubleshooting at application level. Unfortunately, Windows does not report the overall latency and overall packet loss.\nTake note that Windows mixes bit and byte, which it should not. The chart is showing in bit, while the table is showing in byte.\nAnother counter that could be potentially useful is Output Queue Length. You can monitor it on a per network adapter basis, as shown in the Performance Monitor screenshot below. I said it could be useful, because unfortunately the value is always 0. As you can see in the screenshot, Windows 10 states that \u0026ldquo;since the requests are queued by the Network Driver Interface Specification (NDIS) in this implementation, this will always be 0.\u0026rdquo;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-4---storage-metrics/2.4.3-esxi-host/",
      "title": "3. ESXi Host",
      "tags": [],
      "description": "",
      "content": "Look at the ESXi metric groups for storage in the vCenter performance chart. There are 4 metrics groups: storage adapter, storage path, datastore and disk.\nHow do they relate to one another? When do we use which metric group?\nHow do they work in distributed storage such as vSAN?\nThe following diagram explains the relationship. The green boxes are what you are likely to be familiar with. You have your ESXi host, and it can have NFS Datastore, VMFS Datastore, vSAN Datastore, vVOL datastore or RDM objects. vSAN \u0026amp; vVOL present themselves as a VMFS datastore, but the underlying architecture is different. The blue boxes represent the metric groups you see in vCenter performance charts.\nStorage at ESXi is a lot more complex than storage at VM level. Reason is ESXi virtualizes the different storage, and VM consumes it as local SCSI drive. The counter at ESXi level contains data from all VMs. There is no breakdown. For example, the counter at vmnic, storage adapter and storage path are all aggregate counters. It\u0026rsquo;s not broken down by VM. The same with vSAN objects (cache tier, capacity disk, disk group). None of them shows details per VM.\nCan you figure out why there is no path to the VSAN Datastore?\nWe\u0026rsquo;ll do a comparison, and hopefully you will realize how difference distributed storage and central storage is from performance monitoring point of view.\nIn the central storage architecture, NFS and VMFS datastores differ drastically in terms of counters, as NFS is file-based while VMFS is block-based.\nFor NFS, it uses the vmnic, and so the adapter type (FC, FCoE, or iSCSI) is not applicable. Multipathing is handled by the network, so you don\u0026rsquo;t see it in the storage layer. For VMFS or RDM, you have more detailed visibility of the storage. To start off, each ESXi adapter is visible and you can check the counters for each of them. In terms of relationship, one adapter can have many devices (disk or CDROM). One device is typically accessed via two storage adapters (for availability and load balancing), and it is also accessed via two paths per adapter, with the paths diverging at the storage switch. A single path, which will come from a specific adapter, can naturally connect one adapter to one device. The following diagram shows the four paths: Storage Devices The term drive, disk, device, storage can be confusing as they are often used interchangeably in the industry. In vSphere, this means a physical disk or physical LUN partition mounted by the host. The following shows that the ESXi host has 3 storage devices, all are flash drive and the type = disk. The first two are used in vSAN datastore and are accessed via the adapter vmhba1.\nA storage path takes data from ESXi to the LUN (the term used by vSphere is Devices), not to the datastore. So if the datastore has multiple extents, there are four paths per extent. This is one reason why you should not use more than one extent, as each extent adds 4 paths. If you are not familiar with VMFS Extent, Cormac Hogan explains it here.\nFor VMFS (non vSAN), you can see the same counters at both the Datastore level and the Disk level. Their value will be identical if you follow the recommended configuration to create a 1:1 relationship between a datastore and a LUN. This means you present an entire LUN to a datastore (use all of its capacity). The following shows a VMFS datastore with a NetApp LUN backing it.\nIn vSAN, there is no connectivity and Multipathing menu. There is also no Capability Sets menu. vSAN datastore is not mapped to a LUN. It is supported by disk groups.\nStorage Adapter The screenshot shows an ESXi host with the list of its adapters. We have selected vmhba2 adapter, which is an FC HBA. Notice that it is connected to 5 devices. Each device has 4 paths, giving 20 paths in total.\nWhat do you think it will look like on vSAN? The following screenshot shows the storage adapter vmhba1 being used to connect to two vSAN devices. Both devices have names begin with \u0026ldquo;Local\u0026rdquo;. The storage adapter has 2 targets, 2 devices and 2 paths. If you are guessing it is 1:1 mapping among targets, devices and paths, you are right.\nWe know vSAN is not part of Storage Fabric, so there is no need for Identifier, which is made of WWNN and WWPN.\nvRealize Operations provide the Storage Adapter|Outstanding Requests metric, which is required to track if the adapter is struggling to meet demands.\nLet\u0026rsquo;s expand the Paths tab. We can see the LUN ID here. This is important. The fact that the hypervisor can see the device is important. That means the VMkernel can report if there is an issue, be it performance or availability. This is different if the disk is directly passed through to the VM. The hypervisor loses visibility.\nStorage Path Continuing our comparison, the last one is Storage Path. In a fibre channel device, you will be presented with the information shown in the next screenshot, including whether a path is active or not.\nNote that not all paths carry I/O; it depends on your configuration and multipathing software. Because each LUN typically has four paths, path management can be complicated if you have many LUNs.\nWhat does Path look like in vSAN? As shared earlier, there is only 1 path.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-3---memory-metrics/2.3.3-guest-os/",
      "title": "3. Guest OS",
      "tags": [],
      "description": "",
      "content": "Windows memory management is not something that is well explained. Ed Bott sums it this article by saying \u0026ldquo;Windows memory management is rocket science\u0026rdquo;. Like what Ed has experienced, there is conflicting information, including the ones from Microsoft. Mark Russinovich, cofounder of Winternals software, explains the situation in this TechNet post.\nAvailable means exactly what the word means. It is the amount of physical memory immediately available for use. Immediately means Windows does not need to copy the existing page before it can be reused.\nIn formula, here is their definition:\nCached = Standby + Modified Available = Standby + Free It is easier to visualize it, so here it is:\nWindows and Linux manage memory differently, and they also name their metrics differently. VMware Tools provide a set of universal metrics from these two popular types of Guest OSes. The following shows what it looks like in Linux\nA popular tool for Windows monitoring is SysInternal. In addition to the above, it shows Transition and Zeroed.\nIn Use This is the main counter used by Windows, as it\u0026rsquo;s featured prominently in Task Manager.\nThis is often thought as the minimum that Windows needs to operate. This is not true. If you notice on the preceding screenshot, it has compressed 457 MB of the 6.8 GB In Use pages, indicating they are not actively used. Windows compresses its in-use RAM, even though it has plenty of Free RAM available (8.9 GB available). This is a different behaviour to ESXi, which do not compress unless it\u0026rsquo;s running low on Free.\nLook at the chart of Memory Usage above. It\u0026rsquo;s sustaining for the entire 60 seconds. We know this as the amount is too high to sustain for 60 seconds if they are truly active, let alone for hours.\nFormula:\nIn use = Total - (Modified + Standby + Free\nModified Page that was modified but no longer used, hence it\u0026rsquo;s available for other usage but requires to be saved to disk first. It\u0026rsquo;s not counted as part of Available, but counted as part of Cache.\nStandby Windows has 3 levels of standby. As reported by VMware Tools, their names are:\nStandby Core Standby Normal Standby Reserve Different applications use the memory differently, resulting in different behaviour of the metrics. As a result, determining what Windows actually use is difficult.\nThe Standby Normal counter can be fluctuating wildly, resulting in a wide difference if it\u0026rsquo;s included in rightsizing. The following VM is a Microsoft Exchange 2013 server mailbox utility.\nNotice the Standby Normal fluctuates wildly, reaching as high at 90%. The other 2 cache remains constantly negligible. The chart above is based on \u0026gt;26000 samples, so there is plenty of chance for each 3 counters to fluctuate.\nNow let\u0026rsquo;s look at another example. This is a Windows Server 2016. I think it was running Business Intelligence software Tableau.\nNotice the VM usable memory was increased 2x in the last 3 months. Standby Normal hardly move, but Standby Reserve took advantage of the increments. It simply went up accordingly, although again it\u0026rsquo;s fluctuating wildly.\nCache Cache is an integral part of memory management, as the more you cache, the lower your chance of hitting a cache miss. This makes sense. RAM is much faster than Disk, so if you have it, why not use it? Remember when Windows XP introduced pre-fetch, and subsequently Windows SuperFetch? It\u0026rsquo;s a clue that Memory Management is a complex topic. There are many techniques involved. Unfortunately, this is simplified in the UI. All you see is something like this:\nLinux and VMkernel also has its fair share of simplifying this information. This Linux Ate My RAM documents it well. For ESXi, a common misperception is \u0026ldquo;we are short on RAM, but fine on CPU\u0026rdquo;, when it is actually the other way around. To prove it, check the performance counters for each cluster. You may see that the VMs have CPU performance while cluster CPU utilization is lower than cluster memory utilization.\nFree As the name implies, this is a block of pages that is immediately available for usage. This excludes the cached memory. A low free memory does not mean a problem if the Standby value is high. This number can reach below \u0026lt;100 MB, and even touch 0 MB momentarily. It\u0026rsquo;s fine so long there is plenty of cached. I\u0026rsquo;d generally keep this number \u0026gt; 500 MB for server VM and \u0026gt;100 MB for VDI VM. I set a lower number for VDI because they add up. If you have 10K users, that\u0026rsquo;s 1 TB of RAM.\nWhen a Guest OS frees up a memory page, it normally just updates its list of free memory; it does not release it. This list is not exposed to the hypervisor, and so the physical page remains claimed by the VM. This is why the Consumed counter in vCenter remains high when the Active counter has long dropped. Because the hypervisor has no visibility into the Guest OS, you may need to deploy an agent to get visibility into your application. You should monitor both at the Guest OS level (for example, Windows and Red Hat) and at the application level (for example, MS SQL Server and Oracle). Check whether there is excessive paging or the Guest OS experiences a hard page fault. For Windows, you can use tools such as pfmon, a page fault monitor.\nPage File Memory paging is an integral part of Guest OS Memory Management. OS begins using it even though it still has plenty of physical memory. It uses both physical memory and virtual memory at the same time. Microsoft recommends that you do not delete or disable the page file. See this for reference.\nAs shown on the diagram, processes see virtual memory, not physical memory. Guest OS presents this as system API to processes. The virtual memory is backed by the page file and physical memory. Guest OS shields the physical memory and hardware. Paging is an operation of reading/writing from the page file into the physical memory, not from physical disk into the page file.\nLet Windows manages the pagefile size. This is the default setting, so you likely have it already. By default, windows sets the pagefile size to the same size with the physical memory. So if the VM has 8 GB of RAM, the pagefile is an 8 GB file. Anything above 8 GB indicates that Windows is under memory pressure.\nThe size of Page File is not a perfect indicator of the RAM usage, because they contain pages that are never demanded by the App. Windows does SuperFetch, where it predicts what pages will be used and prefetch them in advance. Some of these pages are never demanded by the application. Couple with the nature that Guest OS treats RAM as cache, including the page file will result in oversized recommendation. Paging rate is more realistic as it only considers the recent time period (300 seconds in vRealize Operations case).\nA page would be used as cache if it was paged out at some point due to memory pressure and it hasn\u0026rsquo;t been needed since. The OS will reuse that page as cache. That means that at some point the OS was constrained on memory enough to force the page out to happen.\nA page that was paged out earlier, has to be brought back first before it can be used. This creates performance issue as the application is waiting longer, as disk is much slower than RAM.\nThere are 2 types of page operations:\nPage In: This is a potential indicator for performance. Page-out: This is a potential indicator for capacity. While Paging impacts performance, the correlation between the paging counters and performance varies per application. You can\u0026rsquo;t set a threshold and use it to monitor many VMs. The reason is paging is not always used when Guest OS runs out of memory. There are a few reasons why paging may not correlate to memory performance:\nMemory mapped files. This is essentially a file that has a mapping to memory. Processes use this to exchange data. It also allows the process to access a very large file (think of database) without having to load the entire database into memory. Proactive pre-fetch. It predicts the usage of memory and pre-emptively reads the page and bring it in. This is no different to disk where the storage array will read subsequent blocks even though it\u0026rsquo;s not being asked. This especially happens when a large application starts. Page-in will go up even though there is no memory pressure (page out is low or 0). Windows performs memory capacity optimization in the background. It will move idle processes out into the page file. If you see both Page-in and Page-out having high value, and the disk queue is also high, there is a good chance it\u0026rsquo;s memory performance issue.\nThe counter %pagefile tracks how much of the pagefile is used, meaning the value 100% indicate the pagefile is fully utilized. While the lower the number the better, there is no universal guidance. If you know, let me know!\nReference: this is an old article as it covers 32 bit Windows. If you find a newer one, kindly let me know.\nGuest OS Paging Metrics There are 2 metrics. Page-in and Page-out.\nThe unit is in number of pages, not MB. It\u0026rsquo;s not possible to convert due to mix use of Large Page (2 MB) and Page (4 KB). A process can have concurrent mixed usage of large and non-large page in Windows. The page size isn\u0026rsquo;t a system-wide setting that all processes use. The same is likely true for Linux Huge Pages.\nThe page-in rate metric tracks the rate OS brings memory back from disk to DIMM per second. Another word, the rate of reads going through paging/cache system. It includes not just swap file I/O, but cacheable reads as well (so it\u0026rsquo;s double pages/s).\nPage Out is the opposite of the above process. It is not as important as Page In. Just because a block of memory is moved to disk that does not mean the application experiences memory problem. In many cases, the page that was moved out is the idle page. Windows does not page out any Large Pages.\nThe block size is likely 4 KB. Some applications like Java and databases use 2MB pages.\nYou can profile your environment to see which VMs are experiencing high paging. Create a view, and convert the paging rate into MB/second, by assuming the page size is 4 KB. I\u0026rsquo;d say \u0026gt; 1 GB/second is high.\nFrom the above table, it\u0026rsquo;s interesting to note the page-in dwarf page-out. I plotted one of the VM and page-in far exceed page-out consistently over 7 days.\nCommitted This tracks the currently committed virtual memory, although not all of them are written to the pagefile yet. It measures the demand, so commit can go up without In Use going up, as Brandon Paddock shares here. If Committed exceeds the available memory, paging activity will increase. This can impact performance.\nCommit Limit: Commit Limit is physical RAM + size of the page file. Since the pagefile is normally configured to map the physical RAM, the Commit Limit tends to be 2x. Commit Limit is important as a growing value is an early warning sign. The reason is Windows proactively increases its pagefile.sys if it\u0026rsquo;s under memory pressure.\nThe pagefile is an integral part of Windows total memory, as explained by Mark Russinovich explains here. There is Reserved Memory, and then there is Committed Memory. Some applications like to have its committed memory in 1 long contiguous block, so it reserves a large chunk up front. Databases and JVM belong in this category. This reserved memory does not actually store meaningful application data or executable. Only when the application commits the page that it becomes used. Mark explains that \u0026ldquo;when a process commits a region of virtual memory, the OS guarantees that it can maintain all the data the process stores in the memory either in physical memory or on disk\u0026rdquo;.\nNotice the word on disk. Yes, that\u0026rsquo;s where the pagefile.sys comes in. Windows will use either the physical memory or the pagefile.sys.\nSo how do we track this committed memory?\nThe metric you need to track is the Committed Byte. The % Committed metric should not hit 80%. Performance drops when it hits 90%, as if this is a hard threshold used by Windows. We disabled the pagefile to verify the impact on Windows. We noticed a visibly slower performance even though Windows 7 showing \u0026gt;1 GB of Free memory. In fact, Windows gave error message, and some applications crashed. If you use a pagefile, you will not hit this limit.\nWe have covered Free Memory and Committed Memory. Do they always move in tandem? If a memory is committed by Windows, does it mean it\u0026rsquo;s no longer free and available?\nThe answer is no. Brandon Paddock demonstrated here that you can increase the committed page without increasing the memory usage. He wrote a small program and explained how it\u0026rsquo;s done. The result is Windows committed page is double that of memory usage. The Free Memory \u0026amp; Cached Memory did not change.\nActive File Cache Memory This is the actively in-use subset of the file cache. Unused file cache and non-file backed anonymous buffers (mallocs etc) are not included.\nThis is the size of the portion of the system file cache which is currently resident and active in physical memory. The System Cache Resident Bytes and Memory \\ Cache Bytes counters are equivalent. Note that this counter displays the last observed value only; it is not an average during the collection period.\nIn Linux, this is the amount of file cache memory, in kibibytes, that is in active use, or was in active use since the last time the system reclaimed memory. This is retrieved via the command:\n$ cat /proc/meminfo | grep Active Active: 50955636 kB Active (anon): 30148196 kB Active (file): 20807440 kB For further reading, refer to Linux and Windows.\nLinux Memory Metrics As you can guess from above, Linux does it differently. These are the counters that we\u0026rsquo;re interested from right sizing use case.\nLinux has 2 types of cache: Slab Reclaim and Cached.\nvSphere Tools 10.3.5 provides the following counters:\nTotal Available Free Buffers Used = total - free - buffers - cached Cached = guest.mem.cached + guest.mem.slabReclaim From the kernel documentation, the definition are:\n\u0026ldquo;Cached includes memory that is not freeable as page cache, for example shared memory segments, tmpfs, and ramfs, and it does not include reclaimable slab memory, which can take up a large fraction of system memory on mostly idle systems with lots of files.\u0026rdquo; Available = An estimate of how much memory is available for starting new applications, without swapping. Calculated from MemFree, SReclaimable, the size of the file LRU lists, and the low watermarks in each zone. The estimate takes into account that the system needs some page cache to function well, and that not all reclaimable slab will be reclaimable, due to items being in use. The impact of those factors will vary from system to system. Buffers: Relatively temporary storage for raw disk blocks shouldn\u0026rsquo;t get tremendously large (20MB or so) I notice the above was committed by Linus himself, on Jan 2014. Hats off for doing low level things like this!\nGuest OS Free Memory This is one the 3 major counters for capacity monitoring. The other 2 counters are Page-in Rate and Commit Ratio. These 3 are not contention counters, they are utilization counters. Bad values can contribute to bad performance, but they can\u0026rsquo;t measure the severity of the performance. Windows and Linux do not have a counter that measures how long or how often a CPU waits for memory.\nIn Windows, this is the Free Memory counter. This excludes the cached memory. If this number drops to a low number, Windows is running out of Free RAM. While that number varies per application and use case, generally keep this number \u0026gt; 500 MB for server VM and \u0026gt;100 MB for VDI VM. The reason you should set a lower number for VDI because they add up quickly. If you have 10K users, that\u0026rsquo;s 1 TB of RAM.\nFurther reading for Linux, read this.\nIt\u0026rsquo;s okay for this counter to be low, so long other memory counters are fine. The following table shows VMs with near 0 free memory. Notice none of them are needing more memory. This is the perfect situation as there is no wastage.\nGuest OS Memory Needed We shared earlier that the purpose of memory is to act as disk cache. So you want to utilize all the cache given to you. Because the static nature of memory consumption, you can create a heat map that plots all your VMs memory consumption. You want it near 100% while making sure the page in and page out rate within normal expectation.\nThis is not a raw counter from Windows or Linux. This is a derived counter provided by VMware Tools to estimate the memory needed to run with minimum swapping. It\u0026rsquo;s a more conservative estimate as it includes some of the cache.\nThe counter Memory Needed tracks the amount of memory needed by the Guest OS. It has 5% buffer for spike, based on the general guidance from Microsoft. Below this amount, the Guest OS may swap.\nFormula for Linux = physical memory - Maximum of (0, ( Available - 5 % of physical )) Formula for Windows = physical memory - Maximum of (0, ( Unneeded - 5 % of physical )) where Unneeded = Free + Reserve Cache + Normal Priority Cache Example: the VM has 10 GB of RAM. So the Physical RAM = 10 GB\nSo 5% of physical = 0.5 GB\nSituation 1: Max Memory Utilization Memory Available = 0 GB.\nTools will calculate Memory Needed as\n= 10 GB - Maximum (0, 0 - 0.5) = 10 - Maximum (0, -0.5) = 10 - 0 GB = 10 GB Memory Needed is the same as it\u0026rsquo;s already maxed.\nSituation 2: High Memory Utilization Memory Available = 2 GB.\nTools will calculate Memory Needed as\n= 10 GB - Maximum (0, 2 - 0.5) = 10 - Maximum (0, 1.5 GB) = 10 - 1.5 GB = 8.5 GB You actually still have 2 GB here. But Tools adds around 5%\nSituation 3: Low Memory Utilization Memory Available = 8 GB.\nTools will calculate Memory Needed as\n= 10 GB - Maximum (0, 8 - 0.5) = 10 - Maximum (0, 7.5 GB) = 10 - 7.5 GB = 2.5 GB Again, Tools adds around 5%.\nWe\u0026rsquo;ve covered that you need to look at more than 1 metric before you decide to add more memory. I\u0026rsquo;m afraid it is case by case, as shown in the following table. All these VMs are low on free memory, but other than VM on row no 3, the rest has sufficient memory.\nOther Metrics Page Size: Size of the page. In Windows, this is 4 KB by default. This is not the size of the pagefile.sys in c:\\.\nPaged pool: this is a part of Cache Bytes. Based on this great article, it includes Pool Paged Resident Bytes, the System Cache Resident Bytes, the System Code Resident Bytes and the System Driver Resident Bytes.\nNon-paged pool: this is kernel RAM. It cannot be paged out. It\u0026rsquo;s part of In Use.\nWorking Set: this measures the active usage by all processes. If this number exceeds the available memory, Windows decreases the working set of processes to minimize paging.\nRemaining Swap: The amount of swap space remaining, taking into account the possibility of swap file growth where possible. A low remaining will trigger paging. If the system is configured to run without a swap file, this will return zero.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-2---cpu-metrics/2.2.3-esxi-host/",
      "title": "3. ESXi Host",
      "tags": [],
      "description": "",
      "content": "Hope you like the tour of VM CPU accounting. Can you apply that knowledge into ESXi and explain the following?\nThe above is an ESXi host, showing 3 types of utilization counters. One shows 50%, indicating you have more capacity. But the second one shows 100%, indicating you do not have capacity. And the 3rd shows 75%. Which counters do you take for the ESXi CPU \u0026ldquo;utilization\u0026rdquo; then?\nNotice they have similar pattern, but their sensitivity differs.\nWhy is Usage (%) = 100% when Utilization (%) is around 47%? The gap is more than double. What could be causing it? Why is Utilization (%) fluctuating yet Usage (%) remains constant? Notice both Utilization varies between 45% and 55% while Usage remains flat at 100% Why is Core Utilization (%) in the \u0026ldquo;middle\u0026rdquo;? What does it actually measure then? To answer the above, we need to cover some fundamental. Note that we must take the vantage point of ESXi, not VM. Don\u0026rsquo;t mix this with the VM view of the world as they are similar so it\u0026rsquo;s easy to get mixed up. From ESXi physical threads viewpoint, things such as Ready and CoStop are not applicable as the physical threads are provider of resource.\nUnlike RAM, CPU performance varies widely among different CPU models. Speed matters in CPU, whereas in RAM we can generally ignore it. DDR5 RAM is faster than DDR4 but for general monitoring reason it can be ignored. Because of this significant difference in CPU, we need to have counters to account for:\nHow often it runs. How much the CPU runs in a time period. E.g. if it runs 60% of the time in the last 100 seconds, that means it runs for 60 seconds accumulatively in that period. That\u0026rsquo;s why you see many counters in millisecond. They track the utilization over time. How fast it runs. All else being equal, a 5 GHz CPU is 5x faster than a 1 GHz CPU. Throughput impacts utilization. The faster it can complete a task, the shorter it has to work. That\u0026rsquo;s why you see some counters in MHz. How efficient it runs. CPU SMP impacts the core efficiency. This is covered more here. This efficiency is then translated into MHz, for ease of accounting. These 3 dimensions of run are the reason why CPU utilization is hard to measure. It becomes \u0026ldquo;it depends on what you consider\u0026rdquo;. It can\u0026rsquo;t be a single number. Insisting that the CPU has a single, static, total capacity and use this as the only 100% for all use cases will result in confusion in \u0026ldquo;utilization\u0026rdquo; numbers.\nESXi uses 3 types of units: millisecond, MHz and %.\nTime is the raw unit, meaning the percentage unit is derived from it and the MHz unit is expressed as the average over time. When we see the CPU demand is 2 GHz at 9:00:00 am what vCenter actually means is it the average from 8:59:40 am, assuming you\u0026rsquo;re looking at the real time chart. Other number on the vCenter UI could be averaged of longer time, else frequent changes could cause unnecessary confusion.\nUtilization and Core Utilization Let\u0026rsquo;s dive into the first two fundamental counters. For that, we need to begin with a single physical core in a socket. We also need to start at esxtop, and then move up to vSphere Client UI. The socket can have many cores, we are just interested on 1 core only. It has 2 threads as it supports CPU SMT.\nIn a time period of say 20 seconds1, this core had the following consumption:\nLooking at esxtop, you will see near the top the PCPU Used and PCPU Utilization counters. Note that their values are in percentage, meaning you need to know what they use for 100%.\nIf you guess that they eventually map into vSphere Client counters Usage (%) and Utilization (%), respectively, you are right. However, you need to know how they map.\nPCPU means a physical hardware execution context. That means it is a physical core if CPU SMT is disabled, or a physical thread inside a core if SMT is enabled. It does not mean CPU socket. A single socket with 10 cores and 20 threads will have 20 PCPU counters.\nPCPU Utilization (%) tracks is a physical thread is used or not over time. At any given moment, a thread is either running (unhalted) or not (halted). So it\u0026rsquo;s binary (0% or 100%). But over the 20 second period, the value is averaged. So when you see the number as 50%, it does not mean it\u0026rsquo;s running 100% at half the \u0026ldquo;speed\u0026rdquo;. It means it\u0026rsquo;s running half the time, for only 10 seconds. Using a human analogy, think of it as a person who is either running or standing, and never walking. It\u0026rsquo;s not considering CPU Frequency.\nCore Utilization (%) tracks at the core level. If one of the threads is running, then the value is 100%. At the core level, the average utilization in that entire period is 75%. In the last portion, the core still runs at 100%. The CPU Utilization (%) tracks this. As a result, CPU Utilization (%) is only relevant when hyper-threading is enabled.\nGoing back to our example, here are metrics reported:\nPCPU Utilization (%) for HT 0 = 10 seconds / 20 seconds = 50% PCPU Utilization (%) for HT 1 = 10 seconds / 20 seconds = 50% Core Utilization (%) for entire core = 15 seconds / 20 seconds = 75% Now let\u0026rsquo;s roll this up to the ESXi level. The following show a tiny ESXi with 2 cores, where each core has 2 threads.\nThe metrics at ESXi level is:\nCPU Utilization (%) = 40 seconds / 80 seconds = 50%. CPU Core Utilization (%) = 30 seconds / 40 seconds = 75% Utilization = 50% because each thread is counted independently. There are 4 threads in the preceding ESXi, each runs 50%, so the average at ESXi level is 50%. This counter basically disregards that HT does not deliver 2x the throughput.\nNow let\u0026rsquo;s go back to the chart shown earlier. Can you now explain Utilization (%) and Core Utilization (%)?\nGreat! Let\u0026rsquo;s move to the next one.\nIn the following example, this ESXi has no hyper-threading. What do you notice?\nYup, the Core Utilization is identical with Utilization.\nGreat! You are now ready to tackle the next counters, which are Used (%) and Usage (%).\nThis vCenter counter essentially maps to PCPU Used (%) counter in esxtop. It considers CPU SMT and CPU Clock Speed. Here is how Utilization (%) and Used (%) are related at PCPU level:\nCPU frequency scaling is caused by power management, so let\u0026rsquo;s dive into it.\nPower Management The 2nd factor that impacts CPU accounting is CPU clock speed. The higher the frequency (GHz), the faster the CPU run. All else being equal, a CPU that run at 1 GHz is 50% slower than when it runs at 2 GHz. On the other hand, Turbo Mode can kick in and the CPU clock speed is higher than stated frequency. Turbo Boost normally happens together with power saving on the same CPU socket. Some cores are put to sleep mode, and the power saving is used to turbo mode other cores. The overall power envelope within the socket remains the same.\nC-State = idle state, running or varying degrees of components turned off. A CPU chip has many subcomponents, and not all components have to be powered on. Fully running is C0 state. Within this C0 state, there is a further dimension called P-State.\nP-State = voltage / frequency point. The P0 state is where Turbo Boost happens. There are 14 states, where P13 is the lowest CPU frequency.\nIn addition, it takes time to wake up from a deep C-State. For details on P-State and C-State, see Valentin Bondzio and Mark Achtemichuk, VMworld 2017, Extreme Performance Series.\nThe following screenshot shows ESXi with 14 P-States, where P0 is represented as 2401 MHz. Each row is a Logical CPU. Logical CPU means HT (if it\u0026rsquo;s enabled) or core (if no HT). See Logical CPU 10 and 11. They are running at 100%, and in fact are in Turbo Boost, so obviously both are in C-State C0. The %A/MPERF shows Turbo boost. This was introduced in vSphere 6.5.\n10 and 11 are running 100% in P0 state. %Util corresponds to each HT in Core Utilization.\nEach core can have its own frequency. This makes rolling up the number to ESXi level more complex. You can\u0026rsquo;t derive one Throughput counter from the other. Each has to be calculated independently at core level.\nDoes it mean we should always set power management to maximum?\nNo. ESXi uses power management to save power without impacting performance. A VM running on lower clock speed does not mean it gets less done. You only set it to high performance on latency sensitive applications, where sub-seconds performance matters. VDI, VoIP, video calling, Telco NFV are some examples that are best experienced with low latency.\nUsed Now that we have covered CPU Clock Speed, we can add this dimension into the same scenario above. For that, we will go back to our tiny ESXi:\nIn Core 0, the first thread was running at half the CPU frequency in the first period. While Utilization (%) records this as 100% run, Used (%) is aware of this reduction and records 50% instead. In the 4th period, the thread is competing with another thread. Used (%) recognises the drop in efficiency and register 50% instead of 100%. Personally, I\u0026rsquo;d prefer this to register 62.5%.\nOn the other hand, when Turbo Boost increases the clock speed by 1.5x on the 2nd thread, Utilization (%) is unaware and record 100%, but Used registered 150%. Take note that the value at ESXi level is capped at 100%.\nIn a simplistic example, the above is how Used considers both hyperthreading and CPU scaling.\nWith this knowledge, now the screen on vCenter client UI will be clearer.\nYou see both the Capacity of 35.18 GHz and Used of 11.3 GHz. There is no concept of Usable Capacity in vSphere, so the Free amount is basically Capacity - Used.\nvCenter shows Used in GHz. The value is actually CPU Usage, as the Used counter is supposed in percentage or millisecond. The CPU capacity is summary.hardware.numCpuCores x summary.hardware.cpuMhz.\nThe Used CPU is summary.quickStats.overallCpuUsage.\nThe value above is likely some average of say 5 minutes as it remains static for a while and it does not exactly match the number below as the roll up period is not the same.\nCPU Idle (ms) + CPU Used (ms) = 100%, where 100% = no of physical cores x 20000 ms.\nUsed does not count the threads, meaning each core has 20000 as 100%, not 40000.\nCan you guess how many physical cores the following ESXi has?\nAnswer: 20 cores, 40 threads.\nNotice the total sum is constant at 400K ms. Divide this by 20K ms and you get 20 cores. While the graph shows the line is slightly above 400K, the sum of the 2 values shown is actually 400,000.01 ms.\nIf you want to verify with vCenter, the following ESXi host has 16 cores 32 threads. Notice the sum is ~320000 ms, not 640000 ms.\nUsage vCenter adds this counter, meaning it does not exist at ESXi level. If you see in esxtop, you will find Used (%) and Utilization (%) but not Usage. Usage basically maps to Used, but showing in MHz. This is great as using millisecond is hard to account for \u0026ldquo;how fast you run\u0026rdquo; and \u0026ldquo;how efficient you run\u0026rdquo;. With MHz, we can plot the value across time.\nLet\u0026rsquo;s see if Used (ms) = Usage (MHz).\nTo prove it, we plot 180 data points from each, and compare the average. For completeness, let\u0026rsquo;s compare the latest value too.\nLet\u0026rsquo;s compare the above value to prove the formula. We need to translate them into a common unit for comparison.\nBingo!\nBoth the average values and the latest values match.\nJust like Used, Usage tops out at 100% when all cores run at least one thread at nominal frequency, even if there is still \u0026ldquo;headroom\u0026rdquo; for Turbo Boost or scheduling \u0026ldquo;capacity\u0026rdquo; on other threads. This is why its value will be lower than Core Utilization if there is power savings, as shown below.\nESXi CPU Usage (%) = CPU Usage (MHz) / CPU Total Capacity (MHz), where Total Capacity = total cores x nominal clock speed. It does not consider hyper threading. This accounting technique of removing hyperthreading is consistent with Used.\nThe following chart prove the above equation.\nWhen is Usage (%) higher than Core Utilization (%)?\nThe answer has to be Turbo Boost. The following shows an ESXi where Usage is consistently higher than Core Utilization (%) in the last 24 hours. Notice that the value of Usage was capped at 100%. It did not breach 100%\nI\u0026rsquo;ve marked some areas of the above chart with red dot. Those areas is where Usage turns out to be lower than Core Utilization.\nWhy?\nThe answer is power saving, which typically happens on low utilization. In an aggressive power savings, Usage can even be lower than Utilization, as shown below. This makes sense, as the idles cores consumes are run at lower frequency, hence the average at ESXi level is low.\nDemand Demand looks at different context than Utilization/Used/Usage. It looks at the VM world, not the physical cores. As a result, its value tends to be higher than all the other counters. It does not include the VMkernel load, so at lowly utilization, Demand will be lower than Usage.\nOne good thing about Demand metric is it can go above 100%. All the other counters are capped at 100%. Demand lets you see how high above 100% the demand. It does not mean the VM is experiencing performance, as there is Turbo Boost and Hyperthreading to assist.\nIn older release of vRealize Operations, this counter used to be computed as Sum ( VM CPU / Host Demand for Aggregation ) + CPU Overhead. This is no longer the case as vRealize Operations now simply maps to vCenter metric.\nESXi \u0026ldquo;Utilization\u0026rdquo; counters Let\u0026rsquo;s summarise the counters we have covered so far. vCenter provides 6 counters to account for the utilization of ESXi CPU. Since esxtop uses the Used (%) metric but ESXi uses the Used (ms) metric in the vCenter client, I\u0026rsquo;m including both.\nCounter Available at Unit Source CPU Speed Utilization Thread level % ESXi No Used Thread level ms ESXi No Used Thread level % esxtop only Yes Core Utilization Thread level % ESXi No Usage Thread level % vCenter Yes Usage in MHz Host level MHz vCenter Yes Demand Host level MHz ESXi Yes You know that only Utilization (%) and Used (%) exist at the thread level because they are the only one you see at esxtop2, as shown below.\nWith so many counters, which one should you choose?\nLet\u0026rsquo;s now evaluate all the possible scenarios so you can compare the values returned by the counters. We will use a simple ESXi with 2 cores. Each core has 2 threads. In each of the scenario, a thread is either running or not running. There is no partial run within a thread as that\u0026rsquo;s mathematically covered in our scenarios.\nI will also use 20000 ms as that\u0026rsquo;s more familiar. The following table shows an ESXi with 2 cores. There are 6 possible permutations in their utilization.\nThe table shows clearly that Used splits the Utilization into 2 when both threads are running.\nLook at scenario 1. While Utilization charges 20000 ms to each thread, Used charges 10000. To me, this is not intuitive as ESXi considers HT to deliver 1.25x. Personally I find 12500 easier to understand. The good news is this number is normalized back when it is rolled up to the ESXi host level.\nLook at the first row, especially the cell in green.\nDo you notice something strange with the value of Used (%)?\nYes, it\u0026rsquo;s no longer 50%. It\u0026rsquo;s 100%. The reason is the accounting does not count each thread as 100%. So each core has 20000 and not 40000. If you say that is similar behaviour to Core Utilization, you\u0026rsquo;re right.\nI highlighted with a yellow number 3 areas that you need to pay attention to:\nUtilization is only showing 50% when both cores are utilized. I prefer this to show 80% as HT only delivers 1.25x not 2x. Usage goes up too fast. It\u0026rsquo;s already showing 100% when there is still 25% room left. I prefer this to show 80% to reflect the headroom. The CPU is already 1.5x its frequency, due to Turbo Boost. Usage does not reflect this as the value is capped at 100%. I prefer this to show 150%, to distinguish it from the other 100%. The good part is Demand will be 150%. Let\u0026rsquo;s take some ESXi hosts running production workload to see how the values compare in real world. Each row represents an ESXi host. What\u0026rsquo;s your conclusion from reviewing the following table?\nI\u0026rsquo;ve marked two of the rows with a red dot.\nThe first one happens because of CPU scaling. Not all cores are busy, since Core Utilization shows 72%. The busy ones were dynamically boosted by VMkernel by an average of 21%, hence the Usage counter registers 88% The second example is the opposite. This ESXi is not even 50% utilized, as the core utilization shows 48.88%. VMkernel decides that it could complete the job with less power, and clocks down by an average of 43%. Notice that Usage (%) does not count the hyperthreading. The Total Capacity metric is simply based on cores x nominal speed.\nNow that we know more, which ones should we use and how?\nThe answer depends on the purpose (capacity or performance), and your answer to the following question. There is no right and wrong.\nSay you have an ESXi with 60 cores, 120 threads. What\u0026rsquo;s the capacity? 60 logical CPU or 120 logical CPU? ESXi can run 120 vCPU worth of VMs concurrently, meaning the VMs won\u0026rsquo;t experience CPU Ready. Sure, they will run slower but that\u0026rsquo;s a performance, and not capacity question. It would be the same as having a slower hardware, as the VMs are not put in ready state. The above CPU is 2 GHz, with static power management. That means both Turbo Boost and power savings will happen concurrently. Some cores will run above 2 GHz, while the idle ones run below 2 GHz to ensure the total power envelope of the CPU remains optimized. So what\u0026rsquo;s the capacity? By right, it should reflect reality of each core, but that visibility is only available at esxtop. For ease of accounting, let\u0026rsquo;s agree the capacity is fixed at 2 GHz. Do you have 120 GHz or 240 GHz? Or you want to use 60 cores x 2 GHz x 1.25 = 150 GHz to account for HT only delivering 1.25x? My personal take is you have 120 logical CPU but 150 GHz, as the combined throughput is neither 120 GHz nor 240 GHz. To me, this is a balanced approach that recognise that HT does indeed deliver additional capacity, but not wrongly assumes they deliver 2x.\nFor CPU clock speed, as it fluctuates across time and varies per core, I recommend you ignore it so the Total Capacity does not become a variable. This also lets you see if the CPU is on Turbo Boost. The limitation of this approach is your demand metric likely exceed 100% when Turbo Boost kicks in.\nCapacity I\u0026rsquo;d use Utilization (%) for aggressive and Core Utilization (%) for conservative.\nFrequency scaling is not relevant; hence I do not use Usage. Usage will also inflate the numbers as VMkernel will take advantage of turbo boost. The drawback of this approach is you may see a different number to what vCenter uses as it uses Usage.\nIf Core Utilization is not yet 100% or Utilization is not yet 50% then there is still physical cores available. You can go ahead deploy new VMs.\nIf Core Utilization = 100% (meaning Utilization is at least 50%) then review Utilization and ensure it\u0026rsquo;s not passing your threshold. I\u0026rsquo;d keep it around 80% - 90% per ESXi, meaning the level at cluster level will be lower as we have HA host.\nIf you want to see the number in GHz, then use Usage and Total Capacity. Just don\u0026rsquo;t be alarm if Usage hits 100%. Check the contention counters, as always!\nPerformance I\u0026rsquo;d use Utilization (%) but will accompany it with the contention metrics. Since it\u0026rsquo;s about performance troubleshooting, I\u0026rsquo;d set the threshold around 90% - 95%. For Capacity, you can also add Demand (%) counter to see how high above 100%. The following shows it exceeds 100% but only marginally and momentarily. When Demand passes 100% it means the CPU is running hot (high power consumption) and both threads are busy. Buying more cores or higher frequency could result in the VMs running faster, assuming CPU is the gating factor.\nOther Counters We\u0026rsquo;ve covered the key counters. Let\u0026rsquo;s now look at the rest of the counters\nESXi Peak Core CPU Usage Is any of the physical threads running hot?\nAn ESXi with 72 CPU cores will have 144 logical processors. Hence it\u0026rsquo;s possible that one of them is running hot, while the rest is not. You will not be able to see that single core peak at ESXi Host level as it\u0026rsquo;s the average of 144 metrics. If you are concerned that any of them is running hot, you need to track the peak among them.\nPeak CPU Core Usage (%) tracks the highest CPU Usage among the CPU cores. A constantly high number indicates that one or more of the physical cores has high utilization. So long the highest among any cores at any given time is low, it does not matter which one at a specific point in time. They can take turn to be hot, it does not change the conclusion of troubleshooting. Max() is used instead of 95thpercentile as both result in the same remediation action, and Max() can give better early warning.\nThe unbalanced value among the cores is not needed because unbalance is expected when utilization is not high. When a VM runs, it runs on a few cores, not spread out to all ESXi cores. It\u0026rsquo;s more efficient to schedule that way, as will requires less context switches.\nCPU Architecture As CPU architecture moves towards System on a Chip design, it\u0026rsquo;s important not to assume that a CPU socket is a simple and linear collection of cores. Take a 64-core AMD EPYC for example. It\u0026rsquo;s actually made of 8 Core Complex Dies. From the following diagram, you can see that a thread on CCD 0 is relatively close to a thread that runs on the same CCX, but far to a thread that runs on another CCD. You can see an example of the performance impact here.\nAnother consideration you need to be aware of is NUMA.\nI use 20 second as it\u0026rsquo;s a familiar number. That\u0026rsquo;s what you see in the real time chart in vCenter client, and 20000 ms is often used as the 100% when converting millisecond unit to percentage.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSource: VMworld presentation HCP2583 by Richard Lu and Qasim Ali\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-1---overview/2.1.3-roll-up-vs-aggregation/",
      "title": "3. Roll-Up vs Aggregation",
      "tags": [],
      "description": "",
      "content": "Before we cover the counters, you need to know the various units and how they get:\nrolled up across time (e.g. from 20 second to 5 minutes) aggregated across parent (higher level object). Some common units are milliseconds, MHz, percent, KBps, and KB. Some counters are shown in MHz, which means you need to compare with the ESXi physical CPU static frequency1. In large environments, this can be operationally difficult as you have different ESXi hosts from different generations (and hence, are likely to sport a different GHz). This is also the reason why cluster is the smallest logical building block. If your cluster has ESXi hosts with different frequencies, these MHz-based counters can be difficult to use, as the VMs get vMotion-ed by DRS.\nHow about milliseconds for CPU? Where does it come from and why?\nTo answer that, we need to go deep to the ESXi VMkernel scheduler. Think in terms of the passage of time and the amount of CPU cycles that get completed during that time. A CPU core running at 2 GHz will get 2x CPU cycles completed compared with a core running at 1 GHz. The same goes with Hyper Threading. You get less cycles completed when there is a peer thread competing at the same time.\nWhat you think as utilization or usage or demand or used, it will be easier if you see them as cycles, once you make that small paradigm shift.\nLet\u0026rsquo;s take VM CPU Ready. The following is taken from ESXi vsish command. It shows that the original, raw counter is actually a running number. To calculate the CPU ready of a given time period, we need to subtract the last number from the first number. To convert to percentage, we divide over the collection, which is 20000 ms in the screenshot.\nComplementing units are Stat Type. There are 3 types:\nDelta The value is derived from a running counter. What you see is difference between 2 points in time. All the units in miliseconds are of delta type.\nRate The value measures the rate of change, such as throughput per second. Rate is always the average across the 20 second period. Note: there are metrics with percentage as unit and rate as stat type. I\u0026rsquo;m puzzled why.\nAbsolute The value is a standalone number, not relative to other numbers. Absolute can be latest value at 20th second or the average value across the 20 second period.\nRoll-up The Rollups column is important. Average means the average of 5 minutes in the case of vRealize Operations. What about Summation? Why does the number keep going up as you roll up?\nIt is actually average for those counters where accumulation makes more sense. Let\u0026rsquo;s take an example. CPU Ready Time gets accumulated over the sampling period. vCenter reports counters every 20 seconds, which is 20000 milliseconds. The following table shows a VM has different CPU Ready Time on each second. It has 900 ms CPU Ready on the 5th and 6th second, but has lower number on the remaining 18 seconds.\nOver a period of 20 seconds, a VM may accumulate different CPU Ready Time for each second. vCenter sums all these numbers, then divides it by 20,000. This is actually an average, as you lose the peak within the period.\nLatest, on the other hand, is different. It takes the last value of the sampling period. For example, in the 20-second sampling, it takes the value between 19th and 20th seconds. This value can be lower or higher than the average of the entire 20 seconds period. Latest is less popular compared with average as you miss 95% of the data.\nRolling up from 20 seconds to 5 minutes or higher results in further averaging, regardless whether the rollup technique is summation or average. This is the reason why it is better to use vRealize Operations than vCenter for data older than 1 day, as vCenter averages the data further, into a 0.5 hour average.\nBecause the source data is based on 20-second, and vRealize Operations by default averages these data, the \u0026ldquo;100%\u0026rdquo; of any milisecond data is 20,000 ms, not 300,000 ms. When you see CPU Ready of 3000 ms, that\u0026rsquo;s actually 15% and not 1%.\nBy default, vRealize Operations takes data every 5 minutes. This means it is not suitable to troubleshoot performance that does not last for 5 minutes. In fact, if the performance issue only lasts for 5 minutes, you may not get any alert, because the collection could happen exactly in the middle of those 5 minutes. For example, let\u0026rsquo;s assume the CPU is idle from 08:00:00 to 08:02:30, spikes from 08:02:30 to 08:07:30, and then again is idle from 08:07:30 to 08:10:00. If vRealize Operations is collecting at exactly 08:00, 08:05, and 08:10, you will not see the spike as it is spread over two data points. This means, for vRealize Operations to pick up the spike in its entirety without any idle data, the spike may have to last for 10 minutes.\nvRealize Operations is capable of storing the individual 20-seconds data. But that would result in 15x more data. In most cases, what you want is the peak among the 15 data points. This is where a new set of troubleshooting metrics come in.\nThe Collection Level in vCenter does not apply to vRealize Operations. Changing the collection level does not impact what counters get collected by vRealize Operations. It collects all counters from vCenter using its own filter, which you can customize via policy.\nAggregation Aggregating to a higher-level object is complex as there is no lossless solution. You are trying to represent a range of values by picking up 1 value among them, so you tend to lose the details. The choices of techniques are mean, median, max, min, percentile, and count of. The default technique used is the average() function. The problem with average is it will mask out the problems unless they are widespread. By the time the average performance of 1000 VMs is bad, you likely have a hundred VMs in bad shape.\nLet\u0026rsquo;s take an example. The following table shows ESXi hosts. The first host has CPU Ready of 149,116.33 ms. Is that a bad number?\nIt is hard to conclude. That host has 67 running VMs, and each of those VMs can have multiple vCPU. In total there are 195 vCPU. Each vCPU could potentially experience CPU Ready of 20,000 ms (which is the worst possible scenario).\nIf you sum the CPU Ready of the 67 VM, what number would you get?\nYou\u0026rsquo;re right, you get the same number reported by the ESXi host. This means the ESXi CPU Ready = Sum (VM CPU Ready), and the VM CPU Ready = Sum (VM vCPU Ready).\nBecause it\u0026rsquo;s a summation of the VMs, to convert into % requires you to divide with the number of running VM vCPU.\nESXi CPU Ready (%) = ESXi CPU Ready (ms) / Sum (vCPU of running VMs)\nAre the CPU Ready equally distributed among the VMs? What do you think?\nIt depends on many settings, so there is a good chance you get something like the following. This heat map shows the 67 VMs on the above host, colored by CPU Ready and sized by VM CPU configuration. You can see that the larger VMs tend to have higher CPU ready, as they have more vCPU.\nYou also need to consider performance requirements in analysing millions of data points. Averaging from 100K object every 5 minutes will require a lot of resource. For VMware Horizon, we apply a 2-step roll up technique to minimize the calculation cost. Mathematically, it is less accurate as a small VDI Pool or RDS Farm is treated equally with the large ones. Operationally, just because they are smaller do not mean they are less important.\nIn reality, the CPU frequency varies on a per core basis. It also varies over time. For ease of accounting, we assume it\u0026rsquo;s static for entire box.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-7---availability-management/1.7.3-availability-reporting/",
      "title": "3. Availability Reporting",
      "tags": [],
      "description": "",
      "content": "Can you spot the limitation of the above calculation?\nHint: it measures in 1 month.\nHow many minutes of downtime is allowed with 99.9% in a typical month?\nAbout 43 minutes, which is a long time if it happens during busy time. You can potentially lose a lot of business, not to mention customers unhappiness.\nThe problem with the above calculation is it calculates per month. It fails to account that there is a big difference between all components down at the same time vs different time. Review the following table, which records the uptime every 5 minutes.\nThe above system has 3 tiers: web, application and database.\nThe web tier is sized with 8 VM, plus 2 additional VM added for resilience. The application tier is designed with 3+1 server farm. The database uses active/passive design.\nLet\u0026rsquo;s step through the time to show how difference scenarios impact availability.\n9:00 - 9:05 am 1 of the web server is down. All other servers are up. For simplicity, we assume the downtime is exactly 300 seconds. The uptime of the web tier become 9/10 = 90%. Overall, the system uptime is 90%. SLA is not impacted as the web tier has been designed to handle 2 failures. While SLA not impacted, it\u0026rsquo;s important to record the fact that the uptime is not perfect. 9:05 - 9:10 am 1 web server + 1 application server is down. All other servers are up. The uptime of the web tier become 9/10 = 90%. The uptime of the application tier become 3/4 = 75%. Overall, the system uptime is 68%. SLA is not impacted, as neither tier has violated their thresholds. 9:10 - 9:15 am 3 web servers are down. All other servers are up. The uptime of the web tier become 7/10 = 70%. Overall, the system uptime is 70%. This is higher than the 68% previously, but this time the SLA is impacted as the web tier is not designed to handle 3 failures. From here you can see that uptime and SLA can differ. - The former is absolute and technical, while SLA is relative to the design and any business contracts. 9:15 - 9:20 am As previous, but 1 application server is down. It\u0026rsquo;s important to reflect this deteriotation, hence the uptime drops from 70% -\u0026gt; 53%. SLA does not care about it, as it focuses on fail or not. It\u0026rsquo;s binary within that 5 minutes. We can now continue the timeline for entire month. I\u0026rsquo;m modifying the example a bit to drive the point that SLA and reality can differ.\nFrom 9:00 am - 9:30 am, the system never has 100% uptime. For the rest of the month, it has a perfect 100% uptime.\nSLA is only impacted for 5 minutes. All other downtime do not impact SLA because the system has been designed to handle the failure or it is a scheduled downtime.\nSLA is based on calendar month. Using February 2021 as the example, there are 28 days. This translates into 8064 counts of 5-minute.\nSLA (8064 - 1) / 8064 = 99.988% If the SLA is 99.95, then you pass for the month of February 2021. Reality Average of (34% + 3.75% + 0 + 0% + 34% + 34% + 100% + 100% + 100% + \u0026hellip;) Yes, we simply average all the 8064 numbers that make up February 2021. Result is 99.939% The gap between reality and SLA provides valuable input.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-6---compliance-management/1.6.3-continuous-compliance/",
      "title": "3. Continuous Compliance",
      "tags": [],
      "description": "",
      "content": "While configuring an environment according to the security guidelines is very important, that is just the starting point. Maintaining the same level of configuration on an ongoing basis is of utmost importance. With time configurations drifts occur. How do we make sure the changed environment is still compliant to the set policies? In every organization a compliance test is done on a regular interval, say once a week. What about the status between the checks? Consider the following situation where an organization scheduled a compliance check every week on Sunday at 10 p.m. So, the check catches any drift in between and reported accordingly.\nIn the above example, between 1st and 2nd week the configuration drift was unreported for days and between 3rd and 4th week it went unreported for days. This may lead to serious security lapse or concerns.\nvRealize Operations provides alerts, policies, and reports to validate the vSphere resources against these benchmarks, delivering a continuous compliance checking every 5 minute with alerts. It provides multiple ways to check compliance against a defined benchmark. This includes VMware recommended suggestions, benchmarks from regulatory organizations and even enables you the ability to define a custom policy. Note, these are three different categories of benchmarks available in vRealize Operations with no interdependence. These are listed below in the order they merely appear in the page rather than a preference. Their details are provided below:\nVMware SDDC Benchmarks These are pre-defined VMware benchmarks which monitors the environment against various VMware defined security recommendations. These are further categorized into the following three sub-categories:\nvSphere Security Configuration Guide vSAN Security Configuration Guide NSX-T Security Configuration Guide Custom Benchmarks Build your own custom benchmarking policies and check the environment against those custom defined policies.\nRegulatory Benchmarks Out of the box regulatory compliances, specifically the following:\nCIS Security Standards DISA Security Standards FISMA Security Standards HIPAA Compliance ISO Security Standards PCI Security Standards While VMware SDDC benchmarks provide guidance for securely configuring the virtualized environment, the regulatory benchmarks serve a different purpose. Both the regulatory benchmarks and VMware benchmarks provide similar guidance on the same objects but the regulatory bodies certify the requirements.\nFor example, assume I am a consumer from health industry. Hence I have specific security requirements. How do I know whether the provider I am considering has the necessary security in place? This is where the regulatory benchmarks come in handy. These are tried and tested guidelines aiming for specific industry and requirement. So, if a provider complies to HIPAA benchmark I can be assured that this provider will cater to my security requirement.\nNow imagine taking the HIPAA benchmark guideline and its hundreds of recommendations, implementing it and constantly checking to make sure the environment is compliant. This would require a great deal of work on an ongoing basis. Next consider implementing vRealize Operations and enabling the HIPAA benchmark. You get a dashboard card showing what the compliance status is. For variance you know exactly what needs to be fixed and you can fix it in a jiffy. Just share the report with the customer at any time to prove you are compliant to the requirement.\nBy default all these policies not activated. For the VMware SDDC benchmarks you can enable them from the same page. But for the regulatory benchmarks you need to enable them from the repository.\nThese benchmarks are enabled per defined \u0026ldquo;policies\u0026rdquo; in vRealize Operations. That means you can check different environments for different benchmarks. For example, consider an organization consisting of two different environments. The first environment needs to be HIPAA compliant and the second one needs to be PCI compliant. So, create two different policies for these two environments and then enable benchmarks accordingly to these environments and respective policies. As an example, consider a hospital. In hospitals they store patient information which requires a HIPAA compliant environment. At the same time they accept online payments for the services they provide. This requires an environment which needs to be PCI compliant. One solution to this may be to build a virtualized environment managed by a vCenter server and set up two different clusters catering to the above requirements. With the vRealize Operations integration, we can apply two different policies for these two clusters and apply two different benchmarks to these respectively. This will ensure the required HIPAA and PCI compliance for the environments.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-5---cost-management/1.5.3-cost/",
      "title": "3. Cost",
      "tags": [],
      "description": "",
      "content": "It\u0026rsquo;s important to calculate unit cost, despite the fact it does not actually exist. When you bought that cluster, you did not pay $1 per GHz of CPU. You paid $100,000 for the entire thing, including installation. The $1 is just for ease of calculation so you do not end up with a loss.\nThe Unit cost per VM depends on Overcommitment Ratio, since the hardware cost is identical. If cluster A has 2x overcommitment ratio, then the cost per VM is 2x cheaper, all else being equal.\nOvercommitment Ratio is the way you justify a higher price, hence it\u0026rsquo;s imperative to disclose upfront to your customers.\nUnit Cost has to be associated with VM, not ESXi. It is expressed in vCPU, not per physical core or GHz. How many vCPU you plan to pack determines the cost per vCPU.\nUnit Cost depends on hardware and software. New cluster should cost less due to bigger hardware.\nUnit Price should remain the same within the same class of service. Back to the airline industry example, the price does not depend on the aircraft generation.\nCost Savings From finance point of view, real cost savings is only realized when new purchase is deferred. You can\u0026rsquo;t save on what you\u0026rsquo;ve already spent, accounting wise. Cost Savings is actually Cost Avoidance.\nLet\u0026rsquo;s take a simple example:\nYou spend $2 million on a hyper-converged infrastructure (HCI) solution 3 years ago. It has been used well, and capacity remaining is now 0%, so you need to buy a new HCI. This will cost you only $1 million as the cost of HCI solution has gone down by half in the last 3 years. Via a diligent and arduous reclamation process, you manage to free up capacity. As a result, you do not need to spend the $1 million. You can defer this purchase to the next fiscal year. What\u0026rsquo;s your cost savings from this reclamation: $2 million or $1 million? Accounting wise, it\u0026rsquo;s $1 million only. While that HCI cost you $2 million three years ago, a brand new set with equivalent capacity will only cost you $1 million. In accounting rules, you should not mix numbers from different date, let alone from different fiscal years. Depreciation is not relevant here as the cost is based on replacement cost.\nThe $1 million is certainly an estimation. The actual cost avoided or to be spent depends on vendor quotation, and your negotiation skills. Take note that the actual is much more than the HCI cost. Additional costs can exceed the hardware cost. You need to include the full loaded cost, such as data center facility, implementation service, back up storage, administration service, software licence, management, etc.\nReclamation alone does not reduce cost. How much do you save when you delete files in your notebook?\nRight. Zero.\nOnly when it helps you defer buying a new drive that the reclamation becomes a real cost saving.\nHow about service? We like to cite productivity improvement as a cost saving. While this delivers business value, it is not a hard cost savings. It is a soft benefit with no accounting value. The hard savings only happen when the need to buy additional resource/headcount is deferred, or reduction in Managed Services contract value.\nYou might be able to save from power \u0026amp; cooling by powering off hardware.\nFor large organization with a large infrastructure footprint, tech refresh is a great way to reduce cost. Going down from 100 racks to 50 racks will certainly reduce both capital and operating cost.\nIT needs to be ahead of business. When calculating the cost savings, includes committed projects and future growth. You should also take into account undersized VMs, as the application team may demand that they are upsized.\nCalculate CPU, RAM and Disk. If possible, include network too. It is harder to calculate, as by nature it\u0026rsquo;s just interconnect. For each of these three IaaS resources, calculate both the demand and the reclamation. For the demand, don\u0026rsquo;t forget to include the full cost. When a VM needs 100 GB, it translates into a lot more as you factor is DR, back up, snapshot, etc.\nThe following table provides an example.\nYou need to prepare the above table per physical location. Just because you have 10 TB RAM in Singapore does not mean the VMs in Armenia can use it.\nOptimized Cost The above exercise will help in optimizing cost. There are certainly other avenues to optimize cost, as cost covers more than just capacity. It covers People, Process, Architecture. You can reduce cost by improving process effectiveness, typically achieved by business process reengineering exercise. You can reduce cost by improving process efficiency by automation. E.g. deletion of powered off VM with approval workflow.\nThe following table summarizes the activities you can do to optimize cost.\nSmall clusters have higher HA overhead, hence you can optimize cost by consolidating them.\nComplexity has cost, but it is hard to quantify. For example, human error can be costly but how do you quantify that?\nTake note that standardization will reduce complexity. But this also means less flexible configuration, which can increase cost.\nSimplifying operations, such as not mixing VMs with different class of services in the same cluster, will reduce complexity. But it also comes at a cost of larger infrastructure. The same thing goes with t-shirt sizing.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-4---configuration-management/1.4.3-plan-vs-reality/",
      "title": "3. Plan vs Reality",
      "tags": [],
      "description": "",
      "content": "The actual configurations you have in production should reflect your current architecture standard. Your architecture or standard may change over the years, but it should be documented. You then use the configuration dashboards to compare the reality versus intended standard. If they differ, one of them is wrong and needs to be addressed.\nStandards make operations simpler and are often required for compliance. For example, you have a standard for VMware Tools versions, and you choose one version as your standard, but allow 2 other versions across your environment as it takes time to upgrade. You can create a pie chart showing the distribution of VMware Tools version. Each slice in the pie chart counts the occurrence of a particular value. You should expect to see only three slices. If You are seeing more than three, then the reality differs to your standard.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.3-capacity-planning/",
      "title": "3. Capacity Planning",
      "tags": [],
      "description": "",
      "content": "For IaaS or DaaS, capacity management begins long before hardware is deployed. It begins with a business plan, which decides on what class of service will be provided. Each class of service (e.g. gold, silver, bronze) is differentiated by the quality of service. This typically covers availability (e.g. 99.99% uptime for Gold, 99.95% uptime for Silver), performance, and security/compliance. This was covered earlier in SLA.\nThe preceding table is a generic guideline. As part of your planning with IT Management, you help them define and decide on each Class of Service. This planning session requires vendors input as you want to optimize cost. Use vendors discounting and licensing model to complement the plan, not dictate the plan.\nAt the end of the planning session, you may end up with something like this.\nIn this example, IT Management decides to only provide two business offering:\nSilver: 33% discount at 2% performance penalty Bronze: 67% discount at 5% performance penalty Kim Ramirez advises that from a pricing psychology standpoint it might make sense to offer Gold, with the expectation that nobody will buy it, and it only serves to make Silver look like a good deal. This also addresses a potential confusion where customers wonder where Gold is, if they only see Silver and Bronze offers.\nQuality incurs cost which in turn impacts price. Gold VM is priced higher per vCPU and per GB of memory because it has a higher quality of service. A proper pricing model needs to be planned. A 16 vCPU VM on Silver Tier does cost more than 1 vCPU VM on Gold Tier. This is the behaviour you want to drive. Right tier, right size.\nIf you want your customers to right size in advance, then a 64 vCPU VM needs to be more than 64x the price of 1 vCPU VM. If the pricing model is a simple straight line, there is no incentive to go small and no penalty to over provision. You will end up forcing rightsizing in production, which is a costly and time-consuming process.\nRefer to Cost Management for pricing example as Cost and Price go hand in hand.\nBecause you overcommit, you run the risk of contention. To minimize it, one way is to control the size of the VM. You want to avoid monster VMs dominating your overcommitted ESXi host. The following table provides an example of the size limit you associate with each class of service.\nFor comparison, AWS free tier for EC2 VM is only 1-2 vCPU, 1 GB RAM as it\u0026rsquo;s based on t2.micro and t3.micro.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.3-plan-monitor-troubleshoot-optimize/",
      "title": "3. Plan | Monitor | Troubleshoot | Optimize",
      "tags": [],
      "description": "",
      "content": "There are four distinct processes in performance management:\nPlan This is where you set the performance goal. Make sure the goal is aligned with the business deliverable.\nWhen you architect that vSAN, how many milliseconds of disk latency did you have in mind? For example, you set the goal of 10 ms measured at VM level (not vSAN level and not at individual virtual disk level).\nMonitor This is where you compare Plan vs Actual. That\u0026rsquo;s why the goal must be clearly defined. Does the reality match what your architecture was supposed to deliver? If not, then you need to fix it.\nTroubleshoot You do this when reality is worse than plan, or something amiss, not when there is a complaint. You want to take time in troubleshooting, so it\u0026rsquo;s best done proactively. And quietly with no one rushing you for results.\nOptimize As part your monitoring, you may not discover problem, but you spot opportunity to make performance even better. It\u0026rsquo;s common for new version to deliver performance improvement. Again, you do this proactively, not waiting for complaint to happen.\nMonitor is What, while Troubleshoot is Why. Monitor is part of a Standard Operating Procedure (SOP), while Troubleshoot is an ad hoc, on-demand process. Monitor can be performed by the Level 1 team, with the aid of predefined dashboard and alerts, while Troubleshoot requires expert team. The expert team is also the team setting up the thresholds used by the Level 1 team. Troubleshoot involves logs analysis, as many systems do not generate complete metrics, and there can be many different causes behind a common problem. At the end, the actual root cause may not even be closely related to the problem.\nDay to day operations become more systematic when you distinguish between monitor and troubleshoot. The following table shows the difference:\nMonitor Troubleshoot Question What is the problem? Why does it happen? What is the actual cause of the problem? Nature Proactive Reactive Counter Generally, 1 counter. And this counter is also the SLA. This is the 1st counter you or your customer check. Always many counters. There are layers of counters, one impacting another. SLA Yes, meaning SLA is applicable Yes. It becomes urgent if SLA is breached. KPI Yes, meaning you use KPI in monitoring instead of individual metrics. Yes, but as a starting point. You then drill down into supporting metrics, which are often raw metrics. Metrics Primary counter. You check it proactively as part of SOP Secondary counter. You only check if the primary is reaching threshold. Frequency Performed daily. Gold Class will have higher frequency of regular monitoring than Bronze, as part of SLA. On demand. Timeline Now and Future. You consider future load and anticipate. Now. Future is irrelevant. Your focus is to put out the fire or potential fire. In most cases, Monitor is best done using a 5-minute interval, as 1 minute of bad metrics may not have business impact. Troubleshoot on the other hand may require per second granularity. However, that does not always mean you need to see each and every counter, if your remediation action is the same.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/",
      "title": "Operations Management",
      "tags": [],
      "description": "",
      "content": "The first part of the book explains the art of Operations Management in the context of VMware cloud architecture. It is a pre-requisite to Part 2.\nWhat you architect is SDDC. But what you handover as a business result to your CIO is IaaS. One is a system, the other is a service. We can assess if the architecture is good or not, based on the actual result in production. Does it result in firefighting and blamestorming? Or do you have a peaceful operation where alerts are meaningful and actionable?\nChapter 1 - Overview\r1. Complaint-Based Operations\r2. Purpose-Driven Architecture\r3. Multi-Cloud Operations\r4. Begin with the end in mind\r5. VCDX vs. VCOX\r6. The Restaurant Analogy\r7. Service Level Agreement\r8. Pillar | Process | People\r9. Insight vs. Alert\rChapter 2 - Performance Management\r1. A Day In The Life of a Cloud Admin\r2. The 3 Realms\r3. Plan | Monitor | Troubleshoot | Optimize\r4. Contention vs Utilization\r5. Performance vs Capacity\r6. Performance SLA\r7. KPI vs. SLA\r8. Depth vs Breadth\r9. Leading Indicators\r10. Baseline Profiling\r11. Optimized Performance\r12. Root Cause Analysis\rChapter 3 - Capacity Management\r1. \u0026#34;Good\u0026#34; Advice\r2. End-to-End Capacity\r3. Capacity Planning\r4. Demand Model\r5. Allocation Model\r6. Usable Capacity\r7. Projection\r8. Peak Utilization\r9. Storage Capacity\r10. Optimized Capacity\r11. Reclamation\r12. Rightsizing\rChapter 4 - Configuration Management\r1. Overview\r2. Review Flow\r3. Plan vs Reality\rChapter 5 - Cost Management\r1. Dare to Compare\r2. Price\r3. Cost\rChapter 6 - Compliance Management\r1. Overview\r2. Security Approach\r3. Continuous Compliance\r4. How the Policies Work\r5. Regulatory Benchmarks\r6. Custom Benchmarks\r7. Checking the Result\rChapter 7 - Availability Management\r1. Standalone System\r2. Multi Component System\r3. Availability Reporting\r4. Disaster Avoidance and Recovery\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-9---infrastructure-architect/4.9.4-about-the-author/",
      "title": "4. About the Author",
      "tags": [],
      "description": "",
      "content": "Wow, you made it to the end of the book. If you have read this far I certainly want to know more about you. So here is a bit about me.\nI was born in the beautiful island of Lombok(Indonesia), grew up in Surabaya (Indonesia), studied in Australia, and since 1994 I live in Singapore.\nI graduated from Bond University in 1994, then migrated to Singapore and started working in IT. I still remember that I carried Apple Mac LC (yup, with the 12\u0026quot; monitor) to Singapore in June 1994.\nFirst 9 years of my career was at the Application layer, doing business process innovation and application development. Lettuce Node, I mean Lotus Notus, was and is still dear to my heart.\nI moved to infrastructure world in 2003, focusing on UNIX by joining Sun Microsystems. I joined without knowing what UNIX was and basically zero knowledge of infrastructure. I came to join as SE with no presales experience. My previous manager Seet Pheng Kue recommended me, together with the headhunter FA Mok, and Kim Boo Png made the hiring decision. I\u0026rsquo;m always grateful for what they have done as that forever changed my career. From high level programming to low level hard code infrastructure!\nIn 2008 I applied to VMware as I wanted to follow my sales Chan Seng Chye. Poh Wah Lee convinced me to join VMware as part his team, and until today I still see him as my elder and leader.\nMy email is e1@vmware.com and mobile is +65.9119.9226.\nYou can see more of my works on the Internet. Google has somehow tracks it\nOperationalize Your World The transformation toward multi-cloud operations is a journey. The same journey happened that resulted in this book on your screen. It took years for it to reach the level of maturity.\n2021Retire Virtual Red Dot as it has served its purpose. It's always to prepare the material for a book. With blog, it's impossible to keep contents up to date and structured.\n3rd Edition published. It's made available as free and open source book.\nHorizon adapter released. As you can see in the Horizon chapter, it took the concept of KPI further. This is a great collaboration with EUC specialists Cameron Fore and Fahad Khan.\n2020vRealize Operations 8.2 was released, sporting a brand new content taken from Operationalize Your World. The last major refresh was 6.4 release, and the gap between the 2 version shows how far the content and product have improved.2019Started working on the 3rd edition. Exploring if I should make it free, editable and living document. Grappling with how to make it easy out of the box while allowing flexibility.\nvRealize Operations 8.0 was released. Compared with the early days of version 5.8, the ease of use and power on dashboards and super metrics have had numorous enhancements.\n2018Officially joined vRealize team as Product Manager.2017Heavy travelling as part of global role and delivering workshops.\nStarted working with Varghese Philipose, Shiv Diddee and team. The Middle East and North Africa team would eventually a close partner as we improve the product and content.\n2016vRealize Operations 6.4 was released, sporting a brand new content taken from Operationalize Your World.\nJumped from local role to global role.\nKenon Owens created a program called Operationalize Your World. We did many tours around Asia Pacific, delivering 1-2 day workshop.\n2nd Edition published. It was ~550 pages, and scope broadened to include vSphere and vRealize Operations metrics. Tested the idea of contributing authors.\n2015VMworld debut of the solution. Sunny and I presented in 2 sessions to ~600 audience.20141st Edition published. It was ~250 pages, and scope was performance and capacity\nBecame a member of ambassadors of the CTO Office.\n2013The idea of converting blogs and slides into a book was born. Tried to make it work with 2 other authors to split the load. Tried to make it work with VMware Education.\nVirtual Red Dot was born.\n2012Started blogging, using free domain and hosting. Sunny helped me.2011vCenter Operations 1.0 released. I got the training in Sydney, by David Lavigna. That was the light bulb moment as I'd been troubleshooting manually using vCenter and esxtop.\nGot VCAP DCD. I was one of the first to pass the VCAP DCD exam globally as I participated in the beta. My number is 89. That knowledge proved to be critical for 1+ decade as you can see in this book.\n2009Set up VCP Club, a subset of User Group that has got VCP.2008I joined VMware as SE for global accounts. A fair bit of my time was helping them troubleshoot performance problem, do capacity planning and review configuration best practice. I tried making sure what I sold is operationalized.\nGot my VCP.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.4-performance-management/",
      "title": "4. Performance Management",
      "tags": [],
      "description": "",
      "content": "Performance ranks high in VDI operations so let\u0026rsquo;s start with it. Horizon is a complex architecture with many components and layer. How do you know Horizon is performing?\nOne good way to answer is to begin with the end in mind. The purpose of DaaS is to provide acceptable user experience. To deliver that, there are 3 components (Edge, Network, Data Center) that must work well. Horizon is a client/server architecture, meaning it has a Horizon Client software that runs at the edge, talking via the network to a server agent software residing in the data center.\nThe client software does the screen rendering. Due to lack of contention and utilization metrics, we can\u0026rsquo;t measure its performance. Some thin client or zero client has a tiny OS that support syslog.\nThe network consists of the protocol and the physical network. Typically, the physical network carries more than Horizon protocol. For example, you have IP telephony system, security cameras or remote servers in your branches. You need to have visibility at the consumer (Horizon protocol) level and provider (physical network) level. In most cases, the network is not owned by the EUC team, so EUC team is consuming a shared service. Because of this, the physical network metrics play the supporting role. They are not primary metrics used in the KPI.\nThe data center part is where the bulk of EUC component resides. This includes both VMware and non-VMware components.\nThe network part and the data center part are two independent parts, typically managed by different teams. You can have network problem without the data center problem, and vice versa. By separating them as separate KPI, you can see what kind of problems you have and do the necessary follow up. By combining them, you can potentially lose visibility as the good one can mask the bad one.\nBe mindful of the difference between the user has performance problem and the user causes performance problem.\nDuality of users Victim The user experiences problem.\nContention is high, utilization is low. Not getting work done, so productivity is impacted.\nUser is upset. Villain The user causes performance problem.\nUtilization is very high. Contention is irrelevant in this case. The user may get a lot of work done.\nOther users could be affected, so you are upset. Network KPI This is easier to measure as it has fewer metrics and only has 1 type of resource.\nThe latency is measured at PCoIP or Blast protocol layer, not TCP/UDP layer. Upper layer is more accurate as we can have packet loss at application-layer but Windows sees no dropped packet. The reason was the packet arrives out of order and hence unusable from Horizon viewpoint.\nWe\u0026rsquo;ve set the threshold value to be conservative yet realistic. If your users are accessing over the WAN or unreliable connection, then you may not see green. This is acceptable so long user actual productivity is not impacted.\nTime taken to load the user profile and time taken to logon are not included in the KPI because they are one time value. KPI needs to be a metric that can be evaluated regularly.\nAt this moment, we do not include variance in the latency. If you think we should, do recommend the value for each threshold.\nThe session network utilization is not part of the KPI as we can\u0026rsquo;t put the value into the range. The Blast Extreme protocol may be doing minimal work at that time for that user, so a low network throughput may not indicate poor user experience.\nData Center KPI The DC KPI depends on the types of object. A user can have VDI Session or RDS Session, served by VDI Pool and RDS Farm respectively.\nKPI Consideration VDI Session It has contention metrics. As it’s Windows OS running on a vSphere VM, it has metrics from both layers. RDS Session It does not have contention metrics. It only has utilization metrics and they cannot be used to determine if a user experience degrades.\nThis applies to both application session and desktop session. As a result, the KPI is taken from the RDS Host, which is a server VM serving many users concurrently. The drawback is RDS Host does not provide visibility into the performance of each session. Since both RDS Host and VDI Session is basically a Window VM, we are using the same KPI. Other than RDSH specific counter such as this one, there is no application level specific counters to measure contention. vRealize Operations uses the following counters and threshold to form the KPI.\nThe counters above are layered into 4, matching the layer used in performance troubleshooting. Look at the contention metrics first, then the utilization type.\nWe provide the threshold as they reflect Horizon best practice, which should work for most customers. Your situation may differ, which is why we provide the raw metrics too as the KPI metric cannot be modified.\nThe CPU Queue Length is the total queue length. In future, we may convert it into per vCPU. Same with disk latency, as read and write can move independantly.\nWe do not include CPU Context Switch and Disk Outstanding IO, as I\u0026rsquo;m not yet convinced on the threshold, based on the profiling data. The numbers vary too wide. Send me your profiling result so I can consider it too.\nWe do not include CPU Overlap as the value is negligible most of the time. It will be green most of the time, hence inflating the value unnecessarily.\nDo you know why we include Page-in but not Page-out? How about balloon, swapped and compressed? How come none of them are here? Refer to Part 2 Memory chapter for the answer.\nWe do not include Memory In Use as we have Free Memory. In Use is better for capacity, while Free is better for performance.\nVM CPU utilization is included because it\u0026rsquo;s possible that we have a runaway process that it\u0026rsquo;s impacting user performance. A runaway process typically consumes 1 vCPU so if the VM has 4 CPU the increase is only 25%.\nNow that we have the DC KPI and Network KPI at the smallest object, we can roll up to higher level object. For that, we need a correct hierarchy. The hierarchy is also required by other pillar of operations management.\nKPI Roll Up Using the above as the foundation, we can build the KPI at higher level object. Here is how we do it.\nEach VDI session has 2 KPI: Network KPI and Data Center KPI.\nThe VDI Pool Network KPI is simply the average of all its VDI Session Network KPI. While average is a lagging indicator, it best represents the entire reality, which is required for further roll up to the higher level object. We certainly will complement it with leading indicators.\nThe VDI Pool DC KPI is also the average of its session DC KPI. Because these 2 KPIs operate independantly, we do not combine them.\nFor RDS, the correponding object is RDS Farm, not RDS Host. It\u0026rsquo;s more logical to monitor at this level, just like we monitor at vSphere cluster level and not the individual ESXi. Just like a VM moves within a cluster, a user does not always get the same RDS host in the next session. We take the network KPI from RDS sessions and DC KPI from RDS hosts.\nWe combine both the VDI and RDS KPI at the Pod level. Again, we simply take the average of both. If you have more VDI Pools than RDS Farms, then the Pod KPI value will be driven by the VDI part of your architecture.\nPod DC KPI = Average (VDI Pool DC KPI, RDS Farm DC KPI)\nThe limitation of the above is it each pools and farms are given the same weightage. The number of sessions do not matter. The reason is you manage at pool and farm level, not individual session.\nThe KPI for higher level objects cannot be the average of Pod KPI, as Pod is basically a group. The KPI is still taken from VDI Pool and RDS Farm levels, as these objects provide the resource. This is to ensure fair representation if you have Pod of different size.\nHorizon World DC KPI = Average (VDI Pool DC KPI, RDS Farm DC KPI)\nWe do not include the Horizon server infrastructure at the KPI level. The reason is they are supporting metrics. They do not directly measure the user experience as none of their counters are session-specific. This is an example where we\u0026rsquo;re being careful in choosing KPI. Each KPI is ideally a primary metric, directly measuring the session performance. If you include supporting metrics, you can get false positive or false negative.\nLeading Indicator We covered in Part 1 Chapter 2 Performance Management that you need a leading indicator. The true KPI is a lagging indicator, so we need to complement it. The roll up technique matters so you balance the information.\nA Pod can have thousands of sessions, so how do you roll up?\nEach session has a KPI (%). This is a balanced approach, so we can take its value. At Farm or Pool level, if you take the worst among sessions, the value may be bad most of the time. A better way is to take the 95th percentile, and then complement with a count of sessions in the red. At Pod level, take the same approach, which is 95th percentile, complemented with a count of sessions in the red Using the above, here are the KPI metrics we have at the top level\n95th Percentile Pod DC KPI = 95th Percentile of all its (Farm KPIs, Pool KPIs) values 95th Percentile World DC KPI. Identical formula to Pod, so expect this to be lower than the average of all pods 95th Percentile Pod Network KPI. Same approach with DC KPI, but obviously using Network KPI as input. 95th Percentile World Network KPI. You got the idea. Yes, just 2 each for Pod and World, and 2 each for DC and Network. You need to keep it minimum so it\u0026rsquo;s easier to see over time.\nAt the Farm and Pool level, it\u0026rsquo;s the same approach.\n95th Percentile Farm DC KPI = 95th Percentile of all its RDS Hosts DC KPI values 95th Percentile Farm Network KPI. Same approach with DC KPI, but obviously using Network KPI as input. 95th Percentile Pool DC KPI. Same approach with RDS Farm, but obviously using VDI Session DC KPI as input. 95th Percentile Pod Network KPI. You got the idea. Now that we have the KPI, let\u0026rsquo;s look at the Horizon objects one by one, starting with the smallest/lowest one. We will also include all other performance metrics to complete the picture. To keep the list short and topic manageable, we will not include non performance metrics and properties. We will cover them separately.\nBaseline Profiling Horizon is one of the largest applications in a company, as it can span thousands of VMs and locations. It\u0026rsquo;s important to profile so you know what to expect. Different deployments can have a different performance characteristics, making it hard to establish best practice threshold. In a large scale deployment, different pools or farms can have different numbers. If your design expects a different performance for certain farm or pool, then profile them separately.\nTake time to profile your actual environment while it\u0026rsquo;s healthy so you have a baseline.\nWe cover the profiling technique earlier in Part 1 Chapter 2. Specific for Horizon, you should profile the following counters.\nObject Counters RDS Session Disk IOPS\nFrame Rate RDS Host CPU Queue\nCPU Context Switch\nMemory Page-in Rate\nDisk Queue\nDisk Outstanding IO\nRead IOPS and Write IOPS. Profile them side by side, and compare both against expectation.\nCPU Usage and Memory Usage. Compare against plan. RDS Farm Read IOPS and Write IOPS. Profile them side by side, and compare against expectation.\nCPU Usage in MHz. Make sure this number is within what the cluster can provide. Check the average does not exceed your sizing. VDI Session Same sets of metrics as RDS Host, as both are just VMs. You need to profile separately as your desktop pattern may differ to your server. VDI Pool Same sets of metrics as RDS Farm, as both are just collection of VMs. Connection Server Same sets of metrics as RDS Host. You need to profile separately as their pattern may differ. The profiling will also be useful after a major upgrade. For example:\nIf the new version is supposed to deliver 10% performance improvement, does the reality support it?\nIf the new version delivers 2x scalability but at cost of 1.5x footprint, what do you actually get in your own environment? The lab may not be identical to your real world situation. Horizon World Disk IOPS. Make sure this number is within what your storage subsystem can handle.\nNetwork Bandwidth. Make sure this number is well within what your WAN link can handle, as majority of traffic is non-protocol traffic. As part of the baselining, you will know the typical size of a session, a user, an RDS Host. They form the building block for your sizing. Compare these numbers against the numbers you put in your sizing document (during the time you architected the system). If the reality is higher, you need to revise your plan and buy additional hardware.\nRDS Session Compared with VDI Session, RDS Session has less metric as it\u0026rsquo;s not the whole VM. An RDS Session is sharing one Windows OS with many other sessions. Windows do not provide detail breakdown for each session, and mostly report the metric at Windows level.\nContention Metrics The following contention metrics are provided to troubleshoot further if the Network KPI (%) metric shows bad value.\nLatency (ms)The protocol round trip time taken between Horizon agent (on DC) and Horizon client (in end user device).\nKeep this below the best practice shown in the KPI, or your acceptable number.\nPacket Loss Receive (%)\nPacket Loss Transmit (%)\nThe guidance for overall packet loss is anything above 1% is red. So the guidance for the receive and transmit should be the same, or a bit more stringent.\nThe Agent sends pixels to the Client. If the Agent determines that it needs to drop packets due to network condition it drops them. So TX \u0026amp; RX are from the agent point of view.\nWhile the following metrics only impact at the initial stage, they are important to user experience.\nTime taken to load profileThe time starts after user has been fuly authenticated, when Windows begins the profile loading process and ends when the profile is fully loaded.\nThe guidance for performance is\nGreen = below 5 seconds\nYellow = 5 - 15 seconds\nOrange = 15 - 25 seconds\nRed = Above 25 seconds\nThe guidance is lower than VDI because RDS sessions share the same Windows. The first user logging into Windows takes the biggest performance hit because Windows has to load all GPO policies, system settings, and services that load at login. The subsequent users don't suffer the same time penalty, because those items have already been loaded. There are features like \"Session Pre-Launch\" to mask the initial login time delay\nTime taken to logonThe time starts when the user ID and password is submitted to Windows, and ends when the session is fully authenticated. It does not include the time taken to load the profile and launch start up application.\nThe guidance for performance is\nGreen = below 30 seconds\nYellow = 30 - 45 seconds\nOrange = 45 - 60 seconds\nRed = above 60 seconds\nUtilization Metrics Once you determine there is a problem, the next step is to narrow down if it\u0026rsquo;s CPU, Memory, Disk or Network\nOne common reason behind contention is high utilization. Not all usage metrics are relevant to performance, so the the following only lists the relevant ones.\nCPU Usage (%)\nMemory Usage (%)\nThese values are coming from Windows, not VM. They track the relative consumption of a session againts the RDS Host total capacity.\nMake sure this number is below than expected average. For example, if you size for 20 concurrent users, then each session should be around 5%.\nDisk IOPSUnlike a server workload, users don't generally generate high IOPS or sustained IOPS. They open file, save file, but should not be sustaining for say 1 hour.\rIf the network is over the WAN or mobile network, monitor the following metrics closely.\nFrame RateSee this for explanation. A low frame rate result in inferior user experience. While occasional low is fine, a prolonged low could lead to degraded user experienceBandwidth Utilization (Mbps)Total bandwidth, although in VDI is mostly the agent sending data. Received metric typically covers users input like typing.\nNote it's megabit, unlike kilobyte that vSphere uses. You're welcome.\nRDS Host RDS Host is a Windows Server running on a VM, serving desktop applications. In the current release of Horizon Adapter, there is no RDS application metrics yet. As a result, only Windows and Horizon metrics are used.\nAll the vSphere counters are explained in Part 2 of the book.\nContention Metrics Use the contention metrics to troubleshoot further if the DC KPI (%) metric shows bad value. Once you determine there is a problem, the next step is to narrow down if it\u0026rsquo;s CPU, Memory, Disk or Network\nThe metrics can be grouped into 2: inside Guest OS and outside.\nFor the metrics inside, a major spike at the time of the incident could be the root cause as it\u0026rsquo;s not coming from outside (e.g. shared infrastructure)\nCPU QueueHigh CPU queue is the primary counter that Windows needs more CPU. Either increase the number of vCPU or add more RDS host into the farmCPU Context Switch\nMemory Page-in Rate\nDisk Queue\nCompare them against your baseline.\nThe CPU Context Switch metric will be added in future.\nNext, check if there is a problem outside Windows, meaning at the VM or below.\nPeak vCPU ReadyUse Peak vCPU Ready instead of CPU Ready as the later is the average of all vCPUCPU Co-Stop (%)\nCPU IO Wait (%)\nCPU Overlap (ms)\nThese counters are at VM level, so they are not visible to Windows.\nTheir values should be lower than CPU Ready. Expect them to be less than 1%.\nMemory Contention (%)Keep this below 1%Worst vDisk Read Latency\nWorst vDisk Write Latency\nThese metrics are better than the average of both read \u0026amp; write. You can have one problem and not the other, and the average may mask that.\nThese metrics are better than average at VM-level.\nOutstanding IONot yet implemented. In the mean time, use super metric.\nThis is outside Windows. So if this is high, something wrong on the underlying storage system.\nFor Network, check the protocol metrics. Note they are implemented at RDS Farm level, because RDS Hosts in a farm are meant to be uniformed. Meaning you should not be changing the setting of individual host, because they come from the same master.\nProtocol Latency (ms) Protocol Packet Loss Receive (%) Protocol Packet Loss Transmit (%) Worst Time taken to logon Worst Time taken to load profile Utilization Metrics One common reason behind contention is high utilization. Not all usage metrics are relevant to performance, so the the following only lists the relevant ones.\nPeak vCPU Usage (%)Use the peak vCPU Usage instead of CPU Usage, as the later is the average of all vCPUCPU Usage (%)Note that at present this is coming from VM. In future we may change to Windows.\nIf this number hits \u0026gt;95% repeatedly, that could explain contention.\nOn the other hand, if this number is much lower than expected, there is something amiss. When you have a lot of sessions trying to connect and the RDS Host utilization is low, that means there is a bottlenect that prevents the host from processing the load.\nFree Memory (MB)Ensure this number is \u0026gt; 128 MBMemory UtilizationAs covered in Part 2, this contains buffer. In future we may change this to Windows In Use counter. Let me know your thought.\rDisk utilization is less useful in performance troubleshooting as the limit is high. A very high utilization may in fact deliver a good experience to the user, albeit at the expense of other users.\nRead IOPS\nWrite IOPS\nRead Throughput\nWrite Throughput\nIf any of these is higher than normal, investigate why. It could be security agents scanning all files.\nCompare read and write to your expectation.\nCompare IOPS and Throughput. A large increase in IOPS but not in throughput indicate the block size has increased. Is that what you're expecting?\nRDS Farm As RDS Farm is nothing but a collection of RDS Hosts + RDS Sessions, the metrics are derived from these objects. There is no raw metric at the RDS Farm itself.\nKPI Metrics As RDS Farm is a higher level objects, with potentially hundreds of members, the KPI metrics become a necessity in large scale monitoring.\nFor RDS Host, we take the worst value among the hosts as leading indicator. The reason is a farm typically consists of a dozen of so hosts, not hundreds. For RDS Session, taking the worst is good but need to be complemented with 95th percentile() or count() as there can be hundreds of sessions.\nThe following KPI metrics are provided to troubleshoot further if the Network KPI (%) and DC KPI (%) metrics shows bad value.\nWorst Network KPI among Sessions (%)\nWorst DC KPI among Hosts (%)\nThe first metric you want to see is the KPI metrics. One for DC and one for Network.\nCheck these 2 KPI metrics as they are at session level (for network) and RDS Host level (for DC). If they are not red, then the 2 metrics below will be 0.\nThe above is what you need to monitor. If the number is bad, then check the following:\nRDS Hosts with Red DC KPI\nRDS Sessions with Red Network KPI\nCheck these metrics if the above is showing red. They tell the severity of the situation by showing how many hosts are affected.95th Percentile DC KPI (%)\n95th Percentile Network KPI (%)\nIf there is no session or host in the red, it does not mean they are not in orange level. Use these metrics to check.\nNote that if there are \u0026lt; 20 hosts in a farm, the 95th percentile is basically the worst counter.\nTake note that for rolling up to Pod and World level, the 95th percentile is a more balanced than worst() formula.\nContention Metrics KPI metrics are suitable for monitoring, not troubleshooting, as it\u0026rsquo;s an aggregate of metrics. To troubleshoot, you need contention metric-type.\nIt\u0026rsquo;s easier to troubleshoot at Farm level than individual host or session, as you can see the larger picture. There is no point troubleshooting a particular host or session if the whole farm is on fire. Different hosts and sessions can have different problems, and these metrics will capture them all as it\u0026rsquo;s worst among all members.\nUse the Worst() metrics-type as they are the leading indicators. It shows the worst value among the RDS Hosts or RDS Sessions in the farm. They show the depth of a problem. If they show good value, no need to troubleshoot further as the worst is good.\nFirst, check if there is a problem inside Windows.\nWorst CPU QueueSee RDS Host for more information.Worst CPU Context Switch\nWorst Memory Page-in Rate\nWorst Disk Queue\nSee RDS Host for more information.\nThe CPU Context Switch metric will be added in future\nNext, check if there is a problem outside Windows, meaning at the VM or below.\nWorst CPU Co-stop (%)\nWorst CPU Ready (%)\nWorst Memory Contention\nWorst vDisk Read Latency\nWorst vDisk Write Latency\nSee RDS Host for more information.\rThe above is for Data Center, check if there is a problem in the network.\nWorst Protocol Latency (ms)\nWorst Protocol Received Packet Loss (%)\nWorst Protocol Transmit Packet Loss (%)\nWorst time taken to load profile\nWorst time taken to logon\nSee RDS Session for more information.\rIf the Worst() metric-type show something is wrong, then you want to know many hosts or sessions are affected. This is where the Count() metric-type come in.\nRDS Hosts with high disk latencyNumber of hosts with disk latency \u0026gt; 20 msRDS Sessions with protocol latency\nRDS Sessions with protocol receive dropped packet\nRDS Sessions with protocol transmit dropped packet\nThe threshold used is above 50 ms\nThe threshold used is above 0.5%\nThe threshold used is above 0.5%\nUtilization Metrics One common reason behind contention is high utilization. Not all usage metrics are relevant to performance, so the the following only lists the relevant ones.\nWe take the same approach we did for contention metrics, which is start with Worst() then follow by Count(). The following are the Worst() metric type:\nPeak CPU Utilization among RDS Hosts (%)\nLowest Free Memory among RDS Hosts (MB)\nSee RDS Sessions for more information\rIf the above shows something is wrong, then you want to know many hosts are affected. This is where the Count() metric-type come in.\nRDS Hosts with high CPU utilization\nRDS Hosts with low available memory\nThe threshold used is above 95%\nThe threshold used is above 500 MB\nThe problem could be caused by unbalanced among the RDS Hosts. The unbalanced metric-type shows that.\nMemory Usage Disparity among RDS Hosts (MB)\nCPU Usage Disparity among RDS Hosts (%)\nThe metrics reveal if the load is well balanced.\nNote that Load Balancer does not actually balance load. All it does is balance the number of connections. The problem is load on each session varies. Ideally, load balancer balanced on the RDS Host KPI.\nFinally, the high utilization could be caused by farm-wide spike. The average will tell us this.\nAverage CPU Usage\nAverage Memory Usage\nThese are lagging indicators, so use this as the last resort.\nIf the number is high, and the disparity is high, one of them host is likely saturated.\nMetric wise, RDS Farm differs to RDS Host as it has network metrics. As usual, check the worst first, then the average.\nLowest Frame Rate See RDS Host for more information. Average Frame Rate Is this is below 15 the user experience is affected. Average Transmit Bandwidth Average among all the sessions. We do not provide the highest among them. If you need it, let us know with the exact problem that requires you to need the information at this level. In the mean time, use super metric. Disk utilization is less useful in performance troubleshooting for the reason documented in RDS Host object.\nRead IOPS\nWrite IOPS\nRead Throughput\nWrite Throughput\nSum, not average, from all RDS hosts. See RDS Host for more information.\nMake sure this is within what your storage subsystem can handle\nVDI Session VDI Session is a VM with Horizon protocol, so the metrics are basically Windows and vSphere metrics.\nContention Metrics We included KPI (%) if you need a single metric for ease of reporting or monitoring. It\u0026rsquo;s the average of DC KPI and Network KPI as both are equally important to the user experience.\nVDI Session has the same set of contention metrics as RDS Host object \u0026amp; RDS Session object. So refer to them for the metric description.\nProtocol Latency (ms)\nProtocol Received Packet Loss (%)\nProtocol Transmit Packet Loss (%)\nSee RDS Session for more information.Time taken to logonNote login will be faster if the user is reconnecting to the same desktop (disconnect vs logoff)Time taken to load profileThe guidance for performance is\nGreen = below 30 seconds\nYellow = 30 - 45 seconds\nOrange = 45 - 60 seconds\nRed = above 60 seconds\nUtilization Metrics VDI Session has the same utilization metrics as RDS Host object, because both are VM. The difference is it has network metrics, which are covered in RDS Session object.\nVDI Pool VDI Pool sports the same set of KPI metrics that RDS Farm has. The only difference is it uses VDI Session as the base object, reflecting the fact that a pool is nothing but a collection of VDI VMs.\nRefer to the RDS Farm metric for the explanation. In summary, the metrics are:\nLowest Network KPI among VDI Sessions (%)\nWorst DC KPI among VDI Sessions (%)\nVDI Sessions with Red DC KPI\nVDI Sessions with Red Network KPI\n95th Percentile DC KPI (%)\n95th Percentile Network KPI (%)\nContention Metrics As per RDS Farm, we begin with checking inside Windows.\nWorst CPU QueueThe highest CPU Queue among the VDI Sessions. If this is high then look inside Windows. To reduce this you need to increase the number of vCPU, or move the user to a pool with bigger VM.Worst CPU Context Switch\nWorst Memory Page-in Rate\nWorst Disk Queue\nSee RDS Farm for more information\rIf the above shows something is wrong, then you want to know many VDI Sessions are affected. This is where the Count() metric-type come in\nVDI Sessions with CPU Queue\nVDI Sessions with Disk Queue\nThe threshold used Above 2.\nThe threshold used Above 10 in Windows\nNext, check if there is a problem outside Windows, meaning at the VM or below. Check for both DC and Network\nWorst CPU Co-stop (%)\nWorst CPU Ready (%)\nWorst Memory Contention\nSee RDS Farm for more informationWorst vDisk LatencyWorst vDisk Read Latency\nWorst vDisk Write Latency\nNote these metrics do not exist yet for VDI Pool. In the mean time, use super metric.Worst Protocol Latency (ms)\nWorst Protocol Received Packet Loss (%)\nWorst Protocol Transmit Packet Loss (%)\nWorst time taken to load profile\nWorst time taken to logon\nSee RDS Session for more information\rIf there is a problem, check how broad the problem is.\nVDI Sessions with CPU Ready\nVDI Sessions with Memory Contention\nVDI Sessions with high Disk Latency\nVDI Sessions with protocol latency\nVDI Sessions with protocol receive dropped packet\nVDI Sessions with protocol transmit dropped packet\nThe threshold used is above 2.5%\nThe threshold used is above 1%\nThe threshold used is above 20 ms\nThe threshold used is above 50 ms\nThe threshold used is above 0.5%\nThe threshold used is above 0.5%\nUtilization Metrics One common reason behind contention is high utilization. Not all usage metrics are relevant to performance, so the the following only lists the relevant ones.\nPeak CPU Utilization among VDI Sessions (%)Note this metric is yet to be implemented.\nIf this metric hits \u0026gt;95%, one or more users could be needing more CPU, and perhaps should be migrated to VDI Pool with larger VM.\nLowest Free Memory among VDI Sessions (MB)If this metric hits \u0026lt;1200 MB, one or more users could be needing more memory, and perhaps should be migrated to VDI Pool with larger VM.\rIf the above shows something is wrong, then you want to know many hosts are affected. This is where the Count() metric-type come in.\nVDI Sessions with high CPU utilization\nVDI Sessions with low available memory\nThe threshold used is above 95%\nThe threshold used is above 500 MB\nFor the network metrics, see RDS Farm.\nDisk utilization is less useful for the reason explained in RDS Farm.\nNote that the metrics Average CPU Usage and Average Memory Usage are intentionally not provided as they serve neither performance management nor capacity management.\nThe disparity metrics are not applicable as there are bounds to be disparity among users.\nHorizon Pod Now that we have the KPIs for all key objects, we can roll up. A pod is simply a group of VDI Pool and/or RDS Farm. It has Connection Servers but they are not in the data path once user is authenticated.\nKPI Metrics 95th Percentile Network KPI (%)\n95th Percentile DC KPI (%)\nThe primary metrics.\nBased on all the RDS Farms and VDI Pools in the Pod\nIf the above is bad, then you dive into the individual farm or pool. If you want to see how bad the situation, use the following\nFarms or Pools with Red DC KPI\nFarms or Pools with Red Network KPI\nAim for this number to be 0 as the farm KPI or pool KPI is the average of all their members. It's a lagging indicator.Network KPI (%)\nDC KPI (%)\nWhile it's a lagging indicators, it gives the full picture.\rSince Pod contain Horizon servers, we add 95th Percentile Connection Servers DC KPI (%) metric to help in monitoring. From here, you dive into the individual servers.\nContention Metrics Horizon Pod is too large an object to perform troubleshooting. You need to zoom into a specific farm or pool.\nAt the pod level, the following is provided as the number of data points is a lot less.\nWorst time taken to load profile\nWorst time taken to logon\nWe use the worst instead of 95th percentile as it's an event, not metric. It does not happen every 5 minutes so the number of data points is a lot less.\rIf you have a problem that impacts the entire pod, check at vSphere clusters and DC level as it could be something common.\nUtilization Metrics One common reason behind contention is high utilization. As Pod is a large object, its utilization can potentially exceed what the infrastructure is able to deliver. Start with the total utilization:\nCPU UtilizationMemory is not included as it's actually disk space. Disk space impact capacity, not performance. Memory usage matters in resource provider, such as ESXi.Disk IOPS\nDisk Throughput\nIf the number is higher than what you expect, then drill down to read and write.\rThe problem could also be caused by high utilization within the VDI VM or RDS Host. You did profile your environment, didn\u0026rsquo;t you?\nSince Pod contain Horizon servers, we add the following metric to help in monitoring. From here, you dive into the individual servers.\nCPU Usage per Connection Server\nMemory Usage per Connection Server\nHorizon World We do not aggregate at Horizon Site and Horizon CPA level to minimize footprint of vRealize Operations. If you have the need, let us know with the specific example. In the mean time, use super metric.\nSimilar to a Pod, start with the main KPI metric, and then you dive into a pod, and then into a farm or pool. You do not do troubleshooting at World or Site level.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-6---automation/4.6.4-closing-the-loop/",
      "title": "4. Closing the Loop",
      "tags": [],
      "description": "",
      "content": "Now with the ability to connect back to vRealize Operations to either retrieve data or push custom information, we can finally close the loop to achieve a fully featured closed-control loop. The next picture represents our closed-loop control system including all concepts we have learned in the previous sections of this chapter.\nIf you compare the next picture to figure 16, you will notice that now we have a continuous and closed-loop between the entity executing our automated actions and the entity collecting the data which reflect the behavior of objects we control. We are no longer limited to the \u0026ldquo;fire and forget, until the sensors do something\u0026rdquo; method. With the possibility to execute callbacks to the REST API, vRealize Operations becomes an integral part of an automated SDDC solution.\nLet us now come back to our initial use case: \u0026ldquo;If a VM (the OS) crashes, this VM should be hard-reset\u0026rdquo;. How could we expand that use case and have a sophisticated and automated remediation using all the concepts I have presented in this chapter. We will examine the next picture and extract the possible components of the automation.\nThe central control point is of course vRealize Operation itself.\nThe vCenter Adapter instance is continuously collecting metrics which describes the current behavior of our SDDC, including the behavior of our VMs. Within vRealize Operations we have an Alert Definition that utilizes certain symptoms to fire an alarm when the symptoms indicate that something is wrong, in our use case a VM probably crashed. \u0026ldquo;Probably\u0026rdquo; because we are evaluating symptoms, and symptoms do not necessarily point directly to a root cause. As soon as the alarm has been raised, the configured Notification: Creates a problem ticket in ServiceNow Sends a notification email to the admin team At the same time, the Action configured within the Recommendation starts a vRealize Orchestrator Workflow. The workflow itself may (this is just an example): Tries to connect to the VM via RDP or SSH Executes ping or TCP connect checks Reset the VM if the configured checks underpin the initial assumption Checks the availability of the VM Checks the alert status in vRealize Operations and updates it if required Push additional properties (like e.g., count of vRealize Orchestrator initiated rest events) to the VM object As soon as the alarm status changes, the configured Notification: Updates the problem ticket in ServiceNow Sends another notification email to the admin team With vRealize Operations, its comprehensive REST API, the wide range of Management Packs, integrated Notification Plugins and the capability to run Actions using vRealize Orchestrator you have wide possibilities to automate your SDDC management and level it up to become Self-Driving SDDC.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-4---super-metrics/4.4.4-advanced-examples/",
      "title": "4. Advanced Examples",
      "tags": [],
      "description": "",
      "content": "This is where you vrealize the full capability of super metric. It\u0026rsquo;s actually a programming language that gets executed as a straight line. That means it can\u0026rsquo;t loop.\nTools Status Use Case: check the VM Tools running status. If it is running, return the value of OS uptime, else return the value zero.\nIn this example, we\u0026rsquo;re combining where clause and If Then Else.\ncount( ${this, metric=summary|guest|toolsRunningStatus, where= (!($value contains \u0026#39;Not Running\u0026#39;))}) != 0 ? ( ${this, metric=sys|osUptime_latest} ) : 0 Weighted KPI Use Case: transform raw value into KPI\nRecall in the KPI that you typically have metrics with different units and range. To combine them into a single metric, you need to convert them into the same unit-less range.\nLet\u0026rsquo;s say you have the following metrics that you want to combine into a single KPI\nFor each metric, you have established the range for each color.\nTake IO Wait for example. The green range is only from 0% - 1%, where 0% IO Wait equals to 100%, while 1% IO Wait becomes 75%. That means 0.8% IO Wait is 80%. The yellow range is wider, so 2% IO Wait gets translated into 62.5% as it\u0026rsquo;s in between 50% and 75%.\nSuper metric does not have a Case statement, so we have to use nested IF. The logic looks something like this\nIf it\u0026#39;s in the green range then calculate for green range else if it\u0026#39;s in the yellow range then calculate for yellow range else if in the orange range then calculate for orange range else calculate for red range In addition to the above, you can also assign weightage. This is critical if you have many metrics forming a KPI. for example, if there are 10 metrics, then a single red will not have enough weight to change the overall KPI red. To solve this, you assign higher weightage to red. A good technique is to give yellow 2x the weight of green, orange 2x the weight of yellow, and red 2x the weight of orange. All else being equal, a red has 8x more weight than green.\nThe code in red show how the weigtage being applied.\n${this, metric=cpu|iowaitAvg} as ioWait == 0 ? 100 : ( ioWait \u0026lt; 1 ? ( ioWait - 0) / (1 - 0) * 25 + 75 : ( ioWait \u0026lt; 3 ? ( (ioWait - 1) / (3 - 1) * 25 + 50 ) * 2 : ( ioWait \u0026lt; 5 ? ( (ioWait - 3) / (5 - 3) * 25 + 25 ) * 4 : ( min ( [ (ioWait - 5 ), 2 ] ) / (7 - 5) * 25 ) * 8 ) ) ) The above code has extra logic to handle corner cases at the edge of the spectrum. The first corner case is IO Wait = 0%, which must be translated as 100%. The other corner case is where IO Wait exceed the red range, in which case it must be translated at 0% instead of going negative.\nCan you spot a missing logic in the above?\nYes, the multiplier creates a problem. When you multiply by 2x, 4x, 8x, you need to normalize it back to the values fall within 0 - 100%.\nBut how do you normalize, since each metric can have their own multiplier?\nYou need to have another set of nested IF statement, this time you increase the denominator correspondingly. The following shows the logic for 2 of the metrics. The multiplier is shown in red.\nSum ([ ( ioWait \u0026lt; 1 ? 1 : ( ioWait \u0026lt; 3 ? 2 : ( ioWait \u0026lt; 5 ? 4 : 8 ) ) ) , ( coStop \u0026lt; 1 ? 1 : ( coStop \u0026lt; 2 ? 2 : ( coStop \u0026lt; 3 ? 4 : 8 ) ) ) ]) Once you have the above 2 sets, it\u0026rsquo;s a matter of dividing one over the other. The following shows part of the logic, as I want to focus on the 2 sum statements.\nPretty cool isn\u0026rsquo;t it? If you agree, send your thanks to Gautam Kumar and Artavazd Amirkhanyan.\nVM Uptime Use Case: calculate the VM uptime within the 5-minute collection cycle.\nThis particular super metric wasn\u0026rsquo;t fully implemented in the product due to the false positive from the raw vCenter counter that was discovered during validation. So I\u0026rsquo;m providing as an example of what you can do with super metric.\nThe up time of a VM is more complex than that of a physical machine. Just because the VM is powered on, does not mean the Guest OS is up and running. The VM could be stuck at BIOS, Windows hits BSOD or Guest OS simply hang. This means we need to check the Guest OS. If we have VMware Tools, we can check for heartbeat. But what if VMware Tools is not running or not even installed? Then we need to check for sign of life. Does the VM generate network packets, issue disk IOPS, consume RAM?\nAnother challenge is the frequency of reporting. If you report every 5 minutes, what if the VM was rebooted within that 5 minutes, and it comes back up before the 5th minute ends? You will miss that fact that it was down within that 5 minutes!\nFrom the above, we can build a logic:\nIf VM Powered Off then Return 0. VM is definitely down.\nElse Calculate up time within the 300 seconds period.\nIn the above logic, to calculate the up time, we need first to decide if the Guest OS is indeed up, since the VM is powered on.\nWe can deduce that Guest OS is up is it\u0026rsquo;s showing any sign of life. We can take Heartbeat from Tools. What if there no Tools or Tools not returning heartbeat? We need to have fail back plan. So we check memory usage, network usage and Disk IOPS.\nCan you guess why we can\u0026rsquo;t use CPU Usage?\nVM does generate CPU even though it\u0026rsquo;s stuck at BIOS. We need a counter that shows 0, and not a very low number. An idle VM is up, not down.\nSo we need to know if the Guest OS is up or down. We are expecting binary, 1 or 0. Can you see the challenge here?\nYes, none of the counters above is giving you binary. Disk IOPS for example, can vary from 0.01 to 10000. The \u0026ldquo;sign of life\u0026rdquo; is not coming as binary.\nWe need to convert them into 0 or 1. 0 is the easy part, as they will be 0 if they are down.\nI\u0026rsquo;d take Network Usage as example.\nWhat if Network Usage is \u0026gt;1? We can use Min (Network Usage, 1) to return 1. What if Network Usage is \u0026lt;1? We can use Round up (Network Usage, 1) to return 1. So we can combine the above formula to get us 0 or 1.\nThe last part is to account for partial up time, when the VM was rebooted within the 300 seconds sampling period. The good thing is vR Ops tracks the OS up time every second. So every 5 minute, the value goes up by 300 seconds. As VM normally runs \u0026gt;5 minutes, you end up with a very large number. Our formula becomes:\nIf the up time is \u0026gt;300 seconds then return 300 else return it as it is.\nLet\u0026rsquo;s now put the formula together. Here is the logical formula:\nCan you write the above formula differently? Yes, you can use If Then Else. I do not use it as it makes the formula harder to read. It\u0026rsquo;s also more resource intensive.\nLet\u0026rsquo;s translate the above into a pseudcode.\nLastly, here is what it looks like in actual code. I\u0026rsquo;ve optimized the last bit to /3. No point multiply by 100 then divide by 300.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-9---other-dashboards/3.9.4-role-based-dashboard/",
      "title": "4. Role-Based Dashboard",
      "tags": [],
      "description": "",
      "content": "Storage Team Ask any Storage Team and Platform Team whether the collaboration between them can be improved by a mile, and you are likely to get a nod. One reason for this issue is there is lack of common visibility. You need to see the same thing if you want to collaborate. Storage Team do not get always get access vSphere. Even if they do, vCenter UI is not designed for Storage team. It is designed for VMware Admin.\nvRealize Operations and Log Insight can bridge that providing a set of read-only, purpose-built dashboards, that answer common questions such as:\nWhen a VM Owner complains, can we agree if it\u0026rsquo;s a storage issue within 1 minute? This will help reducing the ping pong game between VM Owner, vSphere Admin, and Storage Admin.\nIs the Storage serving all the VMs well? If not, who are affected, when and how bad? Read or Write? The answer has to be tier based, as Tier 1 VM expects lower latency than Tier 3.\nWhat\u0026rsquo;s the total demand hitting the array? Are they growing fast and becoming a risk? Who are the heavy hitters among the VMs?\nWhen \u0026amp; where are we running out of capacity? How much disk space can be reclaimed? From which VMs?\nWhat have we got? Are they consistently configured?\nThe questions above cover the main areas of SDDC Operations, such as performance, capacity, configuration and availability. They enable joint troubleshooting, capacity planning, performance monitoring. For better collaboration, add physical array monitoring into vRealize Operations and Log Insight, so you can analyze physical arrays and fabrics, and then correlate back with vSphere.\nThe dashboards should provide overall visibility to Storage team. They give insight into the SDDC by showing relevant objects by:\nquickly showing the summary of key information.\nshowing VM, datastore, datastore clusters, compute cluster, and data center. It shows their relationship, which you can interact and drill down.\nshowing all the VMs, where they are located, how much space they are allocated, and how they are using it.\nShowing physical arrays inventory and how they map into vSphere.\nNetwork Team Similar to the problem face between Storage Team and Platform Team, VMware Admin needs to reach out to Network Team. A set of purpose-built dashboards will enable both teams to look at issue from the same point of view.\nThe world of network is highly complex, given its nature as interconnect.\nThe dashboards must answer the following basic questions for Network Team:\nWhat have I got in this virtual environment? What is the virtual network configuration? What are the networks, and how big are they? We have Distributed Virtual Switches, Distributed Port Group, Data center, Cluster, ESXi, etc. How are they related? Distributed Switch does not span beyond vSphere Data Center. So data center is a logical choice to start analysing the relationship. Who are the consumers of my network? Where are they located? Are they healthy? Do we have any errors in our networks? Which port groups see packets dropped? If there is problem, which VMs or ESXi, are affected? Do we have too many special packets? Broadcast, multicast and unknown packets. Who generates them and when? The two primary counters are bandwidth and latency. Bruce Davie explains both in this book1, specifically this page, that the two counters work together. The reason is some applications are latency sensitive, while others are bandwidth hungry. Are they optimized? Just because something is healthy does not mean they are optimized. Look for opportunity to right size. Once Network Admin know what they are facing, they are in better position to analyze:\nUtilization Is any VM or ESXi near its peak in network? Which VXLAN is the busiest? Who are the top consumer for each physical data center? What\u0026rsquo;s their workload pattern? How is the workload distributed in this shared environment? Performance When VM Owner thinks Network is the culprit, can both Network Team and Platform verify that quickly? Configuration Is the configuration consistent across objects of the same kind? Do they follow best practice? What are the virtual networks, and how do they map into the physical top-of-rack switches? Application Team A common request among VMware Admin is to give their customers a self-service access to their own VMs. The VM Owners should be given a simple portal, where they can easily see all their VMs and its performance. You can use the dashboard sharing feature of vRealize Operations for a login-less access.\nBut what if you have many tenants? You don\u0026rsquo;t want to create a dashboard for each of them one by one. The challenge here is how to use the same dashboard for multiple applications teams, assuming they are not allowed to see one another VMs. This requires a security mapping. Each tenant needs to have a login ID, which must be mapped to their VM.\nRole The first step is to create a role and give it limited access. All tenants user accounts will be mapped to this role. This role should not be able to browse the inventory. Its only access is to the group of tenants. Dashboard Create a common dashboard and map to the role. This role can\u0026rsquo;t see any other dashboards Tenant For each tenant, you need to create a user ID. This ID is then mapped to a group. The group has the tenant VMs. In this way, the tenant ID will not be able to see other VMs. Small Team The Small Medium Business segment is a world of its own. There are roles and process that are mandatory in Enterprise segment, but not relevant in SMB segment. As a result, products should be tailored for that market segment. You can create a set of consolidated dashboards for this market, as the environment is much smaller.\nLet\u0026rsquo;s look at some unique characteristics of operations in this small environment:\n1-2 team members doing everything. No siloes in the team. You and your best friends take care of the whole darn IT. You only have a few clusters. Each cluster only has a few ESXi Host. You know your environment very well because it\u0026rsquo;s small. They all fit into 1 rack. Architecture is simple. You have a mental picture of it in your head. You don\u0026rsquo;t buy hardware or VMware every quarter. In fact, it\u0026rsquo;s more like every 3 years. Capacity planning and monitoring become simple as you can do it manually using a simple spreadsheet. The workload is quite stable. You are not adding/removing/changing VM every day. Service Tier is an overkill as you only have 1-2 clusters for all workloads. You still need to cover all the key areas of operations, from availability to performance to compliance. As self-service is expected, you need to provide a dashboard for application team.\nThe book is freely available, and that\u0026rsquo;s part of the reason why I decided to make mine free.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-6---noc-dashboards/3.6.4-live-heavy-hitter-dashboard/",
      "title": "4. Live! Heavy Hitter Dashboard",
      "tags": [],
      "description": "",
      "content": "This dashboard helps you analyze the misuse of the shared infrastructure. This dashboard displays details of VMs misusing the shared infrastructure and if that has caused performance problems to the other VMs. The cause for excessive load might be due to security attacks, for example, denial of service, process runaway, or mass activation of agents.\nDesign Consideration See the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nIn shared environment, it is possible to have victim-villain problem. In the heat map, the villain VM is the one with the largest box size, while the victim is the one with red box. If a handful of VMs are dominating the shared infrastructure, their collective size will be highly visible on the dashboard.\nThere are 4 areas where a monster VM can impact its neighbours.\nCPU. Disk IOPS. Any VM with PVSCSI can generate very high IOPS. Since this hits the underlying physical storage, the view is grouped by Data center, not Datastore or Cluster. Disk Throughput. Apps with large block size (e.g. 4 MB) can consume bandwidth without generating high IOPS Network. Memory is not needed as it\u0026rsquo;s rare for Guest OS to actively read/write from DIMM. It\u0026rsquo;s mostly cache. Think of it like disk space (passive).\nRemediation Action you should take: Check why the VMs are generating excessive load.\nHow to Use There are 4 heat maps, showing the 4 different loads that can be excessive. The heat map displays the relative value and not the absolute value. A VM does not generate a high load in the absolute term just because it has large configuration.\nEach heat map has their own color threshold, reflecting the nature of the contention metrics used in each of them.\nFor NOC Operator, drill down by selecting one of the VM on the heat map\nAll the 4 line charts are automatically showing, enabling you to get a more complete picture of the selected VM.\nPoints to Note Memory is not shown as it\u0026rsquo;s a form of storage. The memory counters are space utilization, not speed. Think of disk space instead of IOPS. It can cause capacity problem on the shared ESXi host, but not performance problem to other VMs. In a large environment, it might be difficult to view a small victim VM. Consider having multiple dashboards and rotate among them. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.4-esxi-configuration/",
      "title": "4. ESXi Configuration",
      "tags": [],
      "description": "",
      "content": "Use this dashboard to view the overall configuration of ESXi Hosts in your environment, especially the configuration that need attention.\nThe dashboard is designed with the same considerations that are common among all the configuration management dashboards.\nHow to Use The dashboard is organized into sections for ease of use.\nThe upper part of the dashboard displays basic ESXi configurations that should be standardized for ease of operations.\nThere are six pie-charts that are displayed as one set because there is a relationship in their values. There should be a correlation between them. Ideally, the ESXi version, the ESXi build, and the BIOS should be identical across all ESXi hosts in a cluster\u0026quot;. Keep the variations of hardware model, NIC speed, and storage path minimal. The more complex the pie chart, the more variants you have. This results in complex operations, potentially resulting in increased OPEX. The configurations should reflect your current architecture standard. Each pie-chart counts the occurrence of a particular value. A large slice signifies that the value is the most common value, and if that is not your current standard, then you must address it. The second section of the dashboard displays configurations that are potentially suboptimal.\nThe three bar-charts display various size dimensions of the ESXi hosts. The bar-charts are designed to be seen as one set. Ensure minimal number of variations to reduce complexity. Smaller ESXi hosts have a relatively higher overhead, and are limited in running larger VMs. If they have a low core count, they could be using outdated CPU. Small ESXi hosts are more expensive on a per core, per GB, per rack unit basis than larger ones if they occupy the same space. On the other hand, a 4-CPU socket ESXi host is likely to be too large, resulting in a concentration risk (too many VMs in a single ESXi host). Maintain a good balance that balance your budget and risk constraints . You should adjust the distribution chart bucket size to fit your environment. The third section of the dashboard displays configurations that you may want to avoid.\nThe six bar-charts focus on security, availability, and capacity settings that you can set as a standard. For example, you should consider enabling the NTP daemon for consistent time, which is critical for logging and troubleshooting. The three tables list the actual ESXi hosts that are in a non-productive state. They can be in maintenance mode, powered off, or in a disconnected state. BTW, I\u0026rsquo;ve modified the last one to show information, to show an example if that makes sense for your operations. I do not do it for the out of the box version as visually it will look awkward as the first 5 charts do not need it. The last part displays all the ESXi hosts in your environment.\nYou can sort the columns and export the result into spreadsheet for further analysis. Some of the columns are color coded to facilitate quick reviews. Adjust their threshold to either reflect your current situation or your desired ideal state Points to Note The number of buckets on the pie chart or bar chart are balanced between the available screen estate, ease of use and functionality. Modify the buckets to either reflect your current situation or your desired ideal state. In a large environment, create a filter for this dashboard. Group by the class of services such as, Gold, silver, and bronze. Default the selection to Gold. In this way, your monitoring is not cluttered with less critical workloads. For a more complete visibility, consider adding physical server monitoring by using the appropriate management pack. More info here. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/3.3.4-datastore-capacity/",
      "title": "4. Datastore Capacity",
      "tags": [],
      "description": "",
      "content": "The Datastore Capacity dashboard is designed for Capacity Team, not day to day Operations team. It provides long term and top down view, enabling the capacity team to better plan future expansion and ageing hardware technological refresh. This dashboard is designed for both VMware administrator and Storage administrator, with the goal of fostering closer collaboration between the 2 team.\nDesign Consideration See the Capacity Dashboards page for common design consideration among all the dashboards for capacity management.\nThis dashboard complements out of the box pages by highlighting the datastores that need attention. It shows 2 distribution charts, grouping datastores with capacity remaining and time remaining.\nLocal Datastores are shown separately as a table on its own, at the end of this dashboard. Avoid running VMs on local datastores, unless its storage requirements can be met with a local disk.\nHow to Use The dashboard is layered, gradually providing details as you work top down in the dashboard.\nThe first layer shows 2 distribution charts\nBar charts summarize the datastores based on capacity remaining and time remaining. Just because you are running low on capacity does not mean you are running out of time. The two bar charts work together. The ideal situation is low Capacity Remaining and high Time Remaining. This means your resources are cost effective and working as expected. The second layer shows a heat map\nThere are three heat maps, the primary being Remaining Capacity heat map. The 2 other heat maps cover Used Capacity. One of them is designed for environment that use Datastore Clusters Each box represents a datastore. If you have many datastores, the heat map will group them. You can drill down to see its members. The larger the datastore, the larger its box is. If you have many small datastores, consolidation can make operations easier. The color indicates usage. Low utilization is marked as grey, not green, as it represents waste. )\nReview the Shared Datastores table\nThe table provides a summary, showing all datastores a glance. They are grouped by Data center. If you use Datastore Cluster as your standard, replace the grouping with it. Here are some of the things you can do: Sort by any column. You can quickly see which datastores are running out of capacity, Filter to a specific vCenter, or even Data center. This is handy in large environment. The table is sorted by the least capacity remaining. Select a datastore from the table\nThe remaining widgets will automatically show the capacity details of the selected datastore For disk space, the total capacity, allocated and actual used are shown. Compare the total capacity vs provisioned vs used. If allocated space grow but actual do not, that could mean the VMs are yet to use it. Watch out, you can run out of space sooner than expected. There are three reclamation opportunities: powered off VM, snapshot, and orphaned VMDK. The snapshot must be 0 GB. If it is not 0, then it should be temporary. A snapshot lasting beyond a day must be investigated. Orphaned VMDK are the ones that are not associated to any VM. The orphaned VMDK must be 0. Points to Note If you are using \u0026ldquo;thin on thin\u0026rdquo;, meaning the underlying LUN is also thin provisioned, add visibility into the physical array.\nThe dashboard does not have datastore clusters. If your environment use it, modify this dashboard or create a new one. In a large environment with many datastores and datastore clusters, add a View List to list the datastore clusters so you get summary information. From this list, drives the datastore view list. Alternatively, create a heat map, listing the datastore clusters.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.4-esxi-contention/",
      "title": "4. ESXi Contention",
      "tags": [],
      "description": "",
      "content": "The ESXi Contention Dashboard is the primary dashboard for ESXi host performance. It\u0026rsquo;s designed for VMware Administrators or Architects, and can be used in both monitoring and troubleshooting. Once you determine there is performance issue, use the ESXi Utilization dashboard to see if the contention is caused by very high utilization.\nDesign Consideration The dashboard is designed to complement the Cluster Contention dashboard by providing the next level of details. Hence it has a very similar layout.\nIt is also designed to complement the vSAN Contention dashboard. In vSAN, the ESXi where the VM is running is potentially not where the file blocks are residing. So there are Compute Host and Storage Hosts. There are a few Storage Hosts, depending on the vSAN FTT setting. This relationship is not shown in the UI.\nThis dashboard is designed to be used as part of your Standard Operating Procedure (SOP). It is designed to be used daily, hence the views are set to show data in the last 24 hours. The dashboard provides performance metrics for VMs in the selected data center.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nThis dashboard is required for environment with standalone ESXi host (not part of a cluster).\nHow to use Review the 2 distribution charts. They give an overview of all the ESXi Hosts utilization and memory performance.\nBoth charts are using the percentage of VM facing performance counter, and not the worst performance among VM counter. The reason is you are looking at ESXi performance, and not a single VM performance. So you want to see how it handles all the VMs.\nThe bar chart is color coded. You want to keep the percentage of VM population not being served as low as possible. Your tolerance level depends on the criticality of the environment.\nReview the ESXi Hosts Performance table\nIt lists all the ESXi hosts, sorted by the worst performance in the last 24 hours. If the table is all showing green, then there is no need to analyze further. The reason 24 hours is chosen instead of 1 week is the performance \u0026gt; 24 hours are likely to be irrelevant. You can change the time period to the period of your interest. The maximum number will be reflected accordingly. Select an ESXi Host from the table\nAll the health charts will automatically show the KPI of selected cluster. For performance, it\u0026rsquo;s important to show both depth and breadth of performance problem. A problem that impacts 1-2 VM requires a different troubleshooting that a problem that impacts all VMs in the cluster. Worst CPU Overlap among VM in the host is included as it indicates a lot of interrupts. A running VM was interrupted because VMkernel needs the physical core to run something else. A high and frequent number of interruptions is not healthy. This can also impact the VM performance. Expect the network error 1% and dropped packet to be 0 most of the times, if not always. If it\u0026rsquo;s not, analyze to see if there is any patterns across all ESXi Hosts, and bring it up to your network team. Points to Note Consider adding a 3rd distribution chart if you have the screen real estate. Show the CPU Co-Stop counter in this 3rd chart, as it complements the CPU Ready counter. If your environment has relatively slow network and storage IO, you can add VM Wait too. Unlike the Cluster Performance dashboard, there is no average ESXi Hosts Performance (%) at vSphere World level. The reason is most ESXi Hosts are part of cluster and monitoring should be done at cluster level. Certain settings such as power management and hyper threading can impact performance. Consider adding a property widget to show relevant property of a selected ESXi Host. If you use VMFS datastores, add the disk contention metrics such as Bus Reset and Aborted Commands. You should expect they return 0 at all times. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.4-dashboard-to-dashboard-navigation/",
      "title": "4. Dashboard to Dashboard Navigation",
      "tags": [],
      "description": "",
      "content": "Avoid designing a deep dashboard with many widgets that requires multiple pages of scrolling. They are harder to understand and may suffer from loading time. Instead, take advantage of the dashboard to dashboard navigation feature, which was enhanced in vRealize Operations 8.2. You can drill down from one dashboard to another, or move laterally. Note that you cannot go up the parent hierarchy.\nThe following is an example. There is an overall performance dashboard, which drills down into capacity dashboards and performance dashboards. The grey arrows indicate a drill down. The blue lines indicate a lateral movement, hence it is bidirectional.\nOnce you design the overall flow, you implement it on each dashboard. Here is an example, where this dashboard drills down into two other dashboards (ESXi Contention and VM Contention).\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-6---other-metrics/2.6.4-vmware-tools/",
      "title": "4. VMware Tools",
      "tags": [],
      "description": "",
      "content": "The following table explains the meaning of the value of Tools status property\nValue Description Guest Tools Not Installed Tools are not installed on the VM. You should install it as you get both drivers and visibility Current Tools version matches with the Tools available with ESXi. Each ESXi has a version of Tools that comes with it. See this for the list. This is the ideal scenario Supported New Newer than the ESXi VMware tools version, but it is supported Supported Old The opposite of New. It is also supported. Even it is older by 0.0.1 is considered old. It does not have to far behind Too Old Tools version is older than the minimum supported version of Tools across all ESXi versions. Minimum supported version is the oldest version of Tools we support. Basically, guest is running unsupported Tools. You should upgrade. As of now for Linux and Windows guests. minimum supported version is the Tools version bundled with ESXi 4.0 which is 8.0.1. Supporting such old versions is challenging. We are planning to change this in future to something newer. In the meantime, you should upgrade as might not work as expected Unmanaged Tools installed in the guest did not come from ESXi, so Tools is not being managed by ESXi host. It may be supported or maybe not, depends on what type of Tools is running in the guest. We support open-vm-tools packaged by Linux vendors and OSPs, which both show up as unmanaged.\nIf a customer builds their own open-vm-tools from source code, we may not support that because we will not know if they have done it correctly or not I covered the various counters used by Tools in their respective section. The following table provides a summary with their key and formula. Not all counters are exposed by Tools and vRealize Operations.\nIf you notice a rare intermittent collection, check vmware.log of the VM. It could be that vmtoolsd daemon in Guest OS paused for a while, due to guest workload or other issue in Windows or Linux.\nLinux Memory Metrics Stat NameSourceUnitguest.contextSwapRate\"ctxt\" from /proc/statNumber/secguest.mem.activeFileCache\"Active(file)\" from /proc/meminfoKBguest.mem.free\"MemFree\" from /proc/meminfoKBguest.mem.physUsableSum of /proc/zoneinfo#present across all zones. Equals to VM configured RAM.KBguest.mem.needed\"guest.mem.physUsable\" - max(0, \"MemAvailable\" from /proc/meminfo - 5% of \"guest.mem.physUsable\")KBguest.page.inRate\"pgpgin\" from /proc/vmstat\nThe rate of reads going through the underlying paging/cache system. It includes not just swapfile I/O, but cacheable reads as well.\nI think Tools take the last value, and not the average over the last collection period. Meaning if Tools collect every 60 seconds, it takes 1 value at 60th second, not the average of 60 values in the entire 60 seconds.\nPages/secguest.page.outRate\"pgpgout\" from /proc/vmstat\nThe rate of writes going through the underlying paging/cache system. It includes not just swapfile I/O, but cacheable writes as well.\nPages/secguest.swap.spaceRemaining\"SwapFree\" from /proc/meminfo\nThe amount of swap space remaining, taking into account the possibility of swapfile growth where possible. If the OS is configured without a swapfile, this will return zero.\nKBguest.page.sizesysconf(_SC_PAGESIZE)Bytesguest.hugePage.size\"Hugepagesize\" from /proc/meminfoKBguest.hugePage.total\"HugePages_Total\" from /proc/meminfo\nTotal large pages allocated\nLarge page countguest.mem.neededReservation5% of \"guest.mem.physUsable\"KBguest.mem.available\"MemAvailable\" from /proc/meminfoKBguest.mem.slabReclaim\"SReclaimable\" from /proc/meminfoKBguest.mem.buffers\"Buffers\" from /proc/meminfoKBguest.mem.cached\"Cached\" from /proc/meminfoKBguest.mem.total\"MemTotal\" from /proc/meminfoKB\rThe above mapping and calculation are based on latest Linux document and source code. As older Linux has used different formula, the future may change.\nWindows Memory Metrics Stat NameSourceguest.contextSwapRateWin32_PerfFormattedData_PerfOS_System = @#ContextSwitchesPersec from WMIguest.mem.activeFileCacheWin32_PerfRawData_PerfOS_Memory = @#SystemCacheResidentBytes from WMIguest.mem.freeWin32_PerfRawData_PerfOS_Memory = @#FreeAndZeroPageListBytes from WMIguest.mem.physUsableWin32_OperatingSystem = #TotalVisibleMemorySize from WMIguest.mem.neededguest.mem.physUsable - max(0, UNNEEDED_BYTES - 5% of guest.mem.physUsable),\nwhere UNNEEDED_BYTES = \"Win32_PerfRawData_PerfOS_Memory =@#FreeAndZeroPageListBytes\" + \"Win32_PerfRawData_PerfOS_Memory =@#StandbyCacheReserveBytes\"\nguest.page.inRateWin32_PerfFormattedData_PerfOS_Memory = @#PagesInputPersec from WMIguest.page.outRateWin32_PerfFormattedData_PerfOS_Memory = @#PagesOutputPersec from WMIguest.swap.spaceRemaining(maximum possible - used) swap spaceguest.page.sizeSYSTEM_INFO.dwPageSize returned by GetSystemInfo()guest.hugePage.sizeGetLargePageMinimum()guest.mem.neededReservation5% of \"guest.mem.physUsable\"guest.mem.availableToMmWin32_PerfRawData_PerfOS_Memory = @#AvailableBytes from WMIguest.mem.standby.normalWin32_PerfRawData_PerfOS_Memory = @#StandbyCacheNormalPriorityBytes from WMIguest.mem.standby.reserveWin32_PerfRawData_PerfOS_Memory = @#StandbyCacheReserveBytes from WMIguest.mem.standby.coreWin32_PerfRawData_PerfOS_Memory = @#StandbyCacheCoreBytes from WMIguest.mem.modifiedPagesWin32_PerfRawData_PerfOS_Memory = @#ModifiedPageListBytes from WMI\rLinux CPU and Disk Metrics Name Source Unit guest.cpu.runQueue \u0026ldquo;procs_running\u0026rdquo; from /proc/stat Number guest.disk.requestQueue Sum of pending IOs from /proc/diskstats across all active block devices Number guest.disk.requestQueueAvg Sum of weighted time deltas across all active block devices Number Windows CPU and Disk Metrics Stat Name Source guest.processor.queue Win32_PerfFormattedData_PerfOS_System = @#ProcessorQueueLength from WMI guest.disk.queue Win32_PerfFormattedData_PerfDisk_PhysicalDisk.Name = \\\u0026quot;_Total\\\u0026quot;#CurrentDiskQueueLength\u0026quot; from WMI guest.disk.queueAvg Win32_PerfFormattedData_PerfDisk_PhysicalDisk.Name = \\\u0026quot;_Total\\\u0026quot;#AvgDiskQueueLength\u0026quot; from WMI "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-5---network-metrics/2.5.4-vm/",
      "title": "4. VM",
      "tags": [],
      "description": "",
      "content": "The following screenshot shows the counters vCenter provides for the Network at a VM layer. The counters are available at each individual vNIC level and at the VM level. Most VMs will only have 1 vNIC, so the data at VM level and vNIC level will be identical. The vNICs are named using the convention \u0026ldquo;400x\u0026rdquo;. That means the first vNIC is 4000, the second vNIC is 4001, and so on.\nAs usual, let\u0026rsquo;s approach the counters starting with Contention. There is no Latency counter so you cannot track how long it takes for a packet to reach its destination. There are, however, counters that track packet loss. For TCP connection, dropped packet needs to be retransmitted and therefore increases network latency from application point of view. The counter will not match the values from Guest OS level as packets are dropped before it’s handed into Guest OS, or after it left the Guest OS. ESXi dropped the packet because it’s not for the Guest OS or it violates the security setting you set.\nvCenter does not provide a counter to track packet retransmit.\nNetwork latency could be impacted by CPU. CPU might not fast enough to process the packet. In VM, this could also be due to the VM having CPU contention.\nBesides unicast traffic, which should form the bulk of your network, vSphere also provides information about broadcast traffic and multicast traffic. If you are not expecting any of this traffic from certain VMs (or clusters) and want to be alerted if it does occur, you can create a group for the objects and then apply a super metric. The super metric would add the four counters that capture broadcast and multicast. You should expect a flat line as the total should be near 0.\nJust in case you\u0026rsquo;re not aware of these KB articles.\nPacket loss in Guest OS using VMXNET3: When using the VMXNET3 driver on a VM on ESXi, you see significant packet loss during periods of very high traffic bursts. The VM may even freeze entirely. This issue occurs when packets are dropped during high traffic bursts. This can occur due to a lack of receive and transmit buffer space or when receive traffic which is speed constrained. esxtop show dropped packets: The network screen output in esxtop show dropped receive packets (%DRPRX) at the virtual switch port. They are actually dropped between the virtual switch and the guest operating system driver. The dropped packets can be reduced by increasing the Rx buffers for the virtual network driver. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-4---storage-metrics/2.4.4-datastore/",
      "title": "4. Datastore",
      "tags": [],
      "description": "",
      "content": "Storage in VMware IaaS is presented as datastore. In some situation, RDM and network file shares are also used by certain VM.\nThe underlying storage protocol can be files (NFS) or blocks (VMFS). vSAN uses VMFS as its consumption layer as the underlying layer is unique to vSAN, and hence vSAN requires its own monitoring technique.\nFor NFS, as it is network file share (as opposed to block), you have no visibility to the underlying storage. The type of counters will also be more limited.\nTake note that datastores that share the same underlying physical array can experience problem at the same time. The underlying array can experience a hot spot on its own, as it is made of independent magnetic disks or SSD.\nVMs in the same datastores can experience different latency. The following heat map shows all the VMs in a single VMFS datastore, backed by ExtremeIO. Notice two of the VMs experience latency above 10 ms, while many other VMs experience less than 1 millisecond.\nThere are more counters available via vCenter API than what\u0026rsquo;s presented in the UI. Just to recap, this is what you get in the UI.\nCounters such as Datastore \\ Outstanding Read Requests and Datastore \\ Outstanding Write Requests are available only in the API. They are required for performance troubleshooting and capacity monitoring.\nCapacity The information you need Counter to use The total capacity of a datastore Capacity | Total Capacity (GB) The actual space consumed in a datastore Capacity | Used Space (GB)\nThis is the actual consumption, not the allocated/provisioned as in Thin Provisioning case. The consumption number in % Capacity | Used Space (%) The actual free space in your datastore Capacity | Available Space (GB) The total provisioned space for VM Capacity | Total Provisioned Consumer Space (GB) As you can see from the following, the last metric will be blank if there is no VM in the datastore.\nYou should be using Datastore Cluster, especially in environment where a cluster uses multiple datastores. Other than the benefits that you get from using it, it also makes capacity management easier. You need not manually exclude local datastore, and you need not manually group the shared datastores, which can be complex if you have multiple clusters.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-3---memory-metrics/2.3.4-vm/",
      "title": "4. VM",
      "tags": [],
      "description": "",
      "content": "The following screenshot shows the memory counters of a VM. Compared with Guest OS such as Windows, can you notice what\u0026rsquo;s missing and what\u0026rsquo;s added? Go ahead and open Windows PerfMon or SysInternal and compare, and you will quickly notice major differences.\nContention This is the only performance counter for memory. Everything else does not actually measure latency. They measure utilization, because they measure the disk space occupied. None captures the performance, which is how fast that memory page is made available to the CPU.\nConsider the hard disk space occupied. A 90% utilization of the space is not slower than 10%. It\u0026rsquo;s a capacity issue, not performance.\nIf a page is not in the physical DIMM, the VM has to wait longer. It could be in Host Cache, Swapped or Compressed. It will take longer than usual. vSphere tracks this in 2 counters: CPU Swap Wait and RAM Latency.\nCPU Swap Wait tracks the time for Swapped In. RAM Latency tracks the percentage of time VM waiting for Decompressed and Swapped In. The RAM Latency is a superset of CPU Swap Wait as it caters for more scenarios where CPU has to wait. vRealize Operations VM Memory Contention metric maps to this. Latency is \u0026gt;1000x lower in memory compared to disk, as it\u0026rsquo;s CPU basically next to the CPU on the motherboard. Time taken to access memory on the DIMM bank is only around 200 nanoseconds. Windows/Linux does not track memory latency. The closest counter is perhaps page fault. The question is does page fault includes prefetch? If you know, let me know please.\nDoes it mean we don\u0026rsquo;t track balloon, swapped and compressed?\nNo.\nThe higher the value is for balloon, swapped, and compressed, the higher the chance of a performance hit happening in the future if the data is requested. The severity of the impact depends on the VM memory shares, reservation, and limit. It also depends upon the size of the VM\u0026rsquo;s configured RAM. A 10-MB ballooning will likely have more impact on a VM with 4 GB of RAM than on one with 512 GB.\nLatency does not include balloon as that\u0026rsquo;s a different context. In addition, the hypervisor is not aware of the Guest OS internal activity.\nIn an environment where you do not do memory overcommit and place limit, the chance of hitting memory contention will be basically 0. You can plot the highest VM Memory Contention counter in all clusters and you will basically see a flat line. That would be a lot of line charts, so I\u0026rsquo;m using a pie chart to analyze 2441 VM in the last 4 months. For each VM, I took the highest value in the last 4 months. Only 13VM had its worst VM Contention above 1%.\nThese counters reduce the value of the Compressed metric and/or Swapped metric, and increase the value of Consumed \u0026amp; Granted.\nThe counter is called %LAT_M in esxtop. CPU Contention is called %LAT_C.\nBalloon Balloon is Guest OS kernel driver. It allocates physical memory in the Guest OS. The Guest OS cannot use these pages. This physical memory in the Guest OS is not backed up by physical memory in ESXi, hence it is available for other VMs. When ESXi is no longer under memory pressure, it will notify the Balloon to release its requested page inside Guest OS. This is a proactive mechanism to reduce the chance of the Guest OS doing paging. Balloon will release the page inside the Guest OS. The Balloon counter for the VM will come down to 0.\nGuest OS will start allocating from the Free Pages. If insufficient, it will take from Cache, then Modified, then In Use. This does not cause performance problem. What will cause performance is when the ballooned page is requested by Windows or Linux. The following shows a VM that is heavily ballooned as limit was imposed on it. Notice the actual performance happens rarely.\nJust because Balloon asks for 1 GB of RAM, does not mean ESXi gets 1 GB of RAM to be freed. It can be less if there is TPS.\nTo use ballooning, Guest OS must be configured with sufficient swap space.\nGuest OS initiate memory reallocation. Therefore, it is possible to have a balloon target value of 0 and balloon value greater than 0. The counter Balloon Target tracks this target, so if you see a nonzero value in this counter, it means that the hypervisor has asked this VM to give back memory via the VM balloon driver. This does not necessarily indicate a reduction of performance, as it depends upon whether the memory page released by the balloon driver is a free one or not. If it is from the free memory, then the Guest OS does not need to perform a page out to meet the request of its balloon driver. If it is not, then the Guest OS will page out, and this can impact performance.\nBalloon is a memory request from ESXi. So it\u0026rsquo;s not part of the application. It should not be included in the Guest OS sizing, hence it\u0026rsquo;s not part of reclamation.\nBalloon impacts the accuracy of Guest OS sizing. However, there is no way to measure it.\nWhen Balloon driver asks for pages, Guest OS will allocate, resulting in In Use to go up. This is because the balloon driver is treated like any other processes. If the page comes from Free, then we need to deduct it from In Use. If the page comes from In Use, then we can\u0026rsquo;t simply deduct the value of In Use. Guest OS pages out, so we need to add Page Out or Cache. Compressed or Swapped This counter tracks the amount of RAM that is subjected to the compression process. It does not track what the resultant compressed amount. There are 2 levels of compression (4:1 and 2:1), so a 4 KB page may end up as 1 KB or 2 KB. If the compression result is less than that, the page will be swapped instead as that\u0026rsquo;s a cheaper operation.\nYou may notice that there is no compression target. We have a balloon target and swap target, so we should expect a compression target too. Right?\nNot really. Because both swap and compression work together to meet the swap target counter, the counter should actually be called Compression or Swap target.\nThe Consumed counter includes this metric. To be accurate, the Compressed counter should track the result of the compression, as that\u0026rsquo;s the actual amount consumed by the compressed pages.\nIt is possible to have balloon showing a zero value while compressed or swapped are showing nonzero values-even though in the order of ESXi memory reclamation techniques, ballooning occurs before compression. This indicates that the VM did have memory pressure in the past that caused ballooning, compression, and swapping then, but it no longer has the memory pressure. Data that was compressed or swapped out is not retrieved unless requested, because doing so takes CPU cycles. The balloon driver, on the other hand, will be proactively deflated when memory pressure is relieved.\nCompressed and Swapped are different from ballooning, as the hypervisor has no knowledge of the free memory inside the Guest OS. It will randomly compress or swap. As a result, any value in this counter indicates that the host is unable to satisfy the VM memory requirement.\nThere are other compression related metrics that are provided. So I have not used them\nCounters Description Average Compressed Average amount of compressed memory in the reporting period. In vCenter case, this is the average of the last 20 seconds. In vRealize Operations case, this is the average of the last 5 minutes. Latest Zipped Last amount of compressed memory in the reporting period. In vCenter case, this is data in the 20th second. vRealize Operations then averages 15 of these datapoints to make a 300 second average. Zip Saved Compression Rate Decompression Rate Which one should you pay attention to?\nThe answer always goes back to: when you see the value, what are you going to do about it? Basing on the purpose or use case helps in applying the metrics in the context of operations.\nConsumed Consumed = Granted - Saving from Sharing\nConsumed does not include overhead memory, although this number is practically negligible.\nConsumes includes memory that might be reserved.\nThis tracks the ESXi Memory mapped to the VM. ESXi assigns large pages (2 MB) to VM whenever possible; it does this even if the Guest OS doesn\u0026rsquo;t request them. The use of large pages can significantly reduce TLB misses, improving the performance of most workloads, especially those with large active memory working sets.\nThe above is one reason why the Consumed metric is higher than the Guest OS In Use. The other reason is it contains pages that were active (and no longer active), but still mapped to the VM.\nHere is a screenshot comparing Windows 10 Task Manager memory counters with vRealize Operations Memory \\ Non Zero Active (KB) and Memory \\ Consumed (KB). As you can see, none of the counters match.\nWhen a Guest OS frees up a memory page, it normally just updates its list of free memory, it does not release it. This list is not exposed to the hypervisor, and so the physical page remains claimed by the VM. This is why the Consumed counter in vCenter remains high when the Active counter has long dropped.\nIt is a common mistake to think they are calculated in a similar, and simply differ based on aggressive vs conservative. The following test shows Active going down while Consumed going up!\nConsumed is affected by Limit. The following is a VM configured with 8 GB RAM but was limited to 2 GB.\nActive This is a widely misunderstood counter. ESXi calls this Touch as it is better represents the purpose of the metric. Note that vCenter still calls it Active, so I will call it Active.\nThis counter is often used to determine the VM utilization, which is not what it was designed for. To know why, we need to go back to fundamental. Let\u0026rsquo;s look at the word Active. It is an English word that needs to be quantified before we can use it as metric. There are 2 dimensions to consider before we apply it:\nDefinition of active. In RAM context, this means read or write activity. This is similar to disk IOPS. The more read/sec or write/sec to a page, the more active the page is. Note that the same page can be read/written to many times in a second. Because a page may be accessed multiple times, the actual active pages are lower. Example: a VM reads 100 pages and writes 200 pages. However, 50 of the writes are on the page that were read. In addition, there are 10 pages that were read multiple times. Because of these 2 factors, the total active pages are far fewer than 300 pages. If the page is average 4 KB, then the total active is way less than 1200 KB. Active is time bound. Last week is certainly not active. Is 300 seconds ago active? What exactly, is recent? 1 second can be defended as a good definition of recent. IOPS is always measured per second, hence the name IOPS. Applying the above understanding, the active counter is actually a rate, not a space. However, the counter reported by vCenter is in KB, not KB/s.\nTo translate from KB/s to KB, we need to aggregate based on the sampling period. Assuming ESXi samples every 2 seconds, vCenter will have 10 sampling in its 20 second reporting period. The 10 samplings can be sampling the same identical pages, or completely different ones. So in the 20 seconds period, the active memory can be as small as 1 sampling, or as large as 10 samplings.\nExamples:\nFirst 2 seconds: 100 MB Active Next 2 seconds: 150 MB Active In the above 4 seconds, the active page ranges from 150 MB to 250 MB.\nEach sampling is done independently, meaning you could be sampling the same block again. But the value is then averaged it with previous samples. Because sampling and averaging takes time, Active won\u0026rsquo;t be exact, but becomes more accurate over time to approximate the amount of active memory for the VM. This number is typically different from Guest OS working set estimate. Sometimes the difference may be big, because Guest OS and VMkernel use different working set estimate algorithm. Also, Guest OS has a different view of active guest physical memory, due to ballooning and host swapping. Note that ballooned memory is considered inactive, so, it is excluded from the sampling.\nIf you plot vRealize Operations in vCenter real-time performance chart, you will see 12 peaks in that one hour line chart. The reason is vRealize Operations pulls, process, and writes data every 5-minutes. The chart for CPU, disk and network will sport the same pattern. This is expected.\nBut if you plot the memory counters, be it total active, active write or consumed, you will not see the 12 peaks. This is what I got instead.\nConsume is completely flat and high. Active (read and write) and Active Write (write only) is much lower but again the 12 peaks are not shown.\nCan you figure it out?\nMy guess is the sampling size. That\u0026rsquo;s just a guess, so if you have a better answer let me know!\nvCenter reports in 20 seconds interval. In vRealize Operations, this metric is called Memory \\ Non Zero Active (KB). vRealize Operations takes 15 of these data and average them into a 300-second average. In the 300 second period, the same page can be read and written multiple times. Hence the active counter over reports the actual count.\nQuiz: now that you know Active over reports, why is it lower than Consumed? Why is it lower than Guest OS counters?\nAs usual, answer to the quiz is at the end of the book.\nBoth Active and Consumed are not suitable for sizing the Guest OS. They are VM level counters, with little correlation to the Guest OS memory usage. Read Guest OS Used counter for the counter we should use.\nThe reason is the use case. It is not about the IOPS. It is about the disk space used. Guest OS expects the non-active pages to be readily available. Using Active will result in a lot of paging.\nReference: Active Memory by Mark Achtemichuk.\nGranted The amount of memory that has been provided to the VM, meaning mapped to ESXi machine memory. It is the amount of virtual memory that is backed by machine memory. It includes Shared memory but exclude Overhead because Overhead is functionally beyond what the VM see.\nThe VM total memory footprint is Granted + Ballooned + Swapped + Compressed + not touched + Overhead.\nNot touched means the VM never uses the page since it\u0026rsquo;s powered on. This happens because:\nThe VM never use it at all. The page was reclaimed by the balloon driver, and the VM never touched it since then. Memory is not granted to the VM until it has been touched once. In the case of Linux, which does not zero out pages upon boot, the counter may not jump immediately upon OS start. For Windows, you may see that Consumed shoots up ahead of Granted. When Windows writes zeroes to initialize the pages, VMkernel is smart enough to do a copy-on-write, so all the pages are pointing to the same physical page. This results in the Consumed counter being higher than the Granted counter, as Granted only counts the physical page once. After a while, as the pages are replaced with actual data, the Granted counter will go up as each of the new pages is backed by large pages (common in Windows 2008 and Windows 7).\nIf you use Limit, which you should not, you may want to know if the VM needs more than the limit amount. Granted is the counter for that, as shown in the following. This VM is a Windows 2016 server. It\u0026rsquo;s configured with 12 GB of RAM, hence the Granted metric does not exceed that.\nThe Granted counter tends to have a stable value as it only goes down if the host is under memory pressure.\nEntitlement = Granted + Overhead.\nThe Zero counter tracks all pages with just zeroes on them (unused pages).\nShared There are 2 types of shared pages:\nIntra-VM sharing: sharing within the same VM. By default, each page is 4 KB. If Guest OS uses the Large Page, then it\u0026rsquo;s 2 MB. The chance of sharing in 4 KB is much higher than 2 MB. Inter-VM sharing. Due to security concern, this is by default disabled in vSphere. A commonly shared page is certainly the zero page. This is a page filled with just zeroes.\nFor accounting purpose, the Shared page is counted in full for each VM. Example:\nVM 1: 1 GB private, 100 MB Shared within itself, 10 MB shared with other VMs (it does not matter how many and what VMs).\nThe 100 MB is the amount that is being shared. If not shared, they would consume 100 MB. But how much is actually consumed as a result of this sharing?\nThe 10 MB is shared with other VMs. VM 1 could be sharing 1 MB each with 10 other VMs, or the entire 10 MB with just 1 VM. The Shared counter merely counts that this 10 MB is being shared. VM 1 definitely consumes this 10 MB, and it\u0026rsquo;s not sharing within itself.\nShared includes zero pages.\nShared Saved metric tracks the estimated amount of machine memory that are saved due to page sharing.\nBecause the ESXi machine page is shared by multiple Guest OS physical pages, this metric charge \u0026ldquo;1/ref\u0026rdquo; page as the consumed machine memory for each of the guest physical pages, where \u0026ldquo;ref\u0026rdquo; is the number of references. So, the saved machine memory will be \u0026ldquo;1 - 1/ref\u0026rdquo; page. For example, if there are 4 pages pointing to the same physical DIMM, then the savings is 3 pages worth of memory.\nNUMA Metrics These counters are not exposed in vCenter. It\u0026rsquo;s available in esxtop\nCounters Description NUMA Migration The number of NUMA migrations that have occurred since the VM\u0026rsquo;s creation Local Memory The amount of the VM\u0026rsquo;s memory that is on the local NUMA nodes. Remote Memory The amount of the VM\u0026rsquo;s memory that is on the remote NUMA nodes. Remote memory access is slower as it has to go through another CPU. Hence, ideally this amount is 0. You increase the chance by making the Configured RAM small. A VM whose configured memory is larger than the ESXi RAM attached to a socket have higher chance of having remote memory. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-2---cpu-metrics/2.2.4-quiz-time/",
      "title": "4. Quiz Time!",
      "tags": [],
      "description": "",
      "content": "By now I hope you vrealize that the various \u0026ldquo;utilization\u0026rdquo; metrics in the 4 key objects (Guest OS, VM, ESXi and Cluster) varies. Each has their own unique behaviour. Because of this, you are right to assume that they do not map nicely across the stack. Let\u0026rsquo;s test your knowledge with an example.\nGuest OS Review the following chart carefully. It\u0026rsquo;s my physical desktop running Windows 10. The CPU has 1 socket 4 cores 8 threads, so Windows see 8 logical processors. You can see that Microsoft Word is not responding as its window is greyed out. The Task Manager confirms that by showing that none of the 3 documents are responding. Word is also consuming a very high power, as shown in the power usage column.\nIt became unresponsive because I turned on change tracking on a 400-page document and deleted hundreds of pages. It had to do a lot of processing and it did not like that. Unfortunately I wasn\u0026rsquo;t able to reproduce the issue after that.\nAt the operating system system, Windows is responding well. I was able to close all other applications, and launched Task Manager and Snip programs. I suspect because Word does not consume all CPUs. So if we track at Windows level, we would not be aware that there is a problem. This is why process-level monitoring is important if you want to monitor the application. Specific to hang state, we should monitor the state and not simply the CPU consumption.\nFrom the Windows task bar, other than Microsoft Word and Task Manager, there is no other applications running. Can you guess why the CPU utilization at Windows level is higher than the sum of its processes? My guess on why Windows show 57% while Word shows 18.9% is Turbo Boost. The CPU counter at individual process level does not account for it, while the counter at OS level does.\nI left it for 15 minutes and nothing change. So it wasn\u0026rsquo;t that it needed more time to process the changes. I suspect it encountered a CPU lock, so the CPU where Word is running is running at 100%. Since Windows overall only reports 57%, it\u0026rsquo;s important to track the peak among Windows CPU. This is why vRealize Operations provides the peak value among the VM vCPU.\nVM vs ESXi Review the following chart carefully. Zoom in if necessary.\nThe vCenter chart1 above shows a VM utilization counters. It\u0026rsquo;s a large VM with 24 vCPU running controlled CPU test. The power management is fixed so it run at nominal clock speed. This eliminates CPU frequency scaling factor.\nIt starts at 50% \u0026ldquo;utilization\u0026rdquo;, with each vCPU pinned to a different physical core. It then slowly ramps up over time until it reached 100%.\nCan you figure out why the three counters moved up differently? What do they measure?\nNow let\u0026rsquo;s look at the impact on the parent ESXi. It only has a single VM, but the VM vCPU matches the ESXi physical cores. The ESXi starts at 50% \u0026ldquo;utilization\u0026rdquo;, then slowly ramp up over time until it reached 100%.\nCan you figure out why the 3 counters moved up differently? What do they measure? As usual, answer can be found at Part 4.\nESXi Utilization vs Contention ESXi \u0026ldquo;utilization\u0026rdquo; does not correlate to ESXi \u0026ldquo;contention\u0026rdquo;. The 4 highlighted area are examples where the metrics don\u0026rsquo;t correlate, even go the opposite way in some of them. Can you guess why?\nAs usual, answer in Part 4.\nProvided by Valentin Bondzio\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-1---overview/2.1.4-resource-management/",
      "title": "4. Resource Management",
      "tags": [],
      "description": "",
      "content": "\nYou need to know the following concepts that vSphere uses to manage the shared resources:\nReservation Limit Share Entitlement Reservation represents a guarantee. It impacts the Provider (e.g. ESXi) as that\u0026rsquo;s where the reservation takes place. However, it works differently on CPU vs RAM.\nCPU If the VM does not use the resource, then it does not come into play as far as the VM is concerned. It\u0026rsquo;s only enforced during the period where the VM actually uses it.\nRAM If it\u0026rsquo;s not yet used, then it does not take effect. Meaning ESXi Host does not allocate any physical RAM to the VM. However, once a VM asks for memory and it is served, the physical RAM is reserved. From then on, ESXi continues reserving the physical RAM even though the VM is no longer using it. In a sense, the page is locked despite the VM become idle for days. The Consumed metric includes this to reflect this behaviour. No other VM can touch it even though it\u0026rsquo;s not used.\nLimit should not be used as it\u0026rsquo;s not visible to the Guest OS. The result is unpredictable and could create a worse performance problem than reducing the VM configuration. For CPU, it impacts the CPU Ready counter. For RAM, in the VMX file, this is sched.mem.max.\nUnlike Reservation and Share, which are statically configured, Entitlement is calculated dynamically. It considers Limit, Reservation, and Shares. For Shares, it certainly must consider Shares of other VMs running on the same host. A VM can\u0026rsquo;t use more than what ESXi entitles it.\nReservation, Share and Limit are relatively static. They do not fluctuate unless they are manually changed. Hence, they behave more like a property than a metric.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-7---availability-management/1.7.4-disaster-avoidance-and-recovery/",
      "title": "4. Disaster Avoidance and Recovery",
      "tags": [],
      "description": "",
      "content": "\rThis page is for rent. Meaning we need a contributing author!\nThere are operational impact when you add capability to handle disaster. There are 3 primary use cases:\nDisaster Avoidance You avoid disaster by doing long distance vMotion on an stretched vSphere cluster.\nDo you have enough WAN bandwidth? Does the vMotion complete within the expected time? - If not, what\u0026rsquo;s causing it? What\u0026rsquo;s the performance impact during the vMotion? As the pipe is shared, this can impact other VMs too. DR Test You are doing a test, as required by regulator or internal Business Continuity Plan. Your production VM is still running, so you need to bubble the network.\nDo you have enough resources on the recovery site? Did it complete within the expected time? If not, what\u0026rsquo;s causing it? DR Actual You are doing the actual recovery. This can be planned or unplanned.\nDo you have enough resources? What\u0026rsquo;s the performance impact on the target cluster and datastore? In a large environment, you can have multiple clusters parcitipating in active/active DR, protecting one another. This can create complex relationship, especially if you have hundreds of business applications and they span across clusters.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-6---compliance-management/1.6.4-how-the-policies-work/",
      "title": "4. How the Policies Work",
      "tags": [],
      "description": "",
      "content": "Having covered what is provided in vRealize Operations, let\u0026rsquo;s discuss how these policies work. What do they do? Underlying all these policies are certain configurations and alert settings. As per the official documentation, \u0026ldquo;all the compliance standards in vRealize Operations, including any standards that you define, are based on alert definitions. Only alert definitions of the Compliance subtype are counted. Custom score cards can monitor user-defined alerts.\u0026rdquo;1.\nFor example, \u0026ldquo;ISO Security Standards\u0026rdquo; checks for the following among many other points:\nConfigure the SSH Service on the ESXi Hosts for Compliance Restrict remote access to the host by disabling the SSH service and the shell service and enabling lockdown mode Provide complex password in vCenter Server Configure lockout in vCenter Server All these configurations are checked in the environment. Symptoms are defined in the environment against these checks and finally alerts are set against those symptoms.\nIf any alerts are raised then there is a misconfiguration against the set policy which needs to be corrected.\nThis also leads to the scope of defining own custom Symptom -\u0026gt; Alerts -\u0026gt; Benchmarks.\nSource: VMware Documentation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.4-demand-model/",
      "title": "4. Demand Model",
      "tags": [],
      "description": "",
      "content": "Demand reflects the reality in production, as it\u0026rsquo;s based on the actual demand for resources in a cluster and datastore. It is enabled by default without any configuration and cannot be disabled.\nDemand is more than the active load that is consuming your capacity. Active load is the visible demand, which you can monitor with the utilization metrics. There are demand that are not visible, because it has no utilization at present.\nUse the Allocation Model and buffer settings in vRealize Operations to cater for this invisible demand. Note that buffer is applied after Availability.\nSudden Demand This can wreak havoc in a shared environment. A group of highly demanding VMs can collectively impact overall performance of the cluster or datastore. An example of this is annual sales or stock market crash. In this case, the capacity team should set an appropriate overcommit ratio and drive by allocation as the demand is low most of the time.\nLatent Demand Many critical VMs are protected with Disaster Recovery. During a DR drill or actual disaster, this load will \u0026lsquo;wake up\u0026rsquo; and consume. You should consider the Site Recovery Manager plans into your capacity.\nPotential Demand Many newly provisioned VMs take time to reach their full expected demand. It takes time for the database to reach the full size, the user base to reach the target, and the functionalities to be complete. Newly provisioned VM tend to be idle (which can be months) and may suddenly grow. When this happens, it will result in an increase in demand.\nUnmet Demand There are 2 parts to it: inside the VM and outside the VM.\nIf the VM is undersized, the unmet demand will not be visible to the underlying infrastructure. Unless that is intentional, it is wise to include undersized VM in the cluster capacity monitoring.\nThe visible part of unmet demand becomes part of IaaS KPI and SLA, covered in Performance Management chapter.\nThere are 2 other consideration when calculating demand in the context of capacity.\nReservation Limit Reservation that is not yet consumed impacts capacity but not performance. Using a restaurant analogy, if all your tables are reserved but only 20% turns up, you have 0 capacity left but can easily serve all customers the real demand is only 20%.\nCPU and Memory behave differently as CPU reservation does not take effect when the reservation holder does not use it.\nLimit needs to be considered as the demand can\u0026rsquo;t exceed the enforced limit. The good part is the demand counter already takes that into account.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.4-contention-vs-utilization/",
      "title": "4. Contention vs Utilization",
      "tags": [],
      "description": "",
      "content": "At the VM layer, we care whether a particular VM is being served well by the platform. Other VMs are irrelevant from the VM owner\u0026rsquo;s point of view. So, the key counter here is VM contention. Infrastructure metrics are irrelevant. Only when we are satisfied that there is no contention can we proceed to check whether the VM is sized correctly or not. Most people check for utilization first because that is what they are used to monitoring in the physical infrastructure. In a virtual environment, we should check for contention first.\nMost raw metrics can be categorized into 3 types:\nThey measure something bad (e.g. contention, latency) They measure something good (e.g. utilization, consumption) They account for something (e.g. inventory, configuration) Consumption, better known as utilization, is hence a family of metrics. It comes in many different names (IOPS, throughput, usage, demand, active, etc.). Its opposite is the contention type of metrics. Utilization is the main source for the capacity family of counters (Capacity Remaining, Time Remaining, VM Remaining, Recommended Size).\nContention is the primary counter family for performance, while utilization is the primary counter family for capacity. Performance \u0026amp; Capacity uses these two types of counters differently. Knowing the requirements of each is critical in optimizing both performance and capacity.\nMost look at utilization, because they fear something wrong will happen if it\u0026rsquo;s high. That \u0026ldquo;something\u0026rdquo; is contention. Contention manifests in different forms. It can be queue, latency, loss, dropped, aborted, context switch.\nThe following diagram shows three different scenarios\nWhat you think will happen. You theorize that contention will only happen when utilization is high, and the unused capacity acts as cushion to prevent unmet demand from happening. What actually happens in most environment. Demand is unmet even though utilization is not high, due to suboptimal configuration or constraint. What could happen if your environment is optimized. You have very high utilization yet you keep unmet demand within the promised SLA. Do not confuse \u0026ldquo;ultra-high\u0026rdquo; utilization indicators as a performance problem. High utilization does not compromise performance, so long as there is no queue or contention. Just because an ESXi Host is experiencing ballooning, compression, and swapping does not mean your VM has memory performance problem. You measure the performance of the host by how well it serves its VMs. While it is related to ESXi utilization, the performance metric is not based on the utilization at all. It is based on contention metrics.\nUtilization is not a counter for performance. It\u0026rsquo;s a counter for capacity. The higher the utilization, the more work gets done, and hence the better the performance. Utilization at 100% is in fact the best possible performance, so long there is no contention. Since we can track contention explicitly, the performance counter becomes secondary, supporting counter.\nThe following diagram shows all the layers in typical IaaS, focusing on the consumer side.\nContention is placed above utilization as that\u0026rsquo;s what you should drive your operations. As Mark Achtemichuk said in this article, drive by contention. For each layer, you have a set of metrics. The black line shows that contention is the primary counter for performance, and utilization is the primary metric for capacity.\nThe green line shows that contention counters give valuable input to capacity by showing how much additional capacity is required. For example, the number of queues in the CPU should be used to determine the amount of CPU to add.\nThe blue line shows that contention in the underlying layer directly impacts the performance of the layer above. For example, if a Guest OS experiences disk latency, the application will feel the impact. That can result in a ripple effect to the top layer.\nThe red line is not solid, as it\u0026rsquo;s showing a misconception. If contention = 0, then utilization at 100% is in fact maximum performance. If we can\u0026rsquo;t measure the contention, then add the buffer (e.g. 90% utilization) as queue tends to develop at high utilization. On the other hand, you can have poor performance at low utilization. Many things can cause this. Here are just some.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/",
      "title": "Metrics",
      "tags": [],
      "description": "",
      "content": "Part 2 (Metrics) is a deep dive into the key metrics that you will most commonly use and should be considered a pre-requisite to Part 3.\nvRealize Operations ships with thousands of metrics and properties, covering objects in vSphere, vSAN, the Guest OS and others. If we take object by object, and document metrics by metrics, it would be both dry and confusing. Most likely you will be disappointed as it does not explain how your problems are solved.\nThis document begins with you. It focuses on the problems You are trying to solve when running your multi-cloud operations. It looks at all the use cases and breaks down the metrics from there, which helps you appreciate why the metrics are layered in such manner. vRealize Operations takes raw counters from the systems that are monitored, and formulates higher-level counters that meet your operational needs better.\nChapter 1 - Overview\r1. Nuances in Metrics\r2. Guest OS vs VM\r3. Roll-Up vs Aggregation\r4. Resource Management\r5. ESXTOP\rChapter 2 - CPU Metrics\r1. Guest OS\r2. VM\r3. ESXi Host\r4. Quiz Time!\rChapter 3 - Memory Metrics\r1. Virtual Memory\r2. Guest OS vs VM\r3. Guest OS\r4. VM\r5. ESXi Host\r6. Other Metrics\rChapter 4 - Storage Metrics\r1. The Layers in Storage\r2. VM\r3. ESXi Host\r4. Datastore\r5. vSAN\r6. Storage Array\rChapter 5 - Network Metrics\r1. Why Network Monitoring Is Unique\r2. SDDC Network Monitoring\r3. Guest OS\r4. VM\r5. ESXi Host\r6. Distributed Switch\rChapter 6 - Other Metrics\r1. Troubleshooting Metrics\r2. VMKernel\r3. vSphere Cluster\r4. VMware Tools\r5. Miscellaneous\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.5-performance-dashboards/",
      "title": "5. Performance Dashboards",
      "tags": [],
      "description": "",
      "content": "Now that you\u0026rsquo;ve seen what the performance metrics are and how they are meant to be used together, designing the dashboards become easier. Armed with knowledge of vRealize Operations, creating all the dashboards can be done within a day.\nIn DaaS, you\u0026rsquo;re outnumbered by your users. There are users than administrators, and problems can also come from non users. As a result, there is a good chance that by the time you look into the problem, 5 minute have passed or the problem no longer happens. This means the performance dashboard should show you a trend, not just the present time or a point in time in the past.\nThe dashboard needs to cover\nHorizon DC Performance\nHorizon Network Performance\nTo complete the picture, the dashboard should enable you to see from vSphere viewpoint, because a problem at lower layer can impact upper layer. This is especially important in Horizon as you will overcommit.\nThe following shows an example of such implementation. It splits performance into 2 (DC and Network). Both are able to drill down into the VDI Pool dashboard and RDS Farm dashboard. Because they drill down into the same dashboard, the destination dashboard has to cover both DC and network.\nThe VDI dashboard includes session, while RDS dashboard includes host and session. From both, you can drill down into the vSphere VM dashboard.\nThe dashboards are designed to work with the object summary page. If you need the most details of an object, drill down to the summary page.\nDC Performance Dashboard This dashboard acts as the overall dashboard for all DC related performance.\nInformation is color coded: Green, Yellow, Orange and Red.\nIt should list all the pods, along with their KPI. Selecting a pod should show its performance over time.\nFrom a pod, you should be able to drill down to its VDI Pools and RDS Farms. The KPI should be shown. Selecting a pod should show its performance over time.\nFinally, selecting a pod, a pool or a farm should give its key information so you have better context.\nThe dashboard is designed to provide a quick overview, enabling convenient access to cycle among pods, farms and pools as you try to establish the performance issue. It\u0026rsquo;s not suitable when you already know the farm or pool with problem. If you already know the specific, then simply go direct to the VDI dashboard or RDS dashboard.\nWe can visualize the overall performance over time using a health chart and pick the KPI metric at the Horizon World object.\nFrom the above, you drill down to the Pod level, bypassing the Cloud Pod level and Site level for more efficient process. The following table show all the Pods. For each pod, it shows the worst performance, meaning the lowest value of the Pod DC KPI (%) any given 5 minute in the last 24 hours. To change to other time period, click on the date icon. To determine if the worst performance is just a one time blip, use the Performance at 95th percentile metric.\nThe columns Farms and Pools show the numbers at present. Customize this table with information that you need.\nSelect a pod and its historical performance is automatically shown. VDI tends to follow working hours of having a trend is important to see the pattern during working hours and non working hours (where you do a lot of maintenance activities).\nThe pod key properties will also be shown for better context.\nFrom the Pod, you can drill down into its RDS Farms or VDI Pools. The navigation is similar, so we will take one of them as example. You get the list of farm, with their performance information.\nThe table has a blue border as you can drill down into the RDS Farm dashboard.\nThe column Sessions show the numbers at present. It\u0026rsquo;s not the highest number of sessions in the last 24 hours.\nYou can select any of the farm, and its KPI will be shown over time\nThe farm key properties will also be shown for better context.\nTo troubleshoot further, select a farm and then navigate to RDS Performance dashboard. The selected farm will be passed as a context.\nFor VDI Pool, select a pool and navigate to the VDI Performance dashboard. The experience is consistent with RDS.\nNetwork Performance The dashboard follows the same design principle with DC Performance. Both acts as the overview dashboard, showing you the overall performance over time, and allowing quick cycles among farms and hosts to find which one to investigate further.\nRDS Performance The RDS Performance dashboard has more details, all the way down to hosts and sessions. It begins by listing all the farms, color coded by performance. You can sort them by their performance, number of active sessions, etc. Selecting a farm with automatically show the KPI. This helps you cycle quickly among many farms.\nThe partially visible line, marked with green, is a drill down from RDS Host into the underlying VM. You\u0026rsquo;ll in the following screenshot that the line starts from the host.\nFrom the Farm, you can drill down into the hosts and the sessions in the farm. The following shows the host section of the dashboard.\nAnd here is the session portion of the dashboard.\nFirst, it shows the farm performance in more details.\nIf the above is not green, then you drill down into specific area (CPU, Memory, Disk, Network, User Profile).\nThe last part if the host status. This scoreboard focuses on the host status that needs attention. There are more status that can fit here, so if you want to see them all, customize this and make it 2 rows.\nThe dashboard is kept simple so it\u0026rsquo;s easy to use. Add necessary widgets to tailor to your need. For example, if you think the performance is caused by high utilization, add the utilization metrics. Do not color coded as high utilization can be healthy (productive).\nFrom the farm, you can drill down to the hosts. The usual KPI (%) is shown, both at its worst and 95th percentile during the last 24 hours.\nAs you can expect, selecting a host shows you the host performance over time.\nYou get the usual raw detail metrics associated with the host. I\u0026rsquo;m showing CPU as an example below.\nFrom the farm, you can drill down to the sessions.\nAs you can expect, selecting a session shows you the host performance over time. You also get the usual raw detail metrics associated with the session.\nVDI Performance The VDI dashboard has the same design with RDS. The main difference lies in the counters.\nAs you can expect, you have the same layout. It begins with a list of VDI Pools.\nFrom one of the pools, you can drill down to the session. From the session, you can drill down to the vSphere VM where the session is running.\nFor VDI, there are 2 sets of status counters. One for the agent, and one for the VM.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-9---other-dashboards/3.9.5-vsan-file-services/",
      "title": "5. vSAN File Services",
      "tags": [],
      "description": "",
      "content": "The vSAN File Services Dashboard helps VMware administrator monitor the file services running in their vSAN environment.\nThis dashboard is designed to complement the vSAN file services management provided by vCenter Server. It does not duplicate information already provided, and each tool has their purpose. vCenter is more of an administrative tool, while vRealize Operations is more of an operations tool.\nHow to Use Review the \u0026ldquo;File Shares by Used Space and Latency\u0026rdquo; heat map\nIt shows all the file shares in your environment.\nThe greater the usage (consumption), the greater the box, so you can easily see the most consumed ones.\nThey are colored by latency. Pay attention to the box with red color.\nReview the \u0026ldquo;vSAN Clusters with File Services enabled\u0026rdquo; table\nIt lists all the vSAN clusters with file services enabled, giving a convenient view to see which clusters have these settings turned on. Select a vSAN cluster from the table\nThe file servers in the selected vSAN cluster will be automatically shown. Selecting a file server will filter the file shares list to only show the file shares in the selected file server.\nThe file shares in the selected vSAN cluster will be automatically shown. Selecting a file share will display all the relevant KPI on the file share.\nPoints to Note vSAN File Servers and vSAN File Shares are 2 new objects in vRealize Operations vSAN management pack.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.5-network-configuration/",
      "title": "5. Network Configuration",
      "tags": [],
      "description": "",
      "content": "Use the Network Configuration dashboard to view the overall configuration of vSphere distributed switch in your environment, especially for the areas that need attention.\nThe dashboard is designed with the same considerations that are common among all the configuration management dashboards.\nHow to Use The dashboard is organized into 2 sections for ease of use.\nThe first section displays network configurations that needs your attention\nThere are 5 bar charts that focuses on critical security settings. The last bar chat shows the version of the vSphere Distribution Switch. Aim to keep the version current, or matching your vSphere version. The second section provides overall configuration, with ability to drill down into a particular switch\nStart by selecting a switch from the list. The ESXi Hosts, port groups and VMs on the switch will automatically be shown. Review each of the tables. For the ESXi Host table, ensure their settings are consistent. Some of the columns are color coded to facilitate quick reviews. Adjust their threshold to either reflect your current situation or your desired ideal state. You can sort the columns and export the result into spreadsheet for further analysis. Points to Note For a more complete visibility, consider adding physical network device monitoring by using the appropriate management pack. More info here.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/3.3.5-vsan-capacity/",
      "title": "5. vSAN Capacity",
      "tags": [],
      "description": "",
      "content": "The vSAN Capacity dashboard complements the vSphere Cluster Capacity dashboard by showing vSAN related capacity. To manage vSAN capacity, use both dashboards.\nAs this dashboard is designed to complement the vSphere Cluster Capacity dashboard, it shares the same design consideration. It focuses on the storage and vSAN specific metrics, and does not repeat what\u0026rsquo;s already covered. It does not list non vSAN cluster.\nSee the Capacity Dashboards page for common design consideration among all the dashboards for capacity management.\nHow to Use The dashboard is layered, gradually providing details as you work top down in the dashboard.\nThe first layer shows 2 distribution charts\nBar charts summarize the clusters based on capacity remaining and time remaining. Just because you are running low on capacity does not mean you are running out of time. The two bar charts work together. The ideal situation is low Capacity Remaining and high Time Remaining. This means your resources are cost effective and working as expected. The second layer shows a heat map\nThe three heat maps are Time Remaining, Capacity Remaining, and VM Remaining. The cluster size has been made constant for ease of use. If your cluster sizes are not standardized, consider using the number of ESXi hosts to show the size difference. The third layer shows a table, accompanied by other widgets to show details of selected cluster\nClusters Capacity List. If any cluster needs attention, then select the cluster to view the related details. Points to Note If you find it useful, add a drill-down to the ESXi Capacity dashboard. A logical place to initiate this drill down is in the vSAN Cluster List widget. Link this widget into the table of ESXi Host in the destination dashboard.\nThis release addresses the discrepancy between capacity values for vSAN Datastore and vSAN Cluster objects. Prior to it, the vSAN Cluster deduped \u0026amp; compressed overhead was not considered.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.5-esxi-utilization/",
      "title": "5. ESXi Utilization",
      "tags": [],
      "description": "",
      "content": "The ESXi Utilization dashboard complements the ESXi Contention dashboard. Together, their goal is to help VMware Administrator in performance management.\nUse this dashboard to identify vSphere clusters with high utilization in a selected data center. When utilization exceeds 100%, performance can be negatively impacted especially when VM experience contention. By default, vRealize Operations has a 5-minute collection interval. For 5 minutes, there may be 300 seconds worth of data points. If a spike is experienced for a few seconds, it may not be visible if the remaining of the 300 seconds is low utilization.\nThe dashboard is designed to complement the Cluster Utilization dashboard, by providing the next level of details. Hence it has a very similar layout.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nHow to Use Review the ESXi Hosts Utilization table\nIt lists all the ESXi hosts, sorted by the highest utilization in the last 1 week. If the table is all showing green, then there is no need to analyze further. You can change the time period to the period of your interest. The maximum number will be reflected accordingly. Select an ESXi Host from the table\nAll the utilization charts will automatically show the key utilization metrics of selected cluster. For memory, the high utilization counters are explicitly shown. Balloon, Compressed, Swapped. Notice they exist even though utilization is not even 90%, indicating high pressure in the past. If you look at only utilization, you\u0026rsquo;d think You are safe! For memory, both Consumed and Active are shown. If active is low, no need to upgrade RAM as Consumed contains disk cache. For me, it\u0026rsquo;s fine for Consumed to be 95% so long RAM Contention is 0. The disk IOPS and the disk throughput are split into read \u0026amp; write to gain insight into the behaviour. Some workload is read oriented, while others are write oriented. The network throughput is split into sent (transmit) and received to gain insight into the behaviour. Plus, the total usage can be misleading because it sums send and received traffic. In reality the network pipe is 1x for each direction (due to the full duplex nature of ethernet), not 2x shared by both. Points to Note If your operations team have some forms of standard that utilization should not exceed certain threshold, you can add the threshold into the line chart. The threshold line will help less technical team as they can see how the real value compares with the threshold. See the Points to Note section of ESXi Contention dashboard as this dashboard is designed to complement it. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.5-color-as-meaning/",
      "title": "5. Color as Meaning",
      "tags": [],
      "description": "",
      "content": "It\u0026rsquo;s easier to see color than read numbers, if the color has meaning. There are many occasions in operations that you just need to know if things are good or bad first, before diving into the actual raw value. Color is also easier at a glance, especially if you have read hundreds of numbers inside a large table.\nHere is the color I recommend:\nGreen -\u0026gt; Yellow -\u0026gt; Orange -\u0026gt; Red Green means good, and gradually getting worse as it moves toward red.\nTypically used in performance monitoring and compliance.\nDark Grey -\u0026gt; Green -\u0026gt; Red We use dark grey in Capacity as wastage (unused) is a bigger issue than over utilization. It\u0026rsquo;s critical to show wastage as it can also impact performance.\nFor performance dashboard, you should consider using red to convey that oversized is bad for performance.\nBlue Neutral color. Used when it does not have any meaning.\nGrey Typically happens in heat map. We use a color instead of white as white is hard to read.\nIn the Compliance dashboard below, color is used to quickly show the various level of compliance. If all you see is Green, there is no need to look at the numbers \u0026amp; texts!\nLast but not least, think of users who may not be able to distinguish all the colors. Provide alternative way for them so the functionality is not lost.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-6---other-metrics/2.6.5-miscellaneous/",
      "title": "5. Miscellaneous",
      "tags": [],
      "description": "",
      "content": "vSphere Data Center he use case for higher level objects, such as Data center, Custom DC, vCenter and World need to reflect the nature of the object. The complex nature of the object needs to be accounted for. For example, a vCenter Data center object may span across physical data centers. This comes from the limitation that a stretched cluster is not a child of 2 separate data center objects, even when the clusters are physically in 2 separate buildings.\nLarge objects such as vCenter also tend to host clusters that serves different purpose, and hence are not compatible with one another. A free capacity on the NSX Edge cluster may not mean the business VM can be deployed, due to different storage, security, and network requirements.\nThese also apply to vRealize Custom Data Center, vCenter and World objects.\nMemory Utilization (KB) Memory utilization level based on descendant VMs utilization. Includes reservations, limits and overhead to run VMs Sum ([HostSystem]Memory|Utilization) Total Capacity (KB) Amount of physical memory configured on descendant ESXi hosts Sum ([HostSystem]Memory|Total Capacity) Usable Capacity (KB) Amount of usable memory resources for VMs after considering reservations for vSphere High Availability (HA) and other vSphere Services. Sum ([Cluster]Memory|Usable Capacity) Workload (%) [(Memory|Machine Demand + Memory|ESX System usage) / Memory|Usable Capacity] * 100 Disk Space Utilization (GB) Storage space utilized on connected vSphere Datastores Sum ([Datastore]Disk Space|Utilization) Total Capacity (GB) Total Storage space available on connected vSphere Datastores Sum ([Datastore]Disk Space|Total Capacity) Workload (%) [(Disk Space|Utilization)/(Disk Space|Total Capacity)] * 100 CPU Demand (MHz) CPU utilization level based on descendant VMs utilization. Includes reservations, limits and overhead to run VMs Sum ([HostSystem]CPU|Demand) Total Capacity (MHz) Amount of CPU resources configured on descendant ESXi hosts Sum ([HostSystem]CPU|Total Capacity) Usable Capacity (MHz) Amount of usable CPU resources for VMs after considering reservations for vSphere High Availability (HA) and other vSphere Services. Sum ([Cluster]CPU|Usable Capacity) Overhead (MHz) Sum ([HostSystem]CPU|Overhead) Demand without overhead (MHz) Sum ([HostSystem]CPU|Demand without Overhead) Workload (%) [(CPU|Demand without overhead + CPU|Overhead) / CPU|Usable Capacity] * 100 Other Metrics Maximum number of VMsThe supported configuration maximum as stated in vSphere Configuration website. This number tends to be very high relative to typical deployment.\nThe metrics exist for vSphere, vCenter Data Center, vSphere Cluster, ESXi Host, Datastore and vRealize Operations Custom Data Center object\nNumber of Hosts * Maximum number of VMs per ESXi Host\rMetric and Property Changes One popular request among customers is we simplify our metrics and properties to improve both scalability and usability. You notice that some metrics are marked for deprecation:\nvRealize Operations 8.3 vRealize Operations 8.2 We disable some instanced metrics here. You can enable them back. vRealize Operations 8.1 vRealize Operations 8.0 vRealize Operations 7.5 vRealize Operations 7.0 Metrics and Properties can be deprecated or disabled for the following reasons:\nThey are rarely used and hence have been disabled. If you plan to use them, you can enable them. They are duplicates. The replacement metric are provided. They are not the right indicator of performance or capacity issues. We have provided replacement metrics and guidance on how you should interpret the results. More details here.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-5---network-metrics/2.5.5-esxi-host/",
      "title": "5. ESXi Host",
      "tags": [],
      "description": "",
      "content": "vCenter provides three additional counters at the host level. It can track Packet receive errors, Packet transmit errors, and Unknown protocol frames. The counters are provided at either host level or vmnic level. They are not provided at the switch or port group level. This means you cannot gauge the performance at the port group level or switch level easily using vCenter.\nJust like vCenter, vRealize Operations also does not provide the counters at the Standard Switch or port group level. This means you cannot aggregate or analyze the data from these network objects point of view. This is one reason why you should use Distributed Switch. It simply has a much richer monitoring capability.\nUsage, Data Received Rate, and Data Transmit Rate are all available at the host level and at the individual NIC level.\nYou should expect the value for packet loss and unknown packet frames to be 0. A packet is considered unknown if ESXi is unable to decode it and hence does not know what type of packet it is. Discuss with your network admin if you are seeing either a dropped packet or an unknown packet.\nPackets loss and Unknown packet frames counters are available at the host level and individual NIC level.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-4---storage-metrics/2.4.5-vsan/",
      "title": "5. vSAN",
      "tags": [],
      "description": "",
      "content": "Performance Monitoring While vSAN provide storage service, it requires network to deliver that. So we need to look at both storage and network in analysis. vSAN is basically a collection of ESXi Hosts, so we need to consider compute metrics also.\nA large vSAN cluster can have many components. Each of these components can have multiple performance metrics. The total number of KPI can reach hundreds of metrics. Take the following example, which is a 10 node cluster.\nHere are some of the questions you want to ask in day-to-day operations:\nIs any of the ESXi hosts in the cluster running high CPU utilization? Is any of the ESXi hosts running high Memory utilization? Is any of the NIC cards in any of the ESXi hosts running high utilization? In the above example, with 4 NIC cards per ESXi, you have 40 TX + 40 RX metrics. Is the vSAN VMkernel network on any of the ESXi hosts congested? Is the Read Cache on any of the Disk Grups sufficient? If you have a lot of cache miss, it can impact performance. Is the Write Buffer on any of the Disk Grups sufficient? Is the Cache Tier performing fast? Each disk has 4 metrics: Read Cache Read Latency, Read Cache Write Latency, Write Buffer Write Latency, Write Buffer Read Latency. Since there are 20 disks, you need to check 80 counters Are the Capacity Disks performing fast? Check both Read and Write latency as they typically have different results. In our example above, there are 120 x 2 = 240 counters. Is any of the Disk Groups running low on space? Is any of the Disk Groups facing congestion? You want to check both the max and count the number of occurrences \u0026gt; 60. Is there outstanding IO on any of the Disk Group? If you add them up, you are looking at 530 metrics for this vSAN cluster. And that\u0026rsquo;s just 1 point in time. It will be difficult to show hundreds of datapoint on a screen, even if you can color code them all. We need a way to zoom in on the early warning.\nThe above is just a point in time. What if you want to see the trend over time? In 1 month you are looking at 530 x 8766 = 4.6+ millions data points. And that\u0026rsquo;s just 1 cluster. So there is a need for a better technique.\nvRealize Operations use the formula Min(), Max(), and Count() to pick the early warning. This was covered earlier in this section. It combines the key metrics into a set of KPI. With these vSAN KPIs, you only have 12 metrics to check instead of 530, without losing any insight. In fact, you get better early warning, as we hide the average. Early Warning is critical as buying hardware is more than a trip to local DIY hardware store.\nThe following tables show the KPIs and their formula.\nFrom the above, we need to reduce it to a single metric so we can report many vSAN clusters. The following diagram shows why.\nIf you want to crack the vSAN KPI, reach out to me.\nPerformance Troubleshooting The above KPI metrics are good enough for monitoring. It tells you if there is a problem. To know what\u0026rsquo;s causing the problem, you need to dig deeper. The first step is to recognise that there are two broad layers: VM layer and backend layer.\nI\u0026rsquo;ve put the two screens side by side for ease of comparison. What do you notice?\nJust like other storage subsystems, you will expect the latency \u0026amp; outstanding IO at the backend layer to be lower. This is because it\u0026rsquo;s a subset of the entire path taken by the IO command of the VM.\nLet\u0026rsquo;s dive deeper to peel the layer. The following diagram shows the key components and how the latency counters are measured. It visualizes the hardware and software component using different box style.\nSoftware: VM, vSAN software and Network kernel loadable module Hardware: IO Controller Card, Cache Disk, Capacity Disk, and Network Card The white arrows show a single Write command, and the yellow arrow show a single read command. Both have double arrows to show the acknowledgement when the command has been completed.\nThe write request is written to the cache disk, and acknowledged. The destaging to capacity disk is done post acknowledgement, hence it\u0026rsquo;s not part of the VM disk latency. In this example, we are showing that the writing happens to be on local ESXi host. The read request is shown as remote so we can cover both local and remote scenarios. Notice the read does not touch the local IO Controller Card. It goes into the network subsystem, which drives the physical network card. On the destination host, the vSAN software will first read from the cache. If there is a miss, it will read from the capacity disk. Other Metrics The Percentage of VM with disk latency metric on vSAN datastore object will not include virtual disks not residing on the vSAN datastore. It only gets from vSAN datastores. Example:\nVM 1 has 2 virtual disks, one on vSAN, one of RDM LUN VM 2 has 2 virtual disks, one on vSAN, one of VMFS datastore In the above example, the formula will ignore the latency from the virtual disks on RDM LUN and VMFS datastore.\nIn the What If scenario:\nGuest File System | Utilization is the metric used to determine VM consumption (without the vSAN overhead due to FTT) "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-3---memory-metrics/2.3.5-esxi-host/",
      "title": "5. ESXi Host",
      "tags": [],
      "description": "",
      "content": "vCenter provides even more counters at ESXi level: 38 counters for RAM plus 11 for VMkernel RAM. VMkernel has around 50 processes that are tracked. As a result, a cluster of 8 ESXi can have \u0026gt; 800 counters just for ESXi RAM! Most of them are not shown as a percentage, making it difficult to compare across ESXi with different memory sizes.\nThe following shows all the metrics. I had to stitch multiple screenshots so you can see them in one view.\nWhich counters are for performance?\nWhich counters are for capacity?\nTotal = VMkernel + VM + Overhead + Free, where:\nTotal is the hardware memory as reported by BIOS to ESXi VMkernel is the memory used by VMkernel and its loadable modules such as vSAN VM is the memory used by VM Overhead is the hypervisor virtualization overhead on each VM. Just like any other modern-day OS, VMkernel uses RAM as cache as it\u0026rsquo;s faster than disk. So the Consumed counter will be near 100% in overcommit environment. This is a healthy utilization.\nJust because the host is low on free physical RAM does not mean that the VMs are performing poorly. Even the presence of swapping out does not mean VMs are performing poorly when the swapped memory is not being accessed by the OS. Poor VM performance only happens when the VM experiences contention.\nBalloon Threshold Balloon is a leading indicator that an ESXi is under memory pressure, hence it\u0026rsquo;s one of the primary counters you should use in capacity. Assuming you\u0026rsquo;re not using Limit to artificially cap the resource, you should ensure that the balloon amount does not cause VM to experience contention.\nWe know that contention happens at hypervisor level, not at VM level. The VM is feeling the side effects of the contention, and the degree of contention depends on each VM\u0026rsquo;s shares, reservation and utilization. ESXi begins taking action if it is running low on free memory. This is tracked by a counter called State. The State counter has five states, corresponding to the Free Memory Minimum (%) value\nESXi StateThreshold1 TB ESXiExample based on ESXi with 1 TB RAMHigh300%32.4 GBFirst, we calculate the Free Memory Minimum value. There is many website to help you with this, such as this.\nFor 1 TB, the value is 10.8 GB.\nClear100%10.8 GBSoft64%6.9 GB. Balloon starts hereHard32%3.5 GB. Compress/Swap starts hereLow16%1.7 GB. Block execution\rUsing the example above, let\u0026rsquo;s see at which point of utilization does ESXi triggers balloon process.\nESXi State 512 GB ESXi 1 TB ESXi 1.5 TB ESXi Balloon Threshold 3.7 GB 6.9 GB 10.2 GB Threshold 508.3 GB 0.99 TB 1.49 TB Threshold in % 99.3% 99.3% 99.3% As you can see from all the 3 ESXi, balloon only happens after at least 99% of the memory it utilized. It\u0026rsquo;s a very high threshold. Unless you are deliberately aiming for high utilization, all the ESXi should be in the high state.\nIn addition, the spare host you add to cater for HA or maintenance mode will help in lowering the overall ESXi utilization. Let\u0026rsquo;s use example to illustrate\nNo of ESXi in a cluster = 12 Provisioned for HA = 11 Target ESXi memory utilization = 99% (when HA happens or planned maintenance) Target ESXi memory utilization = 99% x 11 / 12 = 90.75% (during normal operations) Using the above, you will not have any VM memory swapped as you won\u0026rsquo;t even hit the ballooned stage. If you actually see balloon, that means there is limit imposed.\nThe Low Free Threshold (KB) counter provides information on the actual level below which ESXi will begin reclaiming memory from VM. This value varies in hosts with different RAM configurations. Check this value only if you suspect ESXi triggers ballooning too early.\nESXi memory region can be divided into three: Used, Cached and Free\nUsed is tracked by Active. Active is an estimate of recently touched pages. Cached = Consumed - Active. Consumed contains pages that were touched in the past, but no longer active. I\u0026rsquo;m not sure Ballooned pages are accounted in Consumed, although logically it should not. It should go to Free so it can be reused. Free = Total Capacity - Consumed. The nature of memory as cache means the active part is far lower than the non-active part. It\u0026rsquo;s also more volatile. The following shows an ESXi with low memory usage, both active and consumed, in the last 3 months.\nLet\u0026rsquo;s look at an opposite scenario. The following ESXi is running at 100%. It has granted more memory than what it physically has. Initially, since the pages are inactive, there is no ballooning. When the active rise up, the consumed counter goes up and the balloon process kicks in. When the VM is no longer using the pages, the active counter reflects that and ESXi begin deflating the balloon and giving the pages back.\nI shared in the VM memory counter that just because a VM has balloon, does not mean it experiences contention. You can see the same situation at ESXi level. The following ESXi shows a constant and significant balloon lasting at least 7 days. Yes the worst contention experienced by any VM is not even 1%, and majority of its 19 VMs were not experiencing contention at all.\nKey Metrics vCenter provides Active (KB), Active write (KB), Consumed (KB), Granted (KB), and Usage (%) for utilization counters. Consumed is the amount of memory used on the host. It includes both VM memory and hypervisor memory. In other words, Consumed = Total host memory - Free host memory.\nConsumed includes the VMkernel consumed, not just the VM consumed. The following example shows ESXi hosts with no running VM, so the Consumed counter is mostly made up of VMkernel. From the table, you can see that Consumed = VMkernel Consumed + Granted.\nI\u0026rsquo;ve sorted them by the Granted counter, as I\u0026rsquo;m not expecting it to have any values. Granted at the host is the total of the granted counters of VMs running on the host, so it should be 0 in this case. It includes the shared memory. My guess the extra memory is for non-VM user world process.\nLet\u0026rsquo;s take one of the ESXi to see the value over time. This time around, let\u0026rsquo;s use vCenter instead.\nYou can verify that ESXi Consumed includes its running VMs Consumes by taking an ESXi with a single running VM. The ESXi below has 255 GB of total capacity but only 229 GB is consumed. The 229 GB is split into 191 GB consumed by VM and 36 GB consumed by VMkernel.\nThe VMkernel consumption is the sum of the following three resource pools.\nMemory shared is the sum of all the VM memory pages that are pointing to a shared page. Memory shared common is the sum of all the shared pages. As a result, Memory shared common is at most half the value of Memory shared, as sharing means at least two blocks are pointing to the shared page. If the value is a lot less than half, then you are saving a lot. Today\u0026rsquo;s ESXi hosts are sporting the hardware-assisted memory virtualization from Intel or AMD. With this technology, VMkernel uses large pages to back the VM memory. As a result, the possibility of shared memory is low, unless the host memory is highly utilized. In this state, the large pages are broken down into small, shareable pages. So you can also use the Memory shared common counter to track for signs of host memory under pressure.\nThe Heap counter shows the memory used by VMkernel heap and other data. This is normally a constant and small value.\nDemand, especially unmet Demand, is hard to measure as RAM is a form of storage. RAM does not have Ready or CoStop concept, as it\u0026rsquo;s a disk space. ESXi uses 3 levels to manage demand:\nTPS: this happens automatically even if ESXi has plenty of RAM as it makes sense to do so. It\u0026rsquo;s not an indicative of unmet demand. Sharing the same page is the right thing to do, and not something that should be started only when physical pages are running low. Balloon: this is the first sign of unmet demand. It happens proactively, before ESXi is unable to meet Demand. Ballooning reduces cache. It does not mean ESXi unable to meet Demand. Demand is not met when Contention happen. That\u0026rsquo;s the only time it is not met. Compress/Swap: this happens proactively too. It does not mean VMs were contending for RAM. It merely means ESXi Consumed is very high. That Consumed can contain a lot of cache. Demand = Consumed + Balloon + Compression + Swap\nReserved Capacity (MB) only counts reservation. Therefore, the value will be a lot lower than Total capacity if you do not use reservation. Note that it does not includes memory reserved by VMkernel, which varies from 2 GB to 64 GB. The following shows an ESXi with vSAN. This box has 1.5 TB RAM, and VMkernel usage is steady at 55 GB for at least 6 months. Reservation is very low at 1.4 GB, but it\u0026rsquo;s also steady.\nESXi Reserved = the amount of machine memory that is currently reserved. It is the sum of reservation setting of the groups + the overhead reservation of the groups + minfree metric.\nManaged = the total amount of machine memory managed by VMKernel. VMKernel \u0026ldquo;managed\u0026rdquo; memory can be dynamically allocated for VM, VMKernel, and User Worlds.\nCounters Description Shared Sum of VM Shared + VMkernel Shared\nIf two VMs each have 500 MB of identical memory, the shared memory is 1 GB. Shared Common Machine memory (host memory) savings (KB) - Shared Swap In Swap In Rate Swap Out Swap Out Rate Swap Used Sum of memory swapped of all powered on VMs and vSphere services on the host. Usage / Usable (%) Memory Consumed by VMs / memory provisioned * 100%\nIt does not include memory overhead, while consumed (%) does. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-1---overview/2.1.5-esxtop/",
      "title": "5. ESXTOP",
      "tags": [],
      "description": "",
      "content": "I learned about counters from esxtop and vRealize Operations. For me, esxtop provides the raw metrics, and insight into how ESXi does accounting. In esxtop you get to see how physical (ESXi) and virtual (world) are accounted differently. There are many great materials on esxtop, especially from Valentin Bondzio, where he explains the counters in depth.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-6---compliance-management/1.6.5-regulatory-benchmarks/",
      "title": "5. Regulatory Benchmarks",
      "tags": [],
      "description": "",
      "content": "Let\u0026rsquo;s talk about out-of-box regulatory benchmarks. As mentioned earlier, vRealize Operations provides the following mentioned benchmarks:\nCenter for Internet Security (CIS) security standards Defense Information Systems Agency (DISA) security standards Federal Information Security Management Act (FISMA) security standards Health Insurance Portability and Accountability Act 1996 (HIPAA) Compliance ISO security standards Payment Card Industry (PCI) security standards One interesting point to note, all of these benchmarks apply and work on the same set of objects, mostly vCenter, ESXi, VMs, Distributed Port Groups and Distributed Virtual Switch. You may ask if they work on the same environment with a similar security setting, then how are they different?\nThese regulatory benchmarks are developed and certified by regulatory authorities aiming for specific use cases. Assume an ESXi host has 100 configurations to make. One of the benchmarks may need 60 of them to be configured, another may need another combination of 60 requirements. For example, assume one benchmark only requires the \u0026ldquo;root\u0026rdquo; password needs to be set with an expiry time. But another requires password complexity needs to be also set as per defined criteria.\nYou can apply all of the suggestions from all of the benchmarks and comply to all of them. The purpose of the compliance check is to certify to a regulatory benchmark so that everyone can be sure that the requirements are met. Without the compliance and certification only word of mouth needs to be trusted. The compliance to the benchmark provides the trust and authenticity.\nCIS Security Standards Center for Internet Security (CIS) Controls and CIS Benchmarks provide global standards for internet security and are a recognized global standard for securing IT systems and data against attacks. vRealize Operations provides Alerts, Policies, and Reports to validate the vSphere resources against the CIS hardening guide1. The following resources are validated using this content:\nESXi Host VM The CIS standards provides two different areas of suggestions, manual and automated. The following are examples of configuration checked by CIS Security Standards that can be automated:\nEnsure the default value of individual salt per VM is configured. By default, salting is enabled (Mem.ShareForceSalting = 2) and each VM has a different salt. This means page sharing does not occur across the VMs (inter VM TPS) and only happens inside a VM (intra VM). Ensure NTP time synchronization is configured properly. Ensure the ESXi host firewall is configured to restrict access to services running on the host. Ensure Managed Object Browser (MOB) is disabled: The MOB is meant to be used primarily for debugging the vSphere SDK. Because there are no access controls, the MOB could also be used as a method to obtain information about a host being targeted for unauthorized access. Ensure default self-signed certificate for ESXi communication is not used. Ensure SNMP is configured properly: If SNMP is not properly configured, monitoring data containing sensitive information can be sent to a malicious host and used to help exploit the host. Ensure dvfilter API is not configured if not used: If the dvfilter network API is enabled in the future and it is already configured, an attacker might attempt to connect a VM to it, thereby potentially providing access to the network of other VMs on the host. Ensure vSphere Authentication Proxy is used when adding hosts to Active Directory: If you configure your host to join an Active Directory domain using Host Profiles the Active Directory credentials are saved in the host profile and are transmitted over the network. To avoid having to save Active Directory credentials in the Host Profile and to avoid transmitting Active Directory credentials over the network use the vSphere Authentication Proxy. Ensure VDS health check is disabled: vSphere Distributed switch health check once enabled, collects packets that contain information on host#, vds# port#, which an attacker would find useful. There are many more such checks performed by CIS Security Standards, for a detailed list download the benchmark from their website.\nDISA Security Standards DISA is a part of the Department of Defense (DoD), and is a combat support agency. Failure to stay compliant with guidelines issued by DISA can result in an organization being denied access to DoD networks. This compliance pack validates the compliance of the following resources:\nvCenter ESXi Host VM Distributed Port Group Distributed Virtual Switch Source: VMware Marketplace\nFISMA Security Standards FISMA is United States legislation that defines a comprehensive framework to protect government information, operations and assets against natural or man-made threats. This compliance pack validates the compliance of the following resources:\nvCenter ESXi Host VM Distributed Port Group Distributed Virtual Switch Source: VMware Marketplace\nHIPAA Compliance HIPAA provides data privacy and security provisions for safeguarding medical information. The vRealize Operations Compliance Pack for HIPAA extends the SDDC compliance capabilities of vRealize Operations. This compliance pack validates the compliance of the following resources:\nvCenter ESXi Host VM Distributed Port Group Distributed Virtual Switch Source: VMware Marketplace\nISO Security Standards ISO/IEC 27001 is the best-known standard in the ISO/IEC 27000 family of standards providing requirements for an information security management system (ISMS). This compliance pack validates the compliance of the following resources:\nvCenter ESXi Host VM Distributed Port Group Distributed Virtual Switch Source: VMware Marketplace\nPCI Security Standards The PCI security standards hardening guide addresses the growing threat to consumer payment information. PCI is important to companies that accept, process, or receive payments to prevent, detect and respond to cyber-attacks that can lead to breaches. This compliance pack validates the compliance of the following resources:\nvCenter ESXi Host VM Distributed Port Group Distributed Virtual Switch Source: VMware Marketplace\nSource: VMware Marketplace\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.5-allocation-model/",
      "title": "5. Allocation Model",
      "tags": [],
      "description": "",
      "content": "The allocation model is not enabled by default as the overcommit ratio varies among customers. You should configure it appropriately to account for all the types of demand that is relevant for that cluster. By using both, you can account for both inputs (real demand and unreal demand).\nThe next use case for allocation is showback and reporting. There are typically restrictions such as contractual obligations or SLAs that mandate capacity not be overcommitted beyond an agreed upon ratio. Note these restrictions are usually non-technical.\nSome customers like to do procurement planning based on overcommit ratios. A comfortable overcommit ratio is determined, and that\u0026rsquo;s what is used to project utilization into the future. The overcommit ratio is intended to be a rough estimate of utilization, e.g. 4:1 CPU overcommit ratio means that on average each vCPU will only run 25% utilization.\nThe allocation model has 3 main limitations:\nVM Size VM size is not considered in the overcommit ratio. It assumes that scheduling two monster VMs is as easy as scheduling many small VMs. The ESXi scheduler can juggle more small VMs than a few large ones, especially if they peak at different times.\nOver-provisioned VM It is common to have over-provisioned VM issue, especially among the large VMs. It is hard to solve this in production environment as it will involve downtime and the burden is on you to prove it will not have performance impact. Politically, it may make the team who sized the VM and justified the cost look bad. Your best bet is to prevent the problem from happening in the first place, by using progressive pricing. This is covered in the Pricing section of the book.\nIaaS Workload IaaS workload that do not take the shape of VM is not considered. VMkernel, vSAN, NSX, vSphere Replication, and vMotion all need to be considered. On the other hand, Agent VM is included as it takes the shape of a VM, although it tends to use local datastore.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.5-performance-vs-capacity/",
      "title": "5. Performance vs Capacity",
      "tags": [],
      "description": "",
      "content": "The relationship between capacity and performance varies depending on the object. Consumer objects (e.g. VM, K8S Pod) have different natures than provider objects (e.g. vSphere Cluster, vSAN Cluster). For provider objects, performance is always bottom up. You start with the VM running inside in the provider object, and then aggregate the metrics. Capacity is always top down. You look at the big picture first, then drill down. For example, you start with the vSphere cluster, then drill down to ESXi.\nFor an IaaS provider, the following tables explains how performance and capacity differ.\nCapacity has HA, Buffer, Overhead and Reservation. None of these are relevant to performance monitoring. In Performance, you don\u0026rsquo;t care about them, as performance is about reality (what actually happens). They may cause performance problem, but they are not considered in the performance metric.\nThe confusion on performance and capacity lies in utilization. They share the same raw counter but use it differently. Performance will be absolute (real value), Capacity will be relative (it depends on settings). The following table below shows how utilization is used differently.\nTake for example, the ESXi Memory Consumed, which is the primary utilization counter for ESXi.\nFrom performance monitoring, 100% consumed is not only good, it\u0026rsquo;s perfect. You are maximising your cache. So long as there is no ballooning and contention, this is exactly what you want. From capacity monitoring, 100% consumed is not good, as that means there is no more remaining capacity left. You need to stop provisioning new loads and start the process of buying new hardware. Also, 100% is measured to usable capacity after deducting HA and buffer. It\u0026rsquo;s not measured against the absolute physical capacity. Let\u0026rsquo;s take an example to see how contention and utilization differs. The following is using a cluster object as the example. There are two counters, each expressed in percentage.\nYou want your utilization to be as high as possible, as you\u0026rsquo;ve paid for the hardware already. So, you start from 0% but want to move up as far as possible.\nYou want your performance to stay at 100%. You don\u0026rsquo;t want it to move down far. In fact, 10% degradation can be significant as that can mean 10% of the VM population is affected. In a large cluster with 2000 VMs, that can mean 200 VMs.\nPerformance depends on the class of service. A Gold cluster may have identical hardware with a Bronze cluster, but the VMs running on Gold cluster face less contention, hence they perform better.\nLet\u0026rsquo;s see the above in real life. Here is a cluster experiencing regular high utilization in the last 7 days. You can clearly see the peak. The cluster has 14 ESXi Hosts.\nA logical question here would be what\u0026rsquo;s the impact on VM performance? Are they getting the CPU they asked? The cluster has 550 running VM.\nThis is where the contention counters come in. One tracks the depth of the problem, the other the breadth of the problem.\nThe counter Percentage of VMs facing CPU Ready \u0026gt; 1% shows a nearly identical pattern. We can see that a big percentage of the VM population is affected.\nThe second counter tracks the depth, giving the absolute worst CPU Ready value experienced by any VM in the cluster.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-5---log-insight/",
      "title": "Chapter 5 - Log Insight",
      "tags": [],
      "description": "",
      "content": "Chapter 5 Log Insight There are many useful information that only exists in the logs. They don\u0026rsquo;t surface as alerts, metrics or events. The information is not limited to just security and compliance. They cover availability and performance too. In this chapter, we will share a few practical use cases.\n1. vSphere\r2. vRealize Operations\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/",
      "title": "Dashboards",
      "tags": [],
      "description": "",
      "content": "This last part covers the dashboard. Among these 3 parts, this will be the one that changes the most from each vRealize Operations release.\nIn future, we should add Reports and Alerts, as the three are essentially the way vRealize Operations communicates to users. Keen to take on the challenge?\nChapter 1 - Design Considerations\rChapter 2 - Performance Dashboards\rChapter 3 - Capacity Dashboards\rChapter 4 - Configuration Dashboards\rChapter 5 - Availability Dashboards\rChapter 6 - NOC Dashboards\rChapter 7 - Executive Summary Dashboards\rChapter 8 - True Visibility Suite Dashboards\rChapter 9 - Other Dashboards\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.6-capacity/",
      "title": "6. Capacity",
      "tags": [],
      "description": "",
      "content": "\rThis page is still in draft.\nHorizon consists of different components, each having their own capacity model. Not all components have capacity need, meaning you do not need to do capacity planning and adjustment.\nCapacity User Requirements:\nHow much resources do the users need? Focus on CPU and Memory. Disk Space is simple. Network is done at RDS Farm or VDI Pool level.\nA user can have \u0026gt;1 sessions. He uses 2 desktops due to application licensing or security policy. He could be oversized on Pool 1 and oversized on Pool 2. This means the sizing has to be done per pool or farm.\nWe do not size the sessions. We size the users instead. Outputs\nCPU (GHz), RAM (GB) per pool or farm. RDS Farm Requirements\nThere are 2 main requirements: internal and external.\nInternally, we need to know utilization of the RDS hosts and decide if the RDS Farm is full. Your initial sizing is only a guide. If you undersize then this calculation will prevent you from supporting more than what the farm can actuall support. If you oversize, then this calculation will give you confidence to push beyond your plan. Regardless, you then need to update your plan.\nExternally, the RDS Farm runs on a vSphere cluster. To add more hosts, you need to know if the underlying cluster is able to support it. This cluster could be a shared cluster, so there are other pools or farms there. Outputs\nNo. of RDS Sessions remaining within the farm.\nNo. of RDS Hosts that can be added in the parent cluster. VDI Pool Requirements\nInternally, there is no requirement as it’s a simple allocation model. The data provided by Horizon is good enough.\nExternally, it’s similar to RDS Farm. Output\nNo. of VDI VM that can be added in the parent cluster.\nApplication Requirements\nHow much resources do the application need? Focus on CPU and Memory. Disk Space is simple. Network is covered by the Horizon protocol. Output\nCPU (GHz) and RAM (GB) There is no capacity required for the following objects:\nNo capacity required Pod It’s just a folder or container of farms and pools. The pools/farms may not be interchangeable so you can’t roll them up. In a large environment with hundreds of farms and pools, you can use distribution chart to quickly show the farms and pools that are running low on capacity. Site See Pod. Cloud Pod See Pod. RDS Host Capacity is done at RDS Farm. If the host runs out of capacity, you don’t increase the size of the host, rather you add more hosts. The host size is a design decision. Horizon Servers Connection Servers, UAG, App Vol. They are designed with fixed size. If not enough, add more instance. Users Sizing what a user needs is challenging as each users work differently. Corporate office hours do not apply as users may even work on the weekends.\nRDS Farm Number of Sessions Remaining VDI Pool has Utilization (GHz), which is the total utilization not average.\nTotal - Unavailable - Bad State = Usable Capacity\nUnavailable (nothing wrong. Intentional or will fix by itself) = Provisioned + In progress + Provisioning + Customizing + Deleting + Waiting for Agent + Maintenance mode + Startup + Agent needs reboot Bad state (something wrong. Need manual intervention) = Configuration error + Provisioning error + Error + Unknown + Protocol failure + Domain failure + Agent disabled + Agent unreachable + Invalid IP Usable Capacity consists of\nUsed = Already Used + Connected + Disconnected + Unassigned user connected + Unassigned user disconnected Available = Available RDS host status.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.6-vsan-configuration/",
      "title": "6. vSAN Configuration",
      "tags": [],
      "description": "",
      "content": "The dashboard is designed with the same considerations that are common among all the configuration management dashboards.\nHow to Use The dashboard is organized into 3 sections for ease of use.\nThe first section displays 6 pie charts\nThere are 5 bar charts that focuses on critical security settings. Their values should match your security policy. The last bar chat shows the version of the vSphere Distribution Switch. Aim to keep the version current, or matching your vSphere version. The second section displays 3 bar charts\nTogether, they provide good overview of the vSAN key capacity configuration. By seeing the distribution, you can see if you have capacity configuration that is outside your expectation. The last part of the dashboard shows all the vSAN clusters with their key configuration.\nSome of the columns are color coded to facilitate quick reviews. Adjust their threshold to either reflect your current situation or your desired ideal state You can sort the columns and export the result into spreadsheet for further analysis. Points to Note The number of buckets on the pie chart or bar chart are balanced between the available screen estate, ease of use and functionality. Modify the buckets to either reflect your current situation or your desired ideal state.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/3.3.6-vm-capacity/",
      "title": "6. VM Capacity",
      "tags": [],
      "description": "",
      "content": "The VM Capacity dashboard is designed for Capacity Team, not day to day Operations team. It provides long term and top down view, enabling the capacity team to better plan future expansion and ageing hardware technological refresh.\nSee the Capacity Dashboards page for common design consideration among all the dashboards for capacity management.\nHow to Use Select a data center from the Data centers table. To show from all clusters, select vSphere World. This object covers all clusters. Take note that the charts will take longer due to refresh due to higher amount of data.\nThe bar chart will show the distribution of VM by capacity remaining in the selected data center. It gives you a quick overview if many VMs are undersized or oversized. The bucket size has been designed to map the default settings in VM capacity policy.\nReview the heat map1. It provides the next level of details by grouping the VMs by clusters, so you can see which clusters need to be attended to.\nNote the VM size has been standardized for better visualization. If it suits your capacity team better, add the size. Note that you have to pick CPU or Memory, so you may have to create 2 heat maps.\nReview the table listing all VMs in the selected data center.\nThe list is sorted by the VM with the least capacity remaining. If it suits your capacity team better, sort it by Time Remaining.\nThe table is also color coded. Take note that the threshold is unable to show the grey (wastage) color.\nSelect a VM from the list. All the remaining widgets will automatically show the capacity information of the selected VM.\nThe CPU and Memory utilization are automatically shown. 3 months data is shown, and they are averaged to hourly so you can see the overall trend.\nRight-sizing recommendation is also shown for both CPU and Memory. Unlike physical server, it\u0026rsquo;s important to right-size VM for the benefits listed here.\nFor CPU, the CPU Usage counter is used instead of Demand. Use the knowledge you learned here to figure out why.\nFor disk, it\u0026rsquo;s showing at the Guest OS partition level. There is no overall capacity at VM level because different partitions have different capacity.\nPoints to Note Add more information in the table to give context to the VM. Information such as VM Owner, clusters where the VM is running, and datastores where the VM files are stored can be useful in the analysis.\nThere is a known bug in the age of the VM scoreboard. As a workaround, create a View List, and choose the VM property Configuration \\ Creation Date. Choose the Transformation: Timestamp and then Relative Timestamp.\nvRealize Operations 8.4 sorts the heat map when the size is identical. You are welcome.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.6-datastore-performance/",
      "title": "6. Datastore Performance",
      "tags": [],
      "description": "",
      "content": "Use the Datastore Performance dashboard to view performance problems related to storage such as high latency, high outstanding IO, and low utilization. This dashboard is designed for both VMware administrator and Storage administrator, with the goal of fostering closer collaboration between the 2 team.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nThis dashboard combines contention and utilization metrics in 1 dashboard, but still visually separate them for ease of use.\nLocal datastores are treated separately, as they have their own use case.\nHow to Use Select a data center from the Data centers table\nThe list of shared datastores in the data center will be automatically shown, along with their KPI. note that datastore that is unavailable is not shown. Review the Datastore Performance table\nRead and Write latency are shown separately for a better insight. The nature of read and write problem may not be the same so it\u0026rsquo;s useful to see the difference. Both the worst (peak) performance and 95thpercentile are shown. If the later is close to the peak and it\u0026rsquo;s also high, then it\u0026rsquo;s a sustained problem. If the later is low, then it\u0026rsquo;s a short duration. The table is color coded. If your operations require a different threshold, edit the widget to adjust accordingly. Select a datastore you want to troubleshoot\nIts read latency, write latency and outstanding IO is automatically shown. Outstanding IO should be seen in conjunction with latency. It can be acceptable to have high number of IO in the queue, so long the actual latency is low Note the latency is the normalized average of all VMs in the datastore. Its IOPS and throughput are also shown. These line charts are not color coded as it varies per customer. Edit the widget and add your expected threshold. It will make it easier for the operations team. Its list of VM is automatically shown Select a VM you want to troubleshoot\nIts read latency and write latency are automatically shown. Note that this number is at the VM level. If you suspect one of the virtual disk has high latency, use the counter Peak Virtual Disk Read Latency (ms) and Peak Virtual Disk Write Latency (ms). Consider adding the VM Outstanding IO if you have the screen real estate. Points to Note The dashboard does not have datastore clusters. If your environment use it, add a View List to list them, and have this view list drives the Datastore Performance view list. If you have many VMs with virtual disks on multiple datastores, add a View List widget to list the individual virtual disks. Use this list to plot the latency of individual virtual disk. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.6-table-as-insight/",
      "title": "6. Table as Insight",
      "tags": [],
      "description": "",
      "content": "A table is simply a list, where each row represents an object, and each column shows a single value. This enables us to list hundreds of rows, with ability to filter and sort. Each cell value can also be color coded.\nTable is good for details. However, as a summary, its main problem is how to give an insight over time as each cell can only hold 1 value. How to give an insight into what happens in the past? For example, how to see the performance in the last 1 week? There are 2016 datapoints in the last 7 days, which one do you pick to represent?\nThere are a few possible options in vRealize Operations 8.2\nThe current number. It\u0026rsquo;s useful to show the present situation. However, this does not tell what happened 5 minutes ago. Its usefulness is hence limited. The average of the period. Average is a Lagging Indicator. By the time the average is bad, roughly 50% of the number is unlikely to be good. It is not suitable for proactive monitoring. The worst of the period. This is suitable for daily average, as there are only 288 data points in 24 hours. If you find that results in outlier, then replace it with 99th percentile. As it only takes 1 peak to set this value, your chance of outlier is 7x higher in a week. It\u0026rsquo;s great for peak detection, but needs to be complemented with 95th percentile when looking at weekly or monthly period. The 95th percentile number. This is a good midpoint between Average and Worst. For performance monitoring, 95th percentile is a better summary than average. Use both the Worst and 95th percentile numbers together for better insight. If the numbers are far apart, that indicates the Worst number is likely an outlier. If the numbers are similar, you have a problem. From the above, we should choose Max and 95th percentile.\nThe following table implements the above concept.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-5---network-metrics/2.5.6-distributed-switch/",
      "title": "6. Distributed Switch",
      "tags": [],
      "description": "",
      "content": "\nvSphere network is by nature distributed. Each ESXi contributes to the physical NIC. This represents the physical capacity as each NIC cards have a limit, such as 25 Gbps full duplex. Distributed switch and its port groups span across these independent network cards, and dynamically share the cards. This distributed and dynamic nature makes it practically impossible to define and measure network capacity and performance. Unbalanced can happen among ESXi or physical NIC. In a sense, it\u0026rsquo;s like distributed storage (e.g. vSAN).\nvCenter does not provide information at the individual port group level. This makes monitoring difficult, as you cannot slice the data from the switch point of view. vRealize Operations addresses that by providing the necessary counters at the Distributed Switch level and its Port Groups. It shows a relationship between ESXi, the port group and the switch.\nYou can drill down into a port group, and see the VMs connected to that port group\nCapacity management does not apply to a port group, since its upper limit (also known as the physical capacity) can vary by even a minute. You can use static binding if that helps in capacity and performance management.\nAt the physical layer, you need to use adapter to gain visibility. This gets you interesting metric such as CRC errors, input drop (system unable to cope with incoming packets), input error (likely due to physical layer issues, such as bad hardware, a noisy line, a bad connection, or incorrect data conversion), interface reset (due to issues such as congestion on the line), output drop (system tries to hand off a packet to a transmit buffer but it has no more buffers). More is covered here.\nYou should expect error to be 0 or below 1%.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-4---storage-metrics/2.4.6-storage-array/",
      "title": "6. Storage Array",
      "tags": [],
      "description": "",
      "content": "\rThis page has no content right now. Contributors are welcome! Use the \u0026ldquo;Edit this page\u0026rdquo; link.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-3---memory-metrics/2.3.6-other-metrics/",
      "title": "6. Other Metrics",
      "tags": [],
      "description": "",
      "content": "Demand Can you spot a major counter that exists for CPU, but not for RAM?\nThat\u0026rsquo;s right. It\u0026rsquo;s Demand.\nTo figure out demand, we need to figure out unmet demand, as demand is simply unmet demand + used (which is met demand). Since the context here is VM, and not Guest OS, then unmet demand includes only VM level counters. The counters are ballooned + swapped + compressed.\nDo you agree with the above?\nIf we are being strict with the unmet demand definition, then only the memory attributed to contention should be considered unmet demand. That means balloon, swap, or compressed memory can\u0026rsquo;t be considered unmet demand. Swap in and decompression are the contention portion of memory. The problem then becomes the inability to differentiate contention due to limits using host level metrics, which means we\u0026rsquo;d need to look at VM level metric to exclude that expected contention.\nMemory \\ Usage (%) Memory Usage in vCenter maps to Active. What you see on the vCenter UI is Active, not Consumed.\nMapping to Active makes more sense as Consumed contains inactive pages. As covered earlier, neither Active nor Consumed actually measures the Guest OS memory. This is why vRealize Operations maps Usage to Guest OS. The following shows what Usage (%) = Guest OS Needed Memory over configured memory. The VM has 1 GB of memory, so 757 MB / 1024 = 74%.\nTake note that there can be situation where Guest OS metrics do not make it to vRealize Operations. In that case, Usage (%) falls back to Active (notice the value dropped to 6.99%) whereas Workload (%) falls back to Consumed (notice the value jump to 98.95%).\nMemory \\ Utilization (KB) Equals to Guest Needed Memory (KB) + (Guest Page In Rate per second * Guest Page Size (KB) ) + Memory Total Capacity (KB) - Guest Physically Usable Memory (KB).\nBecause of the formula, the value can exceed 100%. The following is an example:\nIt\u0026rsquo;s possible that vRealize Operations shows high value when Windows or Linux show value. Here are some reasons:\nGuest metrics from VMware Tools are not collecting. The value falls back to Consumed (KB). Ensure your collection is reliable, else the values you get over time contains mixed source. If their values aren\u0026rsquo;t similar, the counter values will be fluctuating wildly. Guest Physically Usable Memory (KB) is less than your configured memory. I\u0026rsquo;ve seen in one case where it\u0026rsquo;s showing 58 GB whereas the VM is configured with 80 GB. My first guess is the type of OS licensing. However, according to this, it should be 64 GB not 58 GB. Low utilization. We add 5% of Total, not Used. A 128 GB VM will show 6.4 GB extra usage. Excessive Paging. We consider this. We include Available in Linux and cache in Windows, as we want to be conservative. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-6---compliance-management/1.6.6-custom-benchmarks/",
      "title": "6. Custom Benchmarks",
      "tags": [],
      "description": "",
      "content": "You can add a custom benchmark by clicking on the \u0026ldquo;Add Custom Compliance\u0026rdquo; card. You can either create a new one or import an existing one. This allows not only define custom benchmarks but further reuse it in other environments.\nProvide a name to the custom benchmark and add an optional description.\nNext, select the alerts definitions to enable as part of the compliance check. You can individually check the ones you want or start with a baseline and further customize the options. You can select a baseline by selecting the \u0026ldquo;Defined By\u0026rdquo; filter.\nOnce the alerts are selected, select the policy where the compliance check will be enabled.\nThis will define and enable the custom benchmark. Again, an initial assessment will be run and report will be generated against it.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.6-usable-capacity/",
      "title": "6. Usable Capacity",
      "tags": [],
      "description": "",
      "content": "As covered earlier in the book, usable is a concept that applies only to capacity. There is no such thing as usable performance. Usable capacity is a non-real number that you get after deducting total capacity with the portion that capacity team decides to exclude. This portion typically accounts for availability, invisible demand and auxiliary demand. The number is non-real as the real available capacity can exceed that.\nAvailability For hardware, this means the part that is added to cater for unavailability period. Common examples are RAID in disk, hot spare in storage array, vSphere HA in vSphere Cluster. Many hardware deployment come in a pair (e.g. network switches) because one of the node is for availability, not capacity.\nIn vSphere Cluster, you typically design with at least 1 host as spare, so you can perform maintenance, upgrade without service degradation. While this host is participating in reality, you exclude this in your capacity. vRealize Operations excludes HA from usable capacity.\nAuxiliary Demand This is typically overhead, which can happen at consumer layer (e.g. VM snapshot) or provider layer (e.g. vSAN resync, VMkernel CPU)\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.6-performance-sla/",
      "title": "6. Performance SLA",
      "tags": [],
      "description": "",
      "content": "Google \u0026ldquo;performance SLA\u0026rdquo; VMware, and you will find only a few relevant articles. The string performance SLA must be within a quote, as it is not performance and SLA, but Performance SLA. Yes, I\u0026rsquo;m after web pages with the words Performance SLA together. You will get many irrelevant results if you simply google VMware Performance SLA without the quote.\nI just tried it again on 14 March 2021. Google returned less than 20K results, which is up from 1.6K results in October 2015. The first 10 are shown below. Notice 8 of them are from my blog, book or speaking event. One item from Sunny Dua, talking about the same performance SLA concept we came up with, appears on the top 10. The last one is from Michael Webster, who used to work at VMware years ago.\nI checked beyond the first 10 results. Other than my own articles, Google returned only a handful of relevant articles. The rest are not in fact relevant if you read them carefully. The relevant articles mention Performance SLA, but they do not define and quantify what a Performance SLA is. If something is not quantified, it is subjective. It\u0026rsquo;s hard to reach formal agreement with customers quickly and consistently when the line is not clearly drawn. If you have a disagreement with your customers, especially paying customers, guess who wins.\nAvailability SLA protects you when there is downtime. Performance SLA protects you when there is performance issue.\nThe Performance SLA for vSphere is defined in the following table:\nUsing a typical 30-day month\nDo you know why you should only use CPU Ready and exclude CPU Co-Stop and CPU Contention from Performance SLA?\nIt took me years to vrealize the mistake.\nAnswer is in Part 4: Quiz Answer, towards the end of the book.\nThe whole point of having performance management is to be able to know the problem before the customers complain. If you can\u0026rsquo;t see the problem before customers do, then you don\u0026rsquo;t have performance management in place. The word manage implies proactive. Passively waiting for an alert or complaint to trigger the troubleshooting process is not management. Proactive requires an internal threshold that is more stringent than the external, formally agreed SLA. This is where KPI comes from.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-6---automation/",
      "title": "Chapter 6 - Automation",
      "tags": [],
      "description": "",
      "content": "Chapter 6 Automation This chapter is contributed by Thomas Kopton, Consulting Architect and vRealize Ambassadors based in Europe.\n1. Introduction\r2. Outgoing Communication\r3. Incoming Communication\r4. Closing the Loop\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/",
      "title": "Miscellaneous",
      "tags": [],
      "description": "",
      "content": "This part is the place for a variety of stuff. Some of them may grow into their own chapters or parts in the future. It also covers basic knowledge that maybe useful for those without computer science background. Lastly, there are some personal sharing from me about the life of an infrastructure architect.\nChapter 1 - Quiz Answers\rChapter 2 - Operational Maturity\rChapter 3 - SDDC vs. IaaS\rChapter 4 - Super Metrics\rChapter 5 - Log Insight\rChapter 6 - Automation\rChapter 7 - VMware IT Operations\rChapter 8 - VDI \u0026amp; DaaS\rChapter 9 - Infrastructure Architect\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.7-availability/",
      "title": "7. Availability",
      "tags": [],
      "description": "",
      "content": "\rThis page is still in draft.\nWe covered in Part 1 Chapter 1 that Availability can impact Performance and Capacity, but need to be measured separately.\nHorizon consists of different components, each having their own availability metrics.\nObject Availability Metric RDS Farm Number of RDS Hosts in Bad State Aim for this number to be 0 at all times. VDI Pool Number of VMs in the pool that is not used yet not available. The metric Desktop in Bad State can be unavailable because they are in one of these states:\nProvisioning | Customizing | Starting Up | Deleting | Waiting for AgentMaintenance mode | In ProgressAgent disabled | Agent unreachable | Agent needs rebootInvalid IP | Protocol failure | Domain failureConfiguration error | Provisioning error | Error UnknownFor the description, see this. Connection Server Pod Number of Connection Servers that are not available. The formula depends on the design. If it is N+1, then the availability will be affected when there is \u0026gt;1 unavailable server. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.7-consumer-correct-it/",
      "title": "7. Consumer / Correct It?",
      "tags": [],
      "description": "",
      "content": "The \u0026ldquo;Consumer / Correct It?\u0026rdquo; dashboard complements the main VM configuration dashboard by displaying the actual VMs, with their relevant information. It is designed for vSphere administrator and platform team, to facilitate the follow-up action with the VM owners. It is a part of 8 dashboards that check the environment for optimization opportunities.\nThe dashboard is designed to focus on VMs that need attention. A list is used to keep it simple, and show actual objects. The list is easy to be tailored by filter and custom group. The list can also be exported for an offline discussion.\nIt\u0026rsquo;s also designed to be extendable, reflecting the reality that different customers will have a different set of settings to verify. Since the dashboard layout is just a collection of tables (View List), you can extend it by simply adding more tables. Simply add more View List widget to check the VM configuration that your operations require.\nHow to Use The dashboard is just a collection of tables (List View), which can be reviewed independently. There is no flow among them.\nClick the object name to navigate to the Object Summary page to view more configurations. There can be valid reasons why specific configurations are not followed. It is recommended that you discuss best practices with VMware.\nAbout the Tools tables\nUsing VMware Tools has multiple benefits. For the list of benefits, refer to KB 340. vRealize Operations uses VMware Tools to retrieve Guest OS metrics. Without this, right-sizing VM memory can be inaccurate, because the hypervisor metrics (VM Memory Consumed and VM Memory Active) are not designed to measure Windows or Linux memory utilization. ESXi VMkernel does not have visibility into the Guest OS for security reasons. Independent software vendor (ISV) support is the most common reason that VMware Tools is not installed. The ISV vendor may claim that no additional software is installed in their appliance unless they have certified it. For more information about VMware Tools, see the VMware Tools documentation. If VMware Tools is installed, there might be reasons why the application team disables it. The Infrastructure team should inform and educate their application team, and document the technical recommendations on why VMware Tools is strongly recommended to run all the time. About the Memory and CPU Limits table\nIt is recommended that you do not use memory and CPU limits as it can result in unpredictable performance. The Guest OS is not aware of this restriction as it is at the hypervisor level. It is recommended that you shrink the VM instead. About No Guest OS counters table\nThere is no visibility into the Guest OS performance counters because the requirements are not met. Memory counter is especially important as VM Consumed and the VM Active are not replacements for Guest OS counters. See this KB for details. About the Old Snapshot table\nEnsure that the snapshot is removed within one day after the change request. If not, it might result in a large snapshot and impact the performance of the VM. Points to Note Add a banner summary at the top of this dashboard, so that you can verify if there is an incorrect confirmation. Add a scoreboard and select the World object and then collapse all the tables below. Create a super metric for each summary and apply it to the World object. In a very large environment, create a filter for this dashboard to enable you to focus on a segment of the environment. Group it by a class of service such as, Gold, silver, and bronze. Default the selection to Gold, your most important environment. In this way, your monitoring is not cluttered with less critical workloads. There are other VM configuration that maybe relevant to your environment. Review the list of VM settings that you may want to add to this dashboard here. For a quick context, add a property widget that lists the selected VM properties. In this way you can check the property of your interest without the need to leave the screen. Note that multiple View List widget can drive the same property widget, so you do not have to create 1 property widget for each View List. If your operations required it, add list VMs that do not have these three key performance counters: CPU Run Queue, CPU Context Switch, and Disk Queue Length. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/3.3.7-vm-reclamation/",
      "title": "7. VM Reclamation",
      "tags": [],
      "description": "",
      "content": "The VM Reclamation dashboard helps you managing various types of reclamation that can be done on VMs. It is designed for both the Capacity team and the Operations team.\nHow to Use The dashboard is divided into 2 sections.\nThe upper section provides summary, giving you overall picture of reclamation. The lower section provides details, giving you the actual VM name to reclaim. Select a data center from the table.\nThe summary information will be automatically shown. To show from all clusters, select vSphere World. This object covers all clusters. Take note that the charts will take longer due to refresh due to higher amount of data. The reclamation potentials are presented as 3 bar charts, each corresponds to an area you can reclaim: Snapshot. Especially those more than a few days old as snapshot is meant to be temporary. Powered off VM. Assuming they are already backed up, it\u0026rsquo;s safe to delete them from vSphere. Idle VM. You get to reclaim memory, not CPU. Idle VM memory still occupies ESXi physical memory. The Idle VM does not display any CPU as there is practically nothing to reclaim as the overhead of idle CPU is being used. The primary benefit for CPU is capacity, especially the overcommit ratio. Memory reclamation is based on the memory footprint at the parent ESXi. The value inside the Guest is not what is being reclaimed, and so it is irrelevant. That\u0026rsquo;s why the VM consumed memory is chosen. Adjust the bucket size in the charts to suit your operational requirements. Review each of the 3 tables They are sorted by the largest reclamation opportunities. Select any of the VM row to see its trend over time. The trend chart is placed in the same page, so you can review without changing context (e.g. open a new screen) and quickly toggle between VMs. If the snapshot is expanding rapidly, ensure that the VM disk is large (relative to the underlying datastore) as it can fill up the datastore. Points to Note If your environment is large, change the dashboard filter to a functional filter. Group by the class of services such as Gold, silver, and bronze and default the selection to the least critical environment. In this way, you can be active in reclamation.\nIf reclaiming is a long drawn manual process in your organization, add a filter by department or VM owners. One way to do this is to create a vRealize Operations custom group.\nIf the VM name in your environment does not provide sufficient business context, add more information in the table to give context to the VM. Information such as VM Owner, clusters where the VM is running, and datastores where the VM files are stored can be useful in the analysis.\nDisk cannot be reclaimed immediately. They have to be in the powered-off stage at least for a week.\nYou should enhance this to include Trim and Unmap. Happy to collaborate and make this into the product. We need to check on only the thin provisioned disk. We should also check at the array level, using the TVS adapter.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.7-vsan-contention/",
      "title": "7. vSAN Contention",
      "tags": [],
      "description": "",
      "content": "The vSAN Contention Dashboard is the primary dashboard for vSAN performance. It\u0026rsquo;s designed for VMware Administrator or Architect, and can be used in both monitoring and troubleshooting. Once you determine there is performance issue, use the vSAN Utilization dashboard to see if the contention is caused by very high utilization.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nAs this dashboard is designed to complement the vSphere Cluster Capacity dashboard, it shares the same design consideration. It focuses on the storage and vSAN specific metrics, and does not repeat what\u0026rsquo;s already covered. It also does not list non vSAN cluster.\nHow to Use Review the 3 distribution charts\nThey give an overview of all the vSAN clusters performance. The first chart shows if the distribution of disk latency experienced by all the VMs in the cluster. You should expect majority of the VMs to experience latency that matches your expectation. For example, in an all flash systems, the VMs should not be having \u0026gt;20 ms disk latency. If your vSAN environment is all flash, you may need to adjust the distribution bucket to a more stringent set. The second chart shows if any of the vSAN kernel module has to wait for CPU. Expect this number to be near 0% and below 1%, as vSAN should not be waiting for CPU time. vSAN gets higher priority than VM World as it lives in the kernel space. The third chart shows if any of the vSAN cluster is dropping packet in the vSAN network (not the VM network). vSAN relies on network to keep the cluster in-sync. This number should be near 0% and less than 1%. Review the vSAN Clusters table\nIt lists all the vSAN clusters, sorted by the least performing. It lists all the ESXi hosts, sorted by the worst performance in the last 24 hours. If the table is all showing green, then there is no need to analyze further. The reason 24 hours is chosen instead of 1 week is the performance \u0026gt; 24 hours are likely to be irrelevant. You can change the time period to the period of your interest. The maximum number will be reflected accordingly. All Flash and Hybrid have different performance. Since there is only 1 benchmark, the all flash will perform better than hybrid, and that\u0026rsquo;s what you expect to see. Select a vSAN cluster from the table\nAll the health charts will automatically show the KPI of selected cluster. vSAN Resync is a type of utilization metric, but its presence can impact performance. vSAN has two scenarios that trigger rebalance (the reason for resync). Proactive: A large variance among devices disk space utilization. Reactive: When devices reach a critical capacity threshold (typically ~80%). This adjustment can be in the form of object components moving to other disks, disk groups, or hosts, or even splitting of existing large components into smaller components to achieve the desired result. If you are using SMART, the 2 heat maps at the bottom of the dashboard provides early warning. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.7-bar-chart-as-insight/",
      "title": "7. Bar Chart as Insight",
      "tags": [],
      "description": "",
      "content": "Distribution Charts comes in many shapes, with bar chart being one of most familiar. It can be used to give insight to a large dataset. Take the following as an example. It shows vSphere shared datastores by their capacity remaining. They are categorised into 5 buckets, from the lowest capacity remaining to the highest. Each bucket is given a color to convey a meaning. Can you guess why \u0026gt;80% is given a grey color, as opposed to even more green?\nThe reason has to do with the reason you bought the capacity in the first place. It\u0026rsquo;s to be consumed. If the capacity is not well used after months or even years, it\u0026rsquo;s a wastage. You overbought capacity.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-6---compliance-management/1.6.7-checking-the-result/",
      "title": "7. Checking the Result",
      "tags": [],
      "description": "",
      "content": "As depicted below, the default compliance page shows at a glance compliance status of the environment against different policies. The \u0026ldquo;Compliance cards\u0026rdquo; show the status of the environment against a compliance benchmark.\nTo check further details of a topic, click on card for that topic. This gives us the detailed view of the environment.\nNote the links under \u0026ldquo;Compliance Alerts List\u0026rdquo;. This gives us the details of the non-compliance. Clicking on that link will take us to the particular alert details.\nAlso note, for any selected object we can check the compliance related to that object from \u0026ldquo;Compliance\u0026rdquo; tab.\nBased on the reports we need to further correct those issues and further run compliance.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.7-projection/",
      "title": "7. Projection",
      "tags": [],
      "description": "",
      "content": "The accuracy of the prediction depends on the amount of data and the length of the cycle. A workload with quarter end peak will naturally need at least 6 months for it to be accurate. If there is enough data, vRealize Operations will consider 6+ months worth of data. While it gives extra weight to recent data, if there is a sudden but short-lasting change, it may not be enough to impact the projection.\nMomentary peaks that are short lived and one-off should not impact capacity planning so the impact may not be noticeable in the projection.\nSustained peaks last for a longer time and do impact projections. If the peak is not periodic, the impact on the projection lessens over time due to exponential decay.\nPeriodic peaks exhibit cyclical patterns or waves. For example hourly, daily, weekly, monthly, last day of the month, etc. There can be multiple overlapping cyclical patterns, which will also be detected. While you should not make capacity decision based on just a few days of data, you do need the 5-minute granularity as input. A 5-minute peak that gets repeated every hours should be considered.\nIf you do not have 3 months and just need an overall sizing, consider using the 97th percentile value. Why 97th percentile? It\u0026rsquo;s based on standard deviation principle. Two Standard Deviation away from the midpoint equals to 95%, and 3 Standard Deviation = 99.7%. 97th percentile hence provides a good balance between 2 SD and 3 SD. By and large, it captures just the right amount of peak and outlier.\nCapacity Remaining (%) uses a projected value, 3 days into the future, hence it might differ with currently used capacity. As it\u0026rsquo;s future value, there is confidence band. You can choose between aggressive (based on the upper limit of the band) and conservative (based on the actual trajectory). On the other hand, if the present utilization exceeds the usable capacity, vRealize Operations sets the value of Capacity Remaining to 0%.\nTake note that CPU Capacity Remaining (%) and Memory Capacity Remaining (%) appear in the policy as enabled but cannot be used. That\u0026rsquo;s an internal metric which should have been hidden.\nTime Remaining measures the number of days before capacity runs out. The projection is up to 1 year, with time remaining above 1 year is simply shown as 1 year. The conservative is based on the upper bound of the capacity remaining projection.\nVM Remaining measures the number VM with average size that can fit into the cluster. The average VM size calculated automatically, so it varies across time and across clusters. VM Remaining at vSphere Data Center and vCenter levels are simply the sum of the children clusters. There is no calculation of average VM size at these levels, so you like have mixed sizes. Also, the VM Remaining value does not fall below 0. It\u0026rsquo;s possible for a data center to show positive VM Remaining value even though there is short fall in one of its member clusters.\nRecommended Size is based on the highest projected value within the planning window, not the value of projection at the end of the window. By default, the planning window is 60 days for VM. This comes from 30 days provisioning buffer + 30 days (the default threshold for Time Remaining to be in the green zone, as shown in the screenshot).\nIf the VM usage is increasing over time, the projection will likely follow, and you will get a number that exists 60 days into the future.\nIf your operations is able to make frequent adjustment, change the Time Remaining window to 0. This will give 30 days adjustment period.\nTake note that the recommended size for Memory is rounded to the nearest GB.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.7-kpi-vs-sla/",
      "title": "7. KPI vs. SLA",
      "tags": [],
      "description": "",
      "content": "I agree that a set of metrics that determine the health of complex object such as VM or application will never be accurate in 100% of the case. This is normal, just like in real life. We take annual health check, performing all sort of tests, and the results will be a series of metrics (e.g. your bad cholesterol level). Are they 100% accurate for you from young until you are old? Are the results 100% accurate for everyone in your city? No, but they are good enough, and certainly much better than nothing. Beside the absolute value, the relative movement of the value over time is also able to give you insight. For example, if the KPI drops on a quiet Sunday morning when the environment is not supposed to have known activities, perhaps there is bad going on?\nIn this book, my definition for KPI is strictly on performance, because the word performance has a specific meaning. To me, KPI as a term does not apply to Availability management and Capacity management. We should call the key indicators that determine availability as KAI, and the key indicators that determine capacity as KCI1. This will prevent confusion as implementation-level solution requires us to be non-ambiguous with terminology.\nBroader definition of KPI that includes non-performance is not used in this book so we can be precise in the implementation. For an overall business KPI, Norman Dee has written a series of blog post here.\nFor KPI to support SLA, the thresholds that it uses must be the same that SLA uses.\nLet\u0026rsquo;s say you have three classes of service, with Gold being the highest and most expensive.\nThe Gold class should be performing better than Bronze. That\u0026rsquo;s the expectation, so we need to reflect that in the reality in production. The Gold absolute performance should be better as it was designed to be better. There\u0026rsquo;s a reason why it\u0026rsquo;s priced higher to begin with.\nKPI This absolute performance is measured in range of 0 - 100% so it\u0026rsquo;s easy to understand, with 100% being the best. Mathematically, KPI is actually unitless. I could have chosen another range, such as 0 - 4, and it won\u0026rsquo;t make any difference. Using percentage and 0 - 100 just makes it easier to remember.\nKPI reports the raw performance as it is.\nMajority of KPIs are internal. They are used as the starting point to troubleshoot.\nFor each type of object, aim to consolidate all the performance metrics into a single KPI. Say you have 1000 AWS EC2 to be monitored. You have a bunch of metrics and you considated them into 2 KPIs. How would you know which EC2 has issues? You need to show 2 sets of heat map or table. That means you need to manually corelated the first table with the second. It\u0026rsquo;s not scalable.\nThe above also presents challenge as you roll up to higher level object.\nSLA While Gold should perform better than Silver, it may not be good enough for the Gold SLA. Gold can fail its own SLA even though it\u0026rsquo;s faster than Bronze in the absolute term. Relative is measured in binary. Pass or Fail. Because it is a binary, it can\u0026rsquo;t measure how good it passes or how bad it fails. This is one area where KPI complements it.\nSLA is typically measured over one calendar month, meaning a one time failure of 5-minute does not constitute formal SLA failure.\nSLA is external as it\u0026rsquo;s written in the contract.\nThe following table shows how KPI and SLA relate. Both takes the same metrics and threshold as input, but they analyze differently as their purpose is different.\nAll three Class of Services share the same set of KPIs, which are absolute. Fast is fast. It is a fact, regardless of what business labels you attach to it.\nTo define your KPI, take each KPI metric and define exactly what fast is and break it into four zones. Each zone is given a quarter of the 100% for simplicity. Ideally, set Gold SLA in the highest range, which is the Green range of KPI. Ideally, set Silver SLA in the range below green, which is the Yellow range of KPI. If they are in the Green range, you have over delivered (or are over delivering). You should optimize your cost by selling more VMs or buying less expensive hardware. Expect Bronze to be in the Orange range. If they are in Green to Yellow range, you over delivering. None should in the Red range. This is where your critical alerts are triggered. Since the very purpose of KPI is to enable proactive operations, you want to minimize being in the red zone. In the preceding example, the Silver range is given a wide band. While this is mathematically possible, operationally it creates unnecessary complexity. It\u0026rsquo;s so much easier to map one color to each class of service. Also, having more than 3 class of service complicates your operation and increase your cost.\nLet\u0026rsquo;s look at an example to illustrate:\nThe Gold SLA for VM Disk Latency is 8 ms, Bronze is 26 ms. A Gold VM 007 has 9 ms disk latency. A Bronze VM 747 has 25 ms disk latency. Gold class delivered better performance in absolute terms. However, in relative terms, Gold failed the SLA while Bronze class passed its SLA. If you have a free Tier, where there is no SLA, then it\u0026rsquo;s fine for them to be in the red zone. Commercial cloud providers provide free tier. They are intentionally designed to be slower and less reliable, because they want you to upgrade and pay.\nInternal SLA For each SLA, there can be many associated KPIs, because not all metrics should be in the contract, while almost all performance metrics need to be monitored.\nvRealize Operations uses the following threshold for vSphere IaaS internal SLA. These numbers are fixed in the product.\nThe above is a stringent threshold. A high standard for performance is used because it is an internal KPI for Infrastructure team consumption. It is not an external, formal SLA. There needs to be a buffer between internal and external, to give the operations team room to react. The buffer is your margin of error.\nAnother reason for the high standard is it must work for mission critical environments. If the threshold is not good enough for such environments, you will not get an early warning.\nA single threshold is used to keep the operations simple. This means the performance in production is expected to have a higher score than the development environment. Development environments will obviously perform worse than Production environments. A single threshold helps to educate the difference in QoS (Quality of Service) provided by the different class of service. You pay less, you get worse performance. You pay half price; you get half the performance.\nThe above four elements of IaaS (CPU, Memory, Disk, Network) are evaluated on every collection cycle. The default collection cycle is 5 minutes, which is an appropriate balance for SLA monitoring. An SLA that is based on a 1-minute collection cycle will be too tight and result in either a cost increase or a reduction in threshold.\nThe following example, taken on vRealize Operations 8.2, shows that this VM was served well by the IaaS. It\u0026rsquo;s getting the four IaaS resources it asked for in the last 24 hours with only one exception. The chart counts each time a VM is not getting a resource. A VM that is not served on all four will register a value of 4 in the chart.\nThe following example shows the opposite. There are many instances where the VM is not getting at least one of the four IaaS resource, and one instance where it did not get two them. The chart also shows 7 days, so pattern or spike can be seen.\nNow that we can measure for every single VM, we can roll up the metric at the ESXi Host or Cluster level. The following formula averages all the running VMs in the cluster. You expect to see a number near 100%, as the expectation is that the cluster is serving all the VMs well, and not just 99% of them. 99% in a cluster with 1000 VMs can mean 10 VMs aren\u0026rsquo;t being served well. All it takes for a complaint can be just one VM!\nThe following example shows that the cluster is struggling to serve all its VMs.\nKPI We shared earlier that SLA only accounts for pass or fail. It does not measure how good you pass or how bad you fail. This is where KPI complements SLA. KPI is implemented in VMware Horizon monitoring, so I will use it as the example.\nKPI is defined as 0 - 100%. As we use 4 colors, we divide them equally. So Green is simply 75% - 100% and Red is simply 0% - 25%. If you create an unequal distribution, some bands will have to be narrower than others. With uneven bands, you also need to be extra careful when defining the threshold for each metric that make up the KPI.\nThe following KPI uses 4 metrics as its input. Each metric has a set of thresholds for green, yellow, orange and red.\nNow that we have the threshold for each metric, we can convert each metric into Green - Red. Horizon adapter is also able to handle when the entire range is defined by a single number. This is useful when you want to define green = 0. That means a single packet loss will put the metric into the yellow range already.\nHow do we translate?\nLet\u0026rsquo;s use an example. Take the Disk Latency (%) metric . It has range from 0 to 40 ms, which maps into the 0 - 100% using the following mapping table.\nWith the above mapping, we can be precise in assigning the value. For examples:\n9 millisecond disk latency translates into KPI value of 77.5%, which is green. The reason is green ranges from 75% to 100%, where 0 ms equals to 100% and 10 ms equals to 75%. So each millisecond is around 2.5%. 42 millisecond disk latency translates into 0%. It is above the upper threshold of 40 millisecond. Since we do not show negative, anything above the limit is shown as 0% We repeat the calculation for each metric. The KPI is simply the average of the metrics.\nIn future, we can add weighted average, so you get a better leading indicator. The problem with a simple average is a single red can be outnumbered by many green, and the KPI will not show a problem.\nYou see, I\u0026rsquo;m not opposed to jargons. so long they are actually used in live operations. If it\u0026rsquo;s just a goal, then no need to label with jargon, else we have to create jargon for every single type of goals.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-7---vmware-it-operations/",
      "title": "Chapter 7 - VMware IT Operations",
      "tags": [],
      "description": "",
      "content": "Chapter 7 VMware IT Operations We partner with VMware IT as our Customer. That means we treat them as real customers as they run our products in real production environment. Ravishankar Rao and George Stephen represent the Tools solution and I\u0026rsquo;ve asked them to share their journey in evaluating and customizing vRealize to their operations. Their goal is for the experience to be useful for other customers, so I\u0026rsquo;ve asked them to write as if they are external customer so you can take the relevant bits in your own evaluation and customization.\n1. Background\r2. Monitoring\r3. Post-Implementation Review\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/",
      "title": "Chapter 8 - VDI &amp; DaaS",
      "tags": [],
      "description": "",
      "content": "Chapter 8 VDI \u0026amp; DaaS While VMware Horizon provides the same business functionalities with products such as Citrix, it requires a monitoring and troubleshooting solution that is aware of its objects, metrics, logs and events. In this chapter we will cover the Horizon-specific operations management.\n1. Roles \u0026amp; Responsibilities\r2. RDS vs VDI\r3. Object Model\r4. Performance Management\r5. Performance Dashboards\r6. Capacity\r7. Availability\r8. Configuration\r9. Horizon Inventory\r10. Horizon Infrastructure\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/downloads/",
      "title": "Downloads",
      "tags": [],
      "description": "",
      "content": "Below you\u0026rsquo;ll find links to download common files referenced in this site:\nvSphere Metrics\rOperationalize Your World\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.8-configuration/",
      "title": "8. Configuration",
      "tags": [],
      "description": "",
      "content": "Consistent configuration is important in DaaS, which is made of many softwares (Horizon, vSphere, NSX, vSAN, physical network, client, etc.). We\u0026rsquo;re following the configuration dashboard best practices set in Part 3 Chapter 1 Design Consideration.\nIncorrect Configuration Address settings that are incorrect, insecure, not following your corporate standards or against Horizon best practice. Outdated Configuration The settings are correct, but on older version. It\u0026rsquo;s hard to keep up with all the vendors releases, so you should prioritize those oldest versions, especially those no longer supported. Complex Configuration The settings are correct and up to date, but they complicates your DaaS operations. Inefficient Configuration The last step is about cost and capacity, as there is nothing wrong already. You want to maximize the usage of your resources while minimizing your cost. While the server-side is under your control as Horizon administrator, the client-side depends on users cooperation. Using a pie chart, you can see what are the most common type of client, and their version of Horizon client software.\nAt the server-side, ensure your Horizon agents software are up to date.\nThe agents reporting version 0 - 0 could be test agent. Don\u0026rsquo;t worry about them.\nThe simplest form of configuration widget is a table that lists the settings you\u0026rsquo;re interested. The following shows an example for VDI Pool.\nAnd here is the example for RDS Farm\nFor Connection Servers, consider checking the following. Group them by the Pod, as the servers within a pod should be consistent.\nIf performance matters, check the power management of ESXi Host. For the clusters hosting the actual sessions, set it to high performance, and not balanced.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.8-consumer-update-it/",
      "title": "8. Consumer / Update It?",
      "tags": [],
      "description": "",
      "content": "The \u0026ldquo;Consumer / Update It?\u0026rdquo; dashboard complements the main VM configuration dashboard by displaying the actual VMs, with their relevant information. It is designed for vSphere administrator and platform team, to facilitate the follow-up action with the VM owners. It is a part of 8 dashboards that check the environment for optimization opportunities.\nThe dashboard follows the same design consideration with the Consumer / Correct it? dashboard. In fact, the 8 dashboards that form the Optimization Flow is designed as a set. You are meant to use them together as you go through the optimization review process.\nHow to Use The dashboard is just a collection of tables (List View), which can be reviewed independently. There is no flow among them.\nClick the object name to navigate to the Object Summary page to view more configurations. There can be valid reasons why specific configurations are not followed. It is recommended that you discuss best practices with VMware.\nAbout Outdated Tools table\nIt lists all the VMware Tools version that is still supported. You should tailor the filter to fit your operational needs. About Outdated VM Hardware\nIt lists all the VM vmx versions that are not 13, 14, 15, or 16. You should tailor the filter to fit your operational needs. About the outdated Windows and Red Hat\nIt lists all Microsoft Windows client version that are not version 10 It lists all Microsoft Windows server version that are not version 2016 and 2019. It lists all Red Hat Enterprise Linux version that are not version 7 or 8. If you run other Operating Systems like Ubuntu, clone the widget. Or repurpose the widget if you don\u0026rsquo;t run RHEL and MS Windows Points to Note See the Points to Note section of Consumer / Correct it? dashboard. This dashboard follows the same design consideration with the dashboard, hence share the same limitations and customization idea.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/3.3.8-vm-rightsizing/",
      "title": "8. VM Rightsizing",
      "tags": [],
      "description": "",
      "content": "The VM Rightsizing dashboard helps you in adjusting the VM size for optimal performance and capacity. It covers both undersized and oversized scenarios. It is designed for both the Capacity team and the Operations team, as rightsizing VM has benefit for day to day performance.\nHow to Use Select a data center from the Data centers table\nThe cluster capacity remaining is provided to give better context. Focus on reclaiming on cluster that is low on capacity remaining, and focus on upsizing on cluster with high capacity remaining. The 4 tables showing the rightsizing is automatically shown.\n2 tables for upsizing recommendation. One for CPU and one for Memory. 2 tables for downsizing recommendation. One for CPU and one for Memory. The business processes for oversized and undersized VMs are different, as one requires the affected VM to be shut down and the Owner to give back resources. For upsize, you want to add incrementally or even automate this process. For downsize, you want to remove in one change window as the effort to reduce is the same and there will be only one downtime. The metrics used are Summary \\ Oversized \\ Virtual CPUs and Summary \\ Undersized \\ Virtual CPUs. It stores the capacity engine calculation on recommended number of vCPUs that must be removed or added. Points to Note You can enhance the dashboard if you need to convey the overall situation to senior management. You plot every single powered-on VM in the environment, sized by their vCPU. In this way, the monster VMs will be highlighted. A 64 vCPU VM will appear 64x larger than a single vCPU VM. This is good as the focus should be on the large VM, as discussed here.\nThe heat map colors the VM by its capacity remaining. A VM with high capacity remaining means it has plenty of wastage resources.\nWhat would it look like on an environment with many monster VMs that are oversized? You get something like this. The grey boxes dominate the space of the heat map. One of the boxes consist of 48 VMs with total \u0026gt; 1000 GHz. All of them have 87.79% capacity remaining. Another word, they are oversized.\nYou may want to do the same for memory.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.8-vsan-utilization/",
      "title": "8. vSAN Utilization",
      "tags": [],
      "description": "",
      "content": "The vSAN Utilization dashboard complements the vSAN Contention dashboard. Together, their goal is to help VMware Administrator in performance management.\nUse this dashboard to identify vSAN clusters with high utilization in a selected data center. When utilization exceeds 100%, performance can be negatively impacted especially when VM experience contention. By default, vRealize Operations has a 5-minute collection interval. For 5 minutes, there may be 300 seconds worth of data points. If a spike is experienced for a few seconds, it may not be visible if the remaining of the 300 seconds is low utilization.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nHow to Use Review the Clusters Utilization table\nIt lists all the vSAN clusters, sorted by the least performing. The table shows the highest 5-minute average in the given period. Peak was chosen due to customers focus on peak when it comes to performance monitoring. To avoid outlier, change to 99thpercentile if that fits your operations better. vSAN clusters IOPS and Throughput are typically correlated with the number of host and VM. Select a vSAN cluster from the table\nAll the health charts will automatically show the KPI of selected cluster. Both IOPS and Throughput as large block size can result in high throughput in relatively low IOPS. If you are seeing large block size when You are not expecting it, investigate which applications are the using it. Read and Write are split as they tend to have different patterns. Health chart is not used as utilization can\u0026rsquo;t be color coded. Max IOPS among capacity disk is shown as a disk has a limit, especially magnetic disk. A typical magnetic disk delivers ~200 IOPS, and this can be easily saturated. Review the Disk Groups table It lists all the vSAN clusters, sorted by the least performing. Select a Disk Group from the table All the health charts will automatically show the KPI of selected cluster. Points to Note See the vSAN Contention dashboard as this dashboard is designed to complement it.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.8-distribution-chart-limitation/",
      "title": "8 Distribution Chart Limitation",
      "tags": [],
      "description": "",
      "content": "There are 2 types of distribution charts:\nRelative distribution: pie chart and donut chart Absolute distribution: bar chart They have the following limitations:\n\u0026quot;No data to display\u0026quot; does not imply that there is something wrong with vRealize Operations data collection process. It might signify that none of the objects meets the filtering criteria of the widget, hence there is really nothing to display. To see the content of a slice in a pie-chart or a bucket in a bar-chart, simply click on it. Note that the list cannot be exported. You can however click on the object name, which will take you to the object summary page. The page provides key configuration information, alongside other summary information. The pie-chart and bar-chart cannot drive other widgets. For example, you cannot select one of the pie-slices or buckets, and expect it to act as a filter to a list or a table. You can apply a specific color in a pie chart or distribution chart for a specific numeric value, but not string value. For example, you can\u0026rsquo;t apply a red color to the value \u0026ldquo;Not Installed\u0026rdquo;. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.8-peak-utilization/",
      "title": "8. Peak Utilization",
      "tags": [],
      "description": "",
      "content": "One common requirement we get from customers is the need to size for peak. We often see mistakes in defining what peak actually is, as by default, averages get in the way.\nSo let\u0026rsquo;s elaborate on peaks.\nHow do you define peak utilization or contention without being overly conservative or aggressive?\nThere are two dimensions of peaks. You can measure them across time or members of the group.\nLet\u0026rsquo;s take a cluster with 8 ESXi hosts as an example. The following chart shows the 8 ESXi utilizations.\nWhat\u0026rsquo;s the cluster peak utilization on that day?\nThe problem with this question is there are 1440 minutes in a day, so each ESXi Host has at least 288 counters (based on the 5-minute reporting period). So this cluster has 288 x 8 = 2304 metrics on that day. A true peak has to be the highest metric among these 2304 metrics.\nTo get this true peak, you need to measure across members of the group. For each sample data, take the utilization from the host with the highest utilization. In our cluster example, at 9:05 am, host number 1 has the highest utilization among all hosts. Let\u0026rsquo;s say it hit 99%. We then take it that the cluster peak utilization at 9:05 am is also 99%.\nYou repeat this process for each sample period (e.g. 9:10 am, 9:15 am). You may get different hosts at different times. You will not know which host provides the peak value as that varies from time to time.\nWhat\u0026rsquo;s the problem of this true peak?\nYup, it might be too sensitive. All it takes is 1 number out of 2304 metrics. If you want to ignore the outlier, you need to use percentile. For example, if you do 99th percentile, it will remove the highest ~23 datapoints.\nTake note that the most common approach is to take the average utilization among all the 8 ESXi hosts in the cluster. So you lose the true peak, as each data point becomes an average. For the cluster to hit 80% average utilization, at least 1 ESXi host must have hit over 80%. That means you can\u0026rsquo;t rule out the possibility that one host might hit near 100%.\nThe same logic applies to a VM. If a VM with 64 vCPUs hits 90% utilization, some cores probably hit 100%. This method results in under-reporting as it takes an average of the \u0026ldquo;members\u0026rdquo; at any given moment, then take the peak across time (e.g. last 24 hours).\nThis \u0026ldquo;averaging issue\u0026rdquo; exists basically everywhere in monitoring, as it\u0026rsquo;s the default technique when rolling up. For a more in-depth reading, look at this analysis by Tyler Treat.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.8-depth-vs-breadth/",
      "title": "8. Depth vs Breadth",
      "tags": [],
      "description": "",
      "content": "What do you notice from the following screenshot?\nNotice the Maximum is \u0026gt;10x higher than the average. The average is also very stable relative to the maximum. It did not move even though the maximum became worse. Once the Cluster is unable to cope, you\u0026rsquo;d see a pattern like this. Almost all VMs can be served, but 1-2 were not served well. The maximum is high because there is always one VM that wasn\u0026rsquo;t served.\nBe careful when you look at counters at parent object such as cluster and datastore, as average is the default counter used in aggregation. Review the following cluster level chart. Do you notice a problem?\nThat\u0026rsquo;s right. No performance issue at all in the last 7 days. The cluster is doing well.\nThis cluster runs more than 100 VMs. What you see above is the average experience of all these VMs, aggregated at cluster level. If there is only a few VMs having a problem, but the majority are not, the above fails to show it.\nWhat you need is a cluster-level metric that tracks if any of the VMs is having contention. We have that, and the result is telling.\nSame pattern, but the scale is 6000%!\nThe following diagram explains how such thing can happen.\nThe above charts show 6 objects that have varying disk latency. The thick red line shows that the worst latency among the 6 objects varies over time.\nPlotting the maximum among all the 6 objects, and taking the average, give us two different results as shown below:\nThe chart shows that it is possible that the average is still well below threshold, but one or more objects was affected. The average number is stable. Only when the cluster is unable to serve ~50% of its VMs, will the average number become high. Therefore, the average is a poor roll up technique. It\u0026rsquo;s a lagging indicator.\nProactive monitoring requires insights from more than one angle. When you hear that a VM is hit by a performance problem, your next questions are naturally:\nHow bad is it? You want to gauge the depth of the problem. The severity also may provide a clue to the root cause. How long did the problem last? Is there any pattern? How many VMs are affected? Who else are affected? You want to gauge the breadth of the problem. Notice you did not ask \u0026ldquo;What\u0026rsquo;s the average performance?\u0026rdquo;. Obviously, average is too late in this case. By the time the average performance is bad, likely half the population is affected.\nThe answer to the 3rd question impacts the course of troubleshooting. Is the incident isolated or widespread? If it\u0026rsquo;s isolated, then you will look at the affected object more closely. If it\u0026rsquo;s a widespread problem then you\u0026rsquo;ll look at common areas (e.g. cluster, datastore, resource pool, host) that are shared among the affected VMs.\nWhen calculating the breadth of the problem, you need to use a stringent threshold. Without this, you will not be able to catch values that are just below the threshold. On the other hand, if you set it too low, you will get a lot of early warning.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.9-horizon-inventory/",
      "title": "9. Horizon Inventory",
      "tags": [],
      "description": "",
      "content": "\rThis page is still in draft.\nYou can check the distribution of desktops and applications among the pods. In the following examples, the last pod is much larger than the first pod, but has similar number of applications available. Compare this against your plan and design documentation.\nYou can do the same thing for RDS Farm\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.9-consumer-simplify-it/",
      "title": "9. Consumer / Simplify It?",
      "tags": [],
      "description": "",
      "content": "The \u0026ldquo;Consumer / Simplify It?\u0026rdquo; dashboard complements the main VM configuration dashboard by displaying the actual VMs, with their relevant information. It is designed for vSphere administrator and platform team, to facilitate the follow-up action with the VM owners. It is a part of 8 dashboards that check the environment for optimization opportunities.\nThe dashboard follows the same design consideration with the Consumer / Correct it? dashboard. In fact, the 8 dashboards that form the Optimization Flow is designed as a set. You are meant to use them together as you go through the optimization review process.\nHow to Use The dashboard is just a collection of tables (List View), which can be reviewed independently. There is no flow among them.\nClick the object name to navigate to the Object Summary page to view more configurations. There can be valid reasons why specific configurations are not followed. It is recommended that you discuss best practices with VMware.\nAbout the Large VMs (CPU, memory, and Disk) tables:\nA large VM, relative to the underlying ESXi host and datastore, requires more careful planning (Day 0) and monitoring (Day 2). Ensure that the VM size does not exceed the size of the underlying ESXi host. If your ESXi host has CPU hyper-threading, do not count the logical processor. Instead, count the physical core. For best performance, keep it within a (non-uniform memory access) NUMA boundary. During monitoring, verify if the VM is highly utilized. If the VM vCPU count is equal to the ESXi cores, and the VM is running at almost full capacity, you might not be able to run other VMs. Large VMs can impact the performance of other VMs, especially if it\u0026rsquo;s given higher shares. Only when the large VM is under-utilized, can the ESXi run other VMs. Note that if the number of configured vCPUs on a VM is higher than number of cores per socket on the ESXi, the VM can experience NUMA effect. If the ESXi has more than one physical CPU (socket), cross-NUMA access negatively impacts performance The larger the VM, the longer time is required to vMotion, Storage vMotion, and backup. For disk space, if the disk is thin-provisioned and under-utilized, you can deploy other VMs in the same datastore. Ensure that the snapshot is tracked closely, as the risk of capacity running out is higher for a large virtual disk. VMs with many virtual disks:\nIt is simpler to have a 1:1 mapping between Guest OS partitions and the underlying virtual disk (VMDK or RDM). For performance and capacity, evaluate the disks and partitions. Each virtual disk must be monitored in terms of IOPS, throughput, and latency. Having multiple virtual disks increases the monitoring and troubleshooting need. If the reason for having many virtual disks is performance, identify which counter serves as proof that multiple virtual disks are required. It is possible that the performance required is met by a single virtual disk. VM with many IP addresses or NICs:\nA VM might need multiple networks, such as production, back up, and management. It is recommended that you route the network interfaces through the NSX-Edge VM. A VM that has multiple network interfaces can bridge the network, causing security risks or network issues. A VM that is part of multiple networks can do so with just a single NIC card. A single NIC can be configured to access multiple networks, with each interface having their own IP configuration Points to Note See the Points to Note section of Consumer / Correct it? dashboard. This dashboard follows the same design consideration with the dashboard, hence share the same limitations and customization idea.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.9-network-performance/",
      "title": "9. Network Performance",
      "tags": [],
      "description": "",
      "content": "Use the Network Performance dashboard to view performance problems related to network such as high latency, frequent retransmit, and many dropped packets. This dashboard is designed for both VMware administrator and Network administrator, with the goal of fostering closer collaboration between the 2 team.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nThe dashboard enables drill down from distributed switch to the ESXi host and port groups in the switch, and then to the VM.\nHow to Use Review the Distributed Switches table\nIt lists all the switches, sorted by the highest packet dropped. The table splits the incoming traffic and outgoing traffic for better analysis. As the focus is performance and not capacity, the throughput counters are not shown. Select a switch from the table\nThe health chart will automatically show the dropped packet trend over time. However, it will not narrow down the list of port groups automatically, as the list of port groups are always showing all the port groups in your environment. If necessary, expand the 2 collapsed widgets. They are showing the network throughput and broadcast packets. Utilization is also shown so you can correlate if the dropped packets are due to higher utilization Review the port groups and ESXi hosts in the selected switch\nThey are automatically listed when you selected a switch from the table above. Just like the distributed switch, you can also see their relevant countes. If your environment has unused network switches, you can filter them out from this list, as this dashboard focuses on performance.\nPoints to Note Latency within a data center should be below one millisecond. Use vRealize Network Insight to study the latency or the retransmitting problems, caused by moving into the lateral traffic. Add a physical network using the appropriate management pack, such as True Visibility Suite. Most packets are unicast, between a pair of sender and receiver. If your environment has many VMs sending broadcast packets to everyone and multicast packets to many targets, add a Top-N widget to find out which VMs are sending these packets. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.9-dashboards-at-scale/",
      "title": "9. Dashboards at Scale",
      "tags": [],
      "description": "",
      "content": "The number of dashboards you will have depends on the size of the environment and the number of people managing it. An environment with 100 VMs in just 5 hosts and 1 cluster will need far fewer dashboards than a global environment with 100,000 VMs spread over 5,000 ESXi, 500 clusters, 20 data centers, and 15 vCenter Servers.\nIn a large environment, where you have many physical data centers and even more vSphere clusters, you will likely need to display the information per physical data center. There are several reasons for this:\nAggregating data at a global level, which spans many physical data centers, will hide too much information. Presenting data at such a level means you are getting an average of thousands of objects. If your environment is generally healthy (and it should be), the average will logically fall within a healthy range. In most cases, the performance in a given physical data center is independent from that of other data centers. For example, your Singapore data center typically does not impact the performance of your London data center. An exception to this case is when you link your data center at the network (stretched L2) and storage layers (synchronous replication). From experience in troubleshooting such a scenario, we recommend you keep the physical layer independent from each other. Assuming your data centers are independent, it makes more sense to display the chart on a per data center basis. VMs typically do not move from one physical data center to another (unless they are paired with storage replication and your network is stretched), so an imbalance among multiple data centers does not translate into a realistic rebalancing action. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.9-storage-capacity/",
      "title": "9. Storage Capacity",
      "tags": [],
      "description": "",
      "content": "Storage Capacity differs to Compute Capacity and presents a challenge on its own. Unlike compute capacity, which is basically vSphere cluster, storage varies in shape. The two major ones are datastore and vSAN, as local datastore and RDM is rarely used. We will discuss vSAN capacity separately as it has its own unique factors such as FTT, plus it needs to consider compute too.\nDatastore Capacity Similar to compute capacity, storage capacity is driven by 2 factors:\nContention If the datastore is unable to serve its existing VMs, meaning they are getting bad latency, are you going to add more VM? You are right, the datastore is full, regardless of how space it has left.\nThe key counters here are latency and outstanding IO.\nUtilization How much disk space is left? Thin provisioning makes this challenging. It requires us to use both the Demand Model and Allocation Model to properly answer the capacity remaining of a datastore.\nTake a look at the following two datastores.\nWhich one has lower capacity remaining? Which one would you choose to deploy additional VM?\nBoth have identical usable physical capacity at 10 TB, as shown by the black line. Both have identical allocation model, based on 2:1 overcommit. But they have different utilization and actual overcommit ratio. Datastore 1 has 5 TB used but 25 TB thin provisioned. Datastore 2 has 8 TB actual used but 12 TB thin provisioned. The red arrow shows the risk.\nTotal Capacity Used Capacity Demand Model 10 TB Datastore 1 = 5 TB\nDatastore 2 = 8 TB Datastore 1 = 50%\nDatastore 2 = 80% Allocation Model 20 TB Datastore 1 = 25TB\nDatastore 2 = 12 TB Datastore 1 = 125%\nDatastore 2 = 60% Datastore 1 has lower actual usage, but higher risk because it has more space over-committed than reclaimable. You should take the lower of the two capacity models. In this case, Datastore 2 is what you should choose.\nThin provisioning brings another complexity in the form of newly provisioned VMs, as their growth are not predictable. They can remain idle for months and suddenly grow their storage consumption. Their growth becomes relatively more predictable after they mature, which vary per business application.\nLastly, there is reclamation. I added the green arrow to indicate that you can have different reclaimable values. In the example above, Datastore 1 happens to have has more reclaimable space.\nCapacity Rollup Now that we know how to calculate the capacity of a single datastore, we are in the position to solve the roll up.\nDatastore may belong to datastore cluster. As datastore cluster groups datastores into a larger pool, we can treat them as one logical pool. This simplifies the capacity calculation.\nIt also makes capacity management easier in large environment with many datastores, as you treat the cluster as one. It makes the information \u0026amp; visualization more compact and manageable. From the datastore cluster, build a drill down.\nFor the overcommit ratio, we should allow a lower overcommit ratio at the datastore cluster level to account for the fact that the distribution among the datastore is not granular. The following diagram illustrates why.\nHow about rolling up to Data Center or vSphere?\nThis is not advisable. Different datastores in a vCenter can have different purposes, such as NSX Edge and business workload. The capacity they have are not interchangeable. Yes, that means we should not even calculate Total Capacity. If you have 1000 datastores globally with each having 1 TB of remaining space, you do not have 1 PB of space.\nSo what can you roll up?\nYou can roll up VM Remaining. This is simply the sum of VM Remaining on each datastore.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.9-leading-indicators/",
      "title": "9. Leading Indicators",
      "tags": [],
      "description": "",
      "content": "You want to be able to see performance problem while it\u0026rsquo;s still early, when only a small percentage of users or applications are affected. For that, you need a leading indicator. Leading indicators complement the lagging indicator by giving the early warning, so you have more time to react.\nAverage is a lagging indicator. The average of a large group tends to be low, so you need to complement it with the peak. On the other hand, the absolute peak can be too extreme, containing outliers.\nThe following table shows where Max() picks up the extreme (outlier) while average fails to detect the problem. This is where 95th percentile or 99th percentile makes more sense.\nThese are the technique to complement average() and maximum(). Depending on the situation, you apply the appropriate technique.\nWorst() This returns the worst value of a group. It\u0026rsquo;s suitable when the number of members are low, such as ESXi hosts in a cluster.\nIf you want to ignore outlier, then use Percentile function.\nIn some situations, you may need both Worst and Percentile for better visibility.\nPercentile() It is similar to the Worst() function, but it returns the number after eliminating a percentage of the worst. For example, if you take the 99th percentile, then you eliminate the worst 1st percentile and take the highest value.\nThe number of members must support the percentile function. If there are only 20 members, then each member corresponds to 5 percentile. You can\u0026rsquo;t do 99th percentile as that needs at least 100 members.\nYou need to adjust the percentile() band accordingly, taking into account the number of members in the array. For example, if you take the 99th percentile of 1 month worth of data, you\u0026rsquo;re eliminating the worst 7.4 hours. On the other hand, if you take 95th percentile of 1 day worth of data, you\u0026rsquo;re eliminating the worst 1.2 hours.\nCount() This is different to the Worst() or Percentile(), as you need to define the threshold first. For example, if you do Count of VM that suffers from bad performance, you need to define what bad is. That\u0026rsquo;s why Count() requires you to define the band for Red, Orange, Yellow and Green. You can then track the number of objects on the Red band, as you expect this number to be 0 at all times. Waiting until an object reaches the red band can be too late in some cases, so consider complimenting it with a count of the members in orange band.\nCount() works better than average() when the number of members is very large. For example, in a VDI environment with 100K users, 5 users affected is 0.005%. It\u0026rsquo;s easier to monitor using count as you can see how it translates into real life.\nDisparity() When members are uniformed and meant to share the load equally, you can also track the disparity among them. This reveals when part of the group is suffering when the average is still good.\nUsage Disparity Examples where you expect balance are:\nUsage among VM vCPU. If a VM has 32 vCPU, you don\u0026rsquo;t want the first 8 suffers while the last 16 are not used. Usage among ESXi in a cluster Usage among RDS Hosts in a farm Usage among Horizon Connection Server in a pod Usage among disk in a vSAN disk group There are 2 options to calculate unbalanced:\nDivide over total. This is a fixed number, as the total is a constant number. Divide over max (highest). This is a dynamic number, as the max is fluctuating. The unbalance is relative, as it depends on the value of the Max metric. Both use cases have their purpose. We are taking the first use for these reasons:\nThat\u0026rsquo;s the most common one. The second use case is used in low level application profiling or tuning, not general IaaS operations. It\u0026rsquo;s also easier to understand. It does not result in high number when unbalanced is low in absolute terms. See the charts below The following calculation shows that using the relatively unbalance results in a high number, which can be misleading as the actual unbalance is only 10%\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-9---infrastructure-architect/",
      "title": "Chapter 9 - Infrastructure Architect",
      "tags": [],
      "description": "",
      "content": "Chapter 9 Infrastructure Architect I see myself as an Infrastructure Architect. After almost a decade in application world, I entered the weird and wonderful world of enterprise IT infrastructure, starting as a presales with Sun Microsystems in 2003. My job titles, roles and departments have changed many times since then, but fundamentally it\u0026rsquo;s about architecting enterprise infrastructure. My official role is a Product Manager for an operations management product, but I still see myself as the engineer doing the performance troubleshooting and reading logs.\n1. The Chef and His Cooking\r2. Global Role\r3. Delivering a Lasting Presentation\r4. About the Author\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/miscellaneous/chapter-8---vdi--daas/4.8.10-horizon-infrastructure/",
      "title": "10. Horizon Infrastructure",
      "tags": [],
      "description": "",
      "content": "\rThis page is still in draft.\nOther than the desktops and RDS hosts, Horizon uses many types of application servers and databases.\nConnection Server The Connection Server is also a VM. At present, the KPI is identical to the RDS Host Universal Access Gateway This section is for rent. That means we need a contributing author! Reach out to me if you want to collaborate MS SQL Server This is covered in Part 3 True Visibility Dashboards, but we need to integrate the KPI with Horizon MS Active Directory Server This section is for rent. That means we need a contributing author! Reach out to me if you want to collaborate "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.10-consumer-optimize-it/",
      "title": "10. Consumer / Optimize It?",
      "tags": [],
      "description": "",
      "content": "The \u0026ldquo;Consumer / Optimize It?\u0026rdquo; dashboard complements the main VM configuration dashboard by displaying the actual VMs, with their relevant information. It is designed for vSphere administrator and platform team, to facilitate the follow-up action with the VM owners. It is a part of 8 dashboards that check the environment for optimization opportunities.\nA suboptimal configuration might not impact performance or increase complexity, but it can be more expensive.\nThe dashboard follows the same design consideration with the Consumer / Correct it? dashboard. In fact, the 8 dashboards that form the Optimization Flow is designed as a set. You are meant to use them together as you go through the optimization review process.\nHow to Use The dashboard is just a collection of tables (List View), which can be reviewed independently. There is no flow among them.\nClick the object name to navigate to the Object Summary page to view more configurations. There can be valid reasons why specific configurations are not followed. It is recommended that you discuss best practices with VMware.\nVM Reservation:\nVM reservation causes a positive impact on the VM, but a negative impact on the cluster. Total reservation cannot exceed cluster capacity. This creates a suboptimal cluster as VMs do not use the entire assigned memory at the same time. VM reservation places a constraint on the DRS placement and HA calculation. Avoid using reservation as a means to differentiate performance SLA among all the VMs in the same cluster. It is difficult to correlate CPU Ready with CPU Reservation. A VM CPU Ready does not improve two times because you increase its CPU reservation by two times. There is no direct correlation. Guest OS visibility:\nSince your workloads are sharing resources and are over-committed, your operations are easier if you know what is running inside. This helps with monitoring and troubleshooting, resulting in more optimal operations. For critical VMs, consider logging the Guest OS (e.g. Windows, Linux) to capture errors that do not surface as metrics. These errors typically appears as events in the log files, or Event database it the case of Microsoft Windows. Use Log Insight to parse Windows events into log entries that can be analyzed. Snapshot:\nOld snapshots tend to be larger. They consume more space and have a higher chance of impacting performance. Points to Note See the Points to Note section of Consumer / Correct it? dashboard. This dashboard follows the same design consideration with the dashboard, hence share the same limitations and customization idea.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.10-vm-contention/",
      "title": "10. VM Contention",
      "tags": [],
      "description": "",
      "content": "The VM Contention Dashboard is the primary dashboard for VM performance. It\u0026rsquo;s designed for VMware Administrators or Architects, and can be used in both monitoring and troubleshooting. Once you determine there is performance issue, use the VM Utilization dashboard to see if the contention is caused by very high utilization.\nThe dashboards answer these questions:\nAre the VMs performing well? If not, which VMs are affected by what problems (CPU, Disk, RAM, Network)? Is the VM performance caused by IaaS not serving it, or by contention within the Guest OS? Are the VMs running high utilization? If yes, which VMs, how high, and what resource (CPU, RAM, Disk, Network)? Are they really high relative to the underlying IaaS capacity? That can cause strain in the shared infrastructure. Any VMs need to be right-sized? By how much and for which resource? For disk, we need to look inside each partition, not at VM level. You can also go back to any point in time, and ask the same questions above. This is important as by the time you have the chance to look at the problem, 5 minutes have passed, or the problem is no longer happening.\nDesign Consideration This dashboard is designed to be used as part of your Standard Operating Procedure (SOP). It is designed to be used daily, hence the views are set to show data in the last 24 hours. This is to encourage daily usage, as what happens beyond 24 hours ago may be practically irrelevant from performance troubleshooting viewpoint.\nData center is used as the boundary for scalability and usability, as showing tens of thousands of objects will impact the dashboard performance and complicate the troubleshooting process.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nFor understanding the performance concept of the selected counters and their thresholds, see the official VMware Documentation on Performance Dashboards.\nHow to Use Select a data center from the Data Center table\nFor small environment, select vSphere World to see VMs from all the data centers. Note that the count of VM includes powered off VMs. If you need to exclude them, modify the widget and choose running VM metric. Analysing by data center makes sense as performance problems tend to be isolated in a single physical environment. A performance problem in country A typically does not cause performance problem in country B. The bar charts above will be automatically shown.\nUse them together to get an insight if you have CPU or Memory performance problems. Each chart analyzes how the VMs are served by the cluster. For each VM, it picks the worst metric in the last 24 hours. By default, vRealize Operations collects every 5 minutes, so this is the highest value among 288 datapoints. Once it has the value from each VM, the bar charts put each VM in the respective performance buckets. The threshold in the buckets consider best practice, hence they are color coded.\nFor your mission-critical environment, you should expect that all the VMs are being served well by the IaaS. So expect to see green on both distribution chart. For development, you may tolerate a small amount of contention in both CPU and Memory.\nThe table listing all the VMs in the selected data center is automatically shown. A portion of the table is shown below.\nThe table shows the hostname as known by Windows or Linux. This is the name that application team or VM owner know, as they may not be familiar with the VM name.\nThe rest of the columns show performance counters. Because the goal is proactive monitoring, as opposed to reactive troubleshooting, the counters show the worst value instead of the average of the monitoring period. For example, the CPU Ready counter shows the highest CPU Ready within the period you specify. The default period is 24 hours, as the dashboard is designed to be part of the daily SOP.\nThe table is sorted by KPI Breached column, directing your attention to the VMs that are not served well by the IaaS.\nThe column KPI Breached counts the number of SLA breaches in any given 5 minute period. As a VM consumes 4 resources of IaaS (CPU, Memory, Disk, Network), the counter varies from 0 - 4, with 0 being the ideal. The value 4 indicates that all 4 IaaS services are not delivered. Note that the same threshold is used regardless of class of service, as this is an internal KPI, not an external SLA. Your internal threshold should be more stringent, so you have reaction time.\nChoose a VM from the table. All the health charts are automatically shown, showing KPIs of that VM.\nEach of the health charts is color coded according to the best practice of that counter. You can change it by simply editing the widget. The chart also displays the last value, lowest value and the peak value of the monitoring period. Expect that the peak is within your threshold.\nGoing back to the table, I\u0026rsquo;ve circled the first VM disk latency. It\u0026rsquo;s showing 79.48 ms latency, hence shown in red. That number corresponds to the peak shown in the Disk Latency health chart below.\nPoints to Note If you need more granular visibility, you can use the following metrics\nPeak vCPU Ready (%) tracks if any of the virtual CPU is experiencing high CPU Ready. It takes the highest among the vCPU. This can be useful in large VMs with many vCPU. Peak Virtual Disk Read Latency (ms) and Peak Virtual Disk Write Latency (ms) track whether any of the virtual disks (either VMDK or RDM) is experiencing latency. This can be useful in large VMs with many virtual disks. Disk Outstanding IO is an average of both read and write. If you prefer better visibility, show read and write separately. If you need more space, remove the CPU Swap Wait. Its value is covered by Memory Contention.\nThe VM counter Performance \\ Number of KPIs Breached tracks the number of KPIs breached. The value ranges from 0 (no breached, which is the ideal state) to 4 (all 4 IaaS services are not delivered well).\nIf the Guest OS counters are not showing up, check that you meet the requirements.\nThe health chart is color coded. Change the settings if it does not suit your environment. If you are unsure of what suitable numbers to set for your environment, profile the metrics. The Guest OS Performance Profiling dashboard provides an example of how to profile metrics.\nFor a smaller environment with just 1-2 Data centers, changing the filter from data center to cluster makes more sense. Once you are listing cluster, you can then add the cluster performance (%) metric and sort them in an ascending order. This way the cluster that needs immediate attention is on top.\nIf you have screen real estate, group the VMs by cluster or by ESXi. In this way, you can quickly see if the problem is in particular cluster or ESXi.\nChange the default timeline from one week to one day as and when required to suit your operations.\nThe Dropped Packet (%) formula is (dropped / (dropped + transferredPackets)) * 100%. In a rare case where there is no packet at all, the result shows undefined (blank). This is because the maths of 0 / 0 = undefined.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/3.1.10-dashboard-getting-started/",
      "title": "10. Dashboard Getting Started",
      "tags": [],
      "description": "",
      "content": "The Getting Started breaks tasks into three broad categories:\nManagement Flows Collections Use the Getting Started Dashboard to understand the relationship between these categories.\nThe Management category includes the seven pillars of operations, explained earlier.\nThe Flows category covers the Process part. It covers the Troubleshooting flow and Optimization flow.\nUse the Troubleshooting flow to resolve any potential issues related to availability, contention, utilization, and configuration. Troubleshooting is more than simply identifying the problem. It focuses on the reason behind the problem and also formulates a solution to prevent reoccurrence. An incident means that something is either dead, slow, or has been breached. You can troubleshoot availability, performance, and capacity. Use the Optimization flow to enhance the performance and lower the cost of your operations. You can choose to correct a problem area, update, simplify, or improve your VMs and infrastructure. You can optimize performance, capacity, cost, and configuration. You even improve the availability of your system to an extent but, you cannot enhance compliance or inventory. The Collection category comprises of Public Cloud and the Library sections.\nThe AWS and Azure dashboards are displayed under the Public Cloud dashboards. You can choose to view the overall performance of these services or view specific dashboards related to the services. The Library contains dashboards related to the Network Operating Center and the Executive. Using each of these categories you can drill down to the specific use cases and problems you are trying to solve. Each problem statement is associated with a predefined dashboard that you can access through this page. To view a dashboard, click the dashboard type and then select a dashboard on the Getting Started dashboard or click the dashboard name listed on the right side of the Getting Started dashboard.\nDeprecated dashboards are no longer in Getting Started since vRealize Operations 8.2. They are placed under the dashboard drop down menu, under Library. Avoid using them as they will be removed in the future.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.10-optimized-capacity/",
      "title": "10. Optimized Capacity",
      "tags": [],
      "description": "",
      "content": "Optimized Capacity means you run utilization at 100%, without wastage or compromising performance. There are two areas where you can optimize: consumer and provider.\nIn the consumer layer (process, guest OS, container, VM), you can optimize the following:\nIn the provider layer (ESXi, cluster, datastore \u0026amp; datastore cluster, distributed switch and port group, hardware), you can optimize the following:\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.10-baseline-profiling/",
      "title": "10. Baseline Profiling",
      "tags": [],
      "description": "",
      "content": "How do you profile your environment in order to set a threshold? How do you determine what\u0026rsquo;s acceptable? What\u0026rsquo;s the actual value in the last few months?\nAll the above can be answered via profiling your environment.\nLet\u0026rsquo;s say you have 5000 VM across 10 clusters. All these clusters provide the same class of service. You want to prove if 5% CPU Ready for VM is a good threshold, or you want to know the actual CPU Ready experienced by these VMs in the last 3 months.\nYou want to profile at least the last 3 months of data, so that any peak within that period is not excluded. Since vRealize Operations stores this counter every 5 minutes, you will have 288 datapoints in a day and 26,298 datapoints in 3 months.\nStep 1 For each cluster, you measure the worst CPU Ready experienced by any VM.\nA cluster with 500 VM will be represented with whatever VM that happens to experience the highest CPU ready at that 5-minute interval. So for every 5 minutes you analyze 500 metrics and take the worst.\nStep 2 You do the above for 3 months.\nSince there are 26,298 datapoints in 3 months, that means you analyze 13,149,000 data points\nStep 3 Taking the worst among 13+ millions will likely return you with an outlier.\nTo address it, you take the 99th percentile, after comparing the value at 100th, 99th and 95th. The average is not applicable as you want to be near the peak.\nYou record this as the worst CPU ready for that cluster in the last 3 months.\nStep 4 You repeat Step 1 - 3 for each cluster.\nThe above gives you the depth of the problem. As covered previously, you need to complement this with the breadth of the problem. The step is similar, except in Step 1 you calculate the percentage of VM experiencing \u0026gt; 2.5% CPU Ready.\nWhy 2.5% and not 5%?\nTo give you better visibility as the number \u0026gt;5% maybe too small.\nOnce you do the above for all the clusters, you may end up with something like this.\nWhat if you want to see the actual distribution of VM CPU Ready in the last 3 months? You can do so by creating a bar chart and specifying the distribution buckets. In the following example, I specify 0% - 1%, 1% - 2%, until 5% as those are the range that I\u0026rsquo;m interested.\nNotice I set the value to be the 99th percentile in this case, as taking the Max may give outlier.\nIf you want to see more example, I apply this baselining technique to figure out the value of CPU Context Switch and CPU Run Queue.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.11-provider-correct-it/",
      "title": "11. Provider / Correct It?",
      "tags": [],
      "description": "",
      "content": "The \u0026ldquo;Provider / Correct It?\u0026rdquo; dashboard complements the main vSphere configuration dashboards by displaying the actual vSphere objects, with their relevant information. It is designed for vSphere administrator and platform team. It is a part of 8 dashboards that check the environment for optimization opportunities.\nThe dashboard follows the same design consideration with the Consumer / Correct it? dashboard. In fact, the 8 dashboards that form the Optimization Flow is designed as a set. You are meant to use them together as you go through the optimization review process.\nHow to Use The dashboard is organized into 3 sections for ease of use.\nThe first section covers vSphere clusters configuration\nA cluster is the smallest logical building block for compute. Consider it as a single computer with physically independent components. As a result, consistency matters. Clusters with DRS set to manual. This means that DRS initiated vMotion does not take place unless it is manually approved by administrator. Since DRS calculates every five minutes, your quick approval is required to prevent a change of condition. Clusters with HA disabled. Without high availability provided by the infrastructure, each application must protect itself from infrastructure failure. Clusters with DRS disabled. DRS focuses on performance and capacity, while HA focuses on availability. Without DRS, you must build a buffer on every ESXi host to cope with peak demand. Clusters with Admission Control disabled. Reservation is respected only when Admission Control is enabled. The second section covers ESXi host configuration\nESXi with Network Time Protocol disabled. Incorrect time can turn logs from useful to potentially misleading. Logs are a critical component of operations, and are the main source of information in troubleshooting. While troubleshooting performance across objects, the sequence of logs determines which event is the likely root cause as the oldest event started the chain of events. A disconnected ESXi host indicates that the ESXi host is not participating in HA and you cannot migrate any VM on it. An ESXi host that is in maintenance mode does not contribute resource to the cluster (or data center in the case of standalone ESXi). The third section covers ESXi host configuration that need to be consistent within a cluster\nBIOS version and ESXi versions. BIOS Power Management, ESXi: Power Management. Ideally, should be set to OS controlled. The ESXi level should be set to balance level. ESXi Storage Path. Ensure that the number of paths and the path policies are identical. ESXi hardware specifications. Different specifications can result in inconsistent performances experienced by the VM. Points to Note See the Points to Note section of Consumer / Correct it? dashboard. This dashboard follows the same design consideration with the dashboard, hence share the same limitations and customization idea. If you have standalone ESXi and you plan to replace them with clustered ESXi host, add a table to list them. Based on your security settings, add a table to check Distributed Switch and Port Group to ensure that security settings such as promiscuous mode are used correctly. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.11-vm-utilization/",
      "title": "11. VM Utilization",
      "tags": [],
      "description": "",
      "content": "The VM Utilization dashboard complements the VM Contention dashboard. Together, their goal is to help VMware Administrator in performance management.\nDesign Consideration This dashboard is designed to support the VM Contention dashboard. Use it to identify VMs with high utilization in a selected data center. When utilization exceeds 100%, performance can be negatively impacted especially when queue developed inside the Windows or Linux. By default, vRealize Operations has a 5-minute collection interval. For 5 minutes, there may be 300 seconds worth of data points. If a spike is experienced for a few seconds, it may not be visible if the remaining of the 300 seconds is low utilization.\nSee the Performance Dashboard page for common design consideration among all the dashboards for performance management.\nHow to Use Select a data center from the Data center table\nFor small environment, select vSphere World to see VMs from all the data centers. Note that the count of VM includes powered off VMs. If you need to exclude them, modify the widget and choose running VM metric. The VM Peak CPU Usage bar charts will be automatically shown\nThere is no Peak Memory usage as it\u0026rsquo;s not actually that applicable. Memory is a form of storage. Consider the hard disk space occupied. A 90% utilization of the space is not slower than 10%. It\u0026rsquo;s a capacity issue, not performance. The bar chart is color coded. This time around, there are 5 colors not 4. The color grey is introduced to convey wastage. Resources that are hardly utilized may not mean performance is at peak. In fact, it could be the opposite. If a VM just need 1+ vCPU, configuring it with 2 CPU will result in better performance than configuring it with 128 CPU. The table listing all the VMs in the selected data center is automatically shown.\nAnalysing by data center makes sense as performance problems tend to be isolated in a single physical environment. A performance problem in country A typically does not cause performance problem in country B. The table focuses on peak utilization, because the context is performance, not capacity. You want an early warning, and the peak value delivers that. If you think this is too aggressive, change the formula to show the 99thpercentile value. For memory counter, the table shows counter from inside the Guest OS. The VM counter Consumed and Active are not shown as they are not about VM performance. I\u0026rsquo;ve customized the table above to use Gbps for storage and Mbps for network, as that\u0026rsquo;s more appropriate. Choose a VM from the table.\nUse Disk IOPS and Throughput together, especially for applications that use large block size. An IO with 250x block size (e.g. 1 MB instead of 4 KB) will generate equal throughput at 250x less IOPS, all else being equal Memory Paging is added in VM utilization dashboard and not VM contention dashboard, as paging metrics are not measuring slowness in memory. The only thing faster than memory is CPU, so memory performance means CPU is waiting for RAM. The waiting is typically caused by the page is not in the physical DIMM or CPU cache. Paging does not measure this slowness. In addition, virtual memory is an integral part of Windows and Linux memory management. It\u0026rsquo;s used alongside physical RAM, not after physical RAM is fully utilized. Microsoft Windows Super Fetch is an example of that integrated memory management. Disk Space is per Guest OS Partition. Reason is that\u0026rsquo;s how Windows or Linux manages their partitions or drives. If the Guest OS counters does not appear, that likely means either VMware Tools, ESXi, or vCenter fail to meet the minimum requirement. Once these are met, the counters will appear as no other configuration is needed in vRealize Operations. Compliment the free memory with the memory IOPS or the memory throughput metric. The metrics in gigabyte measure the space, and not the speed. Memory is a form of storage, so what you must measure is the rate, for example, read-write per second. Points to Note See the Points to Note section of VM Contention dashboard as this dashboard is designed to complement it.\nHealth chart is not used for these 2 reasons:\nSome utilization metrics do not have a \u0026ldquo;ceiling\u0026rdquo;, meaning we don\u0026rsquo;t know what \u0026ldquo;high utilization\u0026rdquo; is, as 100% is hard to define. Example of such metrics are disk IOPS and network throughput. High utilization actually means good performance. 100% utilization is in fact perfect performance, as that means more work is being done. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.11-reclamation/",
      "title": "11. Reclamation",
      "tags": [],
      "description": "",
      "content": "Reclamation delivers many benefits, and some of them are listed below\nThere are 6 areas of reclamation, from the easiest to the hardest. Naturally, the logic differs for each.\nNon VM files are the easiest, because they are not owned by someone else. They are yours! Non VM objects, such as templates and ISOs should be kept in 1 Datastore per physical location. Naturally, you can only reclaim Disk, and not CPU \u0026amp; RAM.\nAn orphaned file is a file in the datastore that is no longer associated with any VM. Orphaned VMs and orphaned VMDK\u0026rsquo;s are not even registered in vCenter. If they are, they may appear italicized, indicating something wrong. They may not have owners too.\nFor orphaned RDM (raw device mapping), look from the storage array if there is any ESXi mounting it.\nSnapshots are not backups, and they do cause performance problems to the VM if kept for extended periods of time. Keep them only for the purpose of protection during change. Once the change is validated as successful, keeping the snapshot does a disservice to the VM. A Snapshot is easier to reclaim, hence vRealize Operations lists them separately.\nTRIM and Unmap When Guest OS delete files or parts of it, it does not replace the value with 0 and just leave the block. This is more efficient and also enable recovery. But this cause the underlying VMDK to grow. The same thing happen at the array level. This is where Trim and Unmap come in.\nvRealize Operations tracks the unmap operations via 2 metrics at ESXi Host. The first one is Unmap IO, which tracks the number of unmap SCSI instructions. For example, if the value is 100, that means ESXi has sent 100 requests of unmap to its datastore. So think of it like IOPS, except the IO is not writing/reading actual block, but more of a request to delete (unmap) the block in the back end array. The value is the sum of 20 seconds since vSphere reports per 20 seconds, then averaged over 5 minutes. In the example below, you can see the host sends unmaps commands frequently in the last 30 days.\nThe second metric is Unmap Size, which tracks the total unmapped space from the operations above. The value is shown in MB.\nYou can track both operations on each datastore, but you can\u0026rsquo;t aggregate them per datastore.\nFor further reading on TRIM and Unmap in vSAN, read this detail article by Patrick Kremer.\nThe problem only happens on thin provisioned disk. So if you want to check how much space you can reclaim, create a view that compare the value inside the Guest vs the value shown at VMDK level.\nPowered-Off VM Powered Off VMs are harder, as there is now an owner of the VM. You need to deal with the VM Owner before you delete them. This is where tagging them with the owner email or Business unit would have been useful.\nWhy do cars have brakes?\nSo they can go faster!\nTake advantage of Powered Off as the brakes for your Idle VMs. If you treat Idle and Powered off as 1 continuum, you can power off the Idle VMs earlier. You get the benefit of CPU and RAM reclamation. It\u0026rsquo;s a safer procedure too, as you can simply power it back on if you find that the VM is actually being used.\nOne major caveat if you do this, is the average utilization of the remaining VMs in the cluster becomes higher. As a result, you may not be able to achieve the overcommit ratio needed to break even.\n2 Sides of Running VM Just like there are two rightsizing formula (one for Guest OS, one for VM), there are two reclamation formula for running VM (idle or not). The formula is complex as it has 2 different stages:\nBefore Determine if the VM falls under the category. For example, does the VM qualify as an Idle VM? This should look inside the VM, as that\u0026rsquo;s where the workload runs. Measuring at the ESXi level can yield incorrect results as that includes loads not generated by the VM.\nAfter Determine what can be reclaimed. Since what is being reclaimed is ESXi resources, the usage inside the Guest OS is irrelevant. The queue inside the Guest does not impact the hypervisor, so there is nothing to reclaim at the ESXi layer. All counters are from ESXi. Guest OS counters are not applicable as we\u0026rsquo;re not reclaiming from inside the Guest.\nSo you need to apply 2 different types of logic.\nIdle VM Idle VM is a great target, as you can now claim CPU and RAM when you power them off. You cannot claim disk yet as you are not deleting them yet. Take note that you are not reclaiming real CPU cycle as it\u0026rsquo;s idle to begin with. Idle VM does not actually consume any ESXi CPU cycles. So reclaiming a 10 vCPU VM running only 1 vCPU does not give you 9 vCPU. You are reclaiming blank air. For memory, you will reclaim real ESXi memory as idle VMs tend to have its consumed memory remained on ESXi.\nLet\u0026rsquo;s look at the first part of the formula, where we decide if a VM is idle or not. VM that is rarely used can appear idle, if you measure idleness over a long period of time. For example, if a VM is only productive (from business viewpoint) for 2 hours a week, that means the remaining 166 hours should be classified as idle. That\u0026rsquo;s 98.8% idle.\nTake note that a longer time window would increase accuracy but also lengthen the time taken to move in and out the Idle VM definition.\nYou can apply the above logic by creating a List View. Take note of corner cases such as VMs that have month-end processing. Even if you set 99% for 1 month the logic can still wrongly mark an active VM as Idle. 1% active means it\u0026rsquo;s only active for a total of 8 hours (0.3 days) in 30 days. Notice it\u0026rsquo;s a total, not a continuous 8 hours. It\u0026rsquo;s cumulative within 30 days. Ideally, you want a daily check, meaning it has to be idle every single day.\nA VM that is idle for 30 days straight, then active for 8 hours, will only need 8 hours to be marked as non-idle. A VM that does not accumulate 8 hours of CPU \u0026gt; 100 MHz, will obviously need more time. So the VM may be wrongly marked idle for days after it\u0026rsquo;s gone active.\nThe drawback of setting at 99% is we have to wait for the full 30 days before deciding. In some corner cases, the VM may never be marked as idle. Take a scenario:\nA VM was active and served its purpose for months. After 2 years, the application is being decommissioned as a new version is being released. As a result, the VM goes idle, as it is simply waiting to be deleted. But because we set at 99%, the logic will wait for the full 30 days before deciding. It\u0026rsquo;s consuming CPU/RAM during the period, as basic services like AV and OS Patches still run. If these non-app workloads add up to \u0026gt;8 hours in 30 days, the VM will never be marked as Idle. Starting from vRealize Operations 7.5, Idle VM has a fixed threshold of 100 Mhz. This means 5% utilization in a single vCPU VM running on a 2 GHz ESXi. This also means 0.25% on a 20 vCPU on the same ESXi. The reason for static is idle by definition is absolute, not relative to the VM size. Oversized VM is relative.\nWhile a VM uses CPU, RAM, Disk and Network, we only use CPU as a definition for Idle. There is no need to consider all 4, and require all 4 to be idle, because they are inter-related. It takes CPU cycles to process Network Packets and perform Disk activity. Data from the NIC and Disk must be copied to RAM also, and the copying effort requires CPU cycles.\nTake note of a corner case limitation of VM with runaway CPU, where CPU is high but no meaningful memory access, network transmission (TX) and disk processing. Idle VM will fail to detect it. It\u0026rsquo;s a corner case, hence I think it\u0026rsquo;s not worth the complexity. Also, the CPU runaway typically happens on a process, which likely a single threaded. Use the CPU Usage Disparity (%) metrics to detect that.\nIdle has to be defined so it\u0026rsquo;s measurable and not subjective. Declare it as a formal policy so you don\u0026rsquo;t end up arguing with your customers.\nIdleness has to consider how long has it been under that threshold.\nA VM does not use CPU non-stop for months. It is normal that there are times when it\u0026rsquo;s idle. A month-end VM that processes payroll can be idle for 29 days.\nBy definition, idle means it\u0026rsquo;s not doing useful business workload. A VM that is doing only non-business workload (e.g. AV scan, Windows regular update) should be considered as idle.\nvRealize Operations use the Reclaimable Idle metric to indicate if a VM is idle or not. The value is set to 1 (true) if the counter Idleness Indicator = 1 for N consecutive days (default value for N is 7 days). This is a daily counter, shown 1x a day as shown in the following example:\nThe Idleness Indicator is a property, so value only shown if it\u0026rsquo;s changed. It\u0026rsquo;s rolling counter, calculated every 5 minutes but each value takes the last 24 hours. As you can see in the following example, its value is only stored if there is a change.\nIdleness Indicator value = 1 if CPU Usage \u0026lt; 100 MHz continuously for 24 hours.\nIn some environment, it can take time before a newly provisioned VM is used. Check the creation date of the VM before powering it off.\nOversized VM Oversized VM has different logic than idle VM since the Idle VM definition does not depend on the size of the VM. The Idle VM definition simply measures if the VM is generating enough workload or not.\nIdle has an absolute definition (100 MHz in vRealize Operations 7.5). Oversized VM depends on the size of the VM. A 64 vCPU VM running 7 vCPU is oversized, while an 8 vCPU running 7 vCPU is not.\nIdle is defined in GHz, while Oversized in %.\nVM is undersized Calculated based on CPU \u0026amp; RAM total capacity and recommended size values.\nIf for at least one of the containers (CPU or RAM) the recommended size \u0026gt; total\nThe lowest value for increasing the CPU is 1 vCPU and for memory is 1 GB\nVM is oversized The VM is oversized if it is possible to reclaim a CPU or Memory.\nCalculated based on CPU \u0026amp; RAM total capacity and recommended size values.\nVM Reclaimable CPU Calculated based on socket counts and core counts of VM\n= Minimum (( reclaimable Sockets * cores Per Socket + reclaimable Cores In Remaining Sockets), CPU Core Count - 2) Will not suggest the reclamation if the CPU Reclaimable value \u0026lt; MHz Per Core value\nVM Reclaimable Memory = total Capacity - recommended Size Must be =\u0026gt; 1 GB and the remaining capacity after reclamation should be =\u0026gt; 2 GB\nReclamation Approach Active VM is politically the hardest, as they serve business workload. Focus on large VMs first. Take on CPU and RAM separately as they are easier to tackle when you split them. Divide and conquer. If you reduce both, and application team claim performance impact, you need to restore both. Claiming CPU and RAM from small VMs can be futile, regardless of idleness. An idle VM with one vCPU cannot be further reduced. Focus on the large VMs, for the reason covered here.\nWhen reducing oversized VM or powering off idle VMs, focus on large VMs. Let\u0026rsquo;s take an example for comparison:\nReduce 20 large VM. Average reduction is 10 vCPU. Reduce 100 small VM. Average reduction is 2 vCPU. In both scenarios, you reclaim 200 vCPU. But the large VM option delivers more benefits and is easier to realize. Here is why:\nEvery downsize is a battle because you are changing paradigm with \u0026ldquo;Less is More\u0026rdquo;. Plus, it requires downtime, which requires approval and change request process. Downsizing from 4 vCPU to 2 does not buy much nowadays with \u0026gt;20 core Xeon. No one likes to give up what they are given, especially if they are given little. By focusing on the large ones, you spend 20% effort to get 80% result. Large VMs are also bad for other VMs, not just for themselves. They can impact other VMs, large or small. ESXi VMkernel scheduler has to find available cores for all the vCPUs, even though they are idle. Other VMs may be migrated from core to core, or socket to socket, as a result. There is a counter in esxtop that tracks this migration. Large VMs tend to have slower performance. ESXi may not have all the available vCPU for them. Large VMs are slower as all their vCPU have to be scheduled. The counter CPU CoStop tracks this. Large VMs reduce consolidation ratio. You can pack more vCPU with smaller VMs than with big VMs. Unused VM Unused VM is not idle, but they do not provide business value anymore. The application team may have stopped using it, but left the application running just in case they need in the future. The VM is not idle as it still generates CPU activity. The activity can be business workload, IT workload, or both.\nThe IT workloads take many forms. Guest OS upgrade, updates and patches can be 3 different workloads with different patterns. VMware Tools patches, antivirus scan, intrusion detection scan n agent based back up are other common examples. In an environment with high security, there can be many security related agents running.\nBusiness workloads can be batch jobs, reports or monitoring. No one is using the application anymore but the application continues running. This is harder to identify than the one running pure IT workload.\nUnused VM is hard to detect as the infra team lack the business context, and the patterns vary widely. The owner verification is required before you power off the VM. This is why it\u0026rsquo;s important to have ability to relate a VM to a department or owner. We discussed the criticality of business-centric infrastructure in Part 1.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.11-optimized-performance/",
      "title": "11. Optimized Performance",
      "tags": [],
      "description": "",
      "content": "Optimized Performance is difficult because the best performance is achieved when utilization/throughput is at 100%. Running at that level requires a perfect level of mastery due to many dimensions of inter-dependencies.\nVertical dependency There are layers in the stack, and a problem in a lower layer can impact an upper layer.\nHorizontal dependency The four elements of IaaS are not standalone. When CPU is paused, RAM \u0026amp; Disk will experience latency as time shifts as far as the Guest OS is concerned.\nFlow dependency A problem in your NSX Edge VM on the NSX Edge Cluster can impact a business VM sitting on another cluster, because of the traffic flow. If you don\u0026rsquo;t understand the flow, you can waste time troubleshooting at the wrong cluster.\nVersion dependency There are valid reasons behind \u0026ldquo;What Works With What\u0026rdquo;. It\u0026rsquo;s a known problem that not all versions of all components work well together. Drivers, Firmware, etc. can cause interoperability problem, which can manifest itself as performance.\nConsumer Layer The consumer layer consists of VM and Container (which often runs inside a VM). Guest OS lives inside this, and in turn provides a platform for processes to run. So if you are running containers, you are adding a new layer to monitor. As you can see here, adding a new layer alters the metrics in the adjacent layers. If you have expertise in container monitoring, drop me an email!\nAt the Process level, there seems to be limited useful information for troubleshooting. The following shows Windows Sysinternal, a great tool for Windows troubleshooting. As you can see, they are just utilization counters.\nMore on CPU Context Switch is covered here.\nWe have better visibility at vSphere VM level due to the various counters provided. The following table lists the metrics and associated actions you can perform to address the issue.\nI do not put AWS EC2 or Azure VM here as the visibility is rather limited.\nLet\u0026rsquo;s now put together all the counters from Guest OS and VM. For completeness, I added the utilization counters too because the 5-minute average may be too long.\nThe KPI counters maybe too technical for some users, so vRealize Operations 8.2 includes a starting line to get them started. It sports a color coded dashboard. You adjust the threshold of the widgets of the dashboard if you think they do not meet your requirements. Only do so after you profile your environment, and not simply base on theory.\nProvider Layer At any given moment, a running VM always resides on an ESXi Host. Due to DRS and HA, it\u0026rsquo;s easier to monitor at cluster level. Since a cluster can have hundreds of VMs, you need consolidated metrics that can represent the experience of all the running VMs in the cluster. vRealize Operations 8.2 provides the following metrics:\nA running VM also consumes datastore service or has Raw Device Mapping (RDM) disk.\nHere is the list of potential problems at the provider layer:\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.12-provider-update-it/",
      "title": "12. Provider / Update It?",
      "tags": [],
      "description": "",
      "content": "The \u0026ldquo;Provider / Update It?\u0026rdquo; dashboard complements the main vSphere configuration dashboards by displaying the actual vSphere objects, with their relevant information. It is designed for vSphere administrator and platform team. It is a part of 8 dashboards that check the environment for optimization opportunities.\nAs part of operations best practices, keep the infrastructure up to date. Running outdated components that are too far behind the latest version, can cause support problems or upgrade problems. It is common that the fix for the problem is only available in the later versions. Outdated hardware can also result in higher operating costs. Outdated hardware might cost more data center footprint, such as rack space, cooling, and UPS. Refreshing your technology and consolidation are two common techniques to optimize cost.\nThe dashboard follows the same design consideration with the Consumer / Correct it? dashboard. In fact, the 8 dashboards that form the Optimization Flow is designed as a set. You are meant to use them together as you go through the optimization review process.\nHow to Use The dashboard is just a collection of tables (List View), which can be reviewed independently. There is no flow among them.\nClick the object name to navigate to the Object Summary page to view more configurations. There can be valid reasons why specific configurations are not followed. It is recommended that you discuss best practices with VMware.\nAbout the outdated vSphere components\nIt lists all the vCenter Server that are not 6.7 or 7.0. It lists all the ESXi Host that are not 6.5, 6.7 or 7.0 It lists all the vSAN ESXi Host that are not 6.7 or 7.0. A more stringent filter is applied for vSAN due to relatively higher maturity in the latest release. Specifically from vRealize Operations and Log Insight, there are more counters, properties and events that improve monitoring and troubleshooting. It lists all the vSphere Distributed Switch, regardless of version. You should tailor the filter to fit your operational needs. About Outdated Server BIOS\nIt lists all the ESXi regardless of the BIOS version. Edit the widget and tailor the filter to fit your operational needs. Other than customizing the existing widgets, consider adding the following checks.\nESXi hosts with outdated hardware, using a filter based on your environment. ESXi hosts that are no longer on warranty. Create a custom property to capture the end of warranty. Physical storage arrays with outdated firmware, model and expiring warranty expire. Physical network switch with outdated OS version and hardware model Note that the last 2 items above requires you to install relevant management pack.\nPoints to Note See the Points to Note section of Consumer \\ Correct it? dashboard. This dashboard follows the same design consideration with the dashboard, hence share the same limitations and customization idea.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.12-guest-os-performance-profiling/",
      "title": "12. Guest OS Performance Profiling",
      "tags": [],
      "description": "",
      "content": "There are counters that directly impact the performance of Windows or Linux, the Operating Systems running inside a VM. These KPIs are outside the control of the hypervisor, meaning ESXi VMkernel is not able to control the increase or decrease of their values. Visibility into these KPIs also requires an agent, such as VMware Tools. As a result, they are typically excluded in performance monitoring.\nBecause these KPIs are closer to the applications, it is critical to know their values and establish an acceptable range, which will vary in your environment. By profiling the actual performance over time and from of all VMs, you can establish a threshold that is supported by facts. Since there are 8766 instances of 5 minutes in a month, profiling 1000 VM over a month means you are analyzing 8.8 million datapoints, more than enough to draw a conclusion.\nDesign Consideration In larger environments, loading thousands of VMs into dashboards takes time. To make these dashboards load faster, we have grouped them by data center. For smaller environments, the vSphere World group is available to see all VMs.\nHow to Use Select a data center from the data centers list.\nThe three tables listing CPU, memory and Disk will automatically show the VMs in the selected data center or vSphere World. Each table shows the highest value in the last 1 week (2016 datapoints based on 5-minute collection cycles), hence their columns are prefixed with Max. About the CPU table widget The CPU queue is the sum of all vCPU. A larger VM can tolerate higher queue as it simply has more processors. If you want to compare VMs of different size, create a super metric that calculates the queue per vCPU. The Max CPU Queue column shows the highest number of processes in the queue during the given period. Best practices indicate you should stay below 3 for each queue. For a VM with 8 CPUs (8 queues), you want to be below 24. I can\u0026rsquo;t find documentation that states if CPU Hyper Threading (HT) technology provides 2x the number of queue length. Logically it should as the threads are at the start of the CPU pipelines, and both threads are interspersed in the core pipeline. CPU Context Switch. There is cost associated with context switch. The problem is there is no guidance for this number, and it varies widely. This is the very purpose of this dashboard! About the Memory list widget\nMemory paging: Modern operating systems (Linux and Windows) use memory as cache, it\u0026rsquo;s much faster than disk. It proactively pre-fetches pages and anticipates future needs (Windows calls this Super Fetch). The rate pages that are being brought in and out can reveal memory performance abnormalities. A sudden change, or one that has sustained over time, can indicate page faults. Page faults indicate pages aren\u0026rsquo;t readily available and must be brought in. If a page fault occurs too frequently it can impact application performance. While there is no concrete guidance, as it varies by application, you can view relative size. Operating Systems typically use 4KB or 2MB page sizes. About the Disk list widget\nDisk Queue are queued IO commands not sent to the VM. They have been retained inside the Guest OS (either at kernel level or driver level). High disk queue in the guest OS, accompanied by low IOPS at the VM, can indicate that the IO commands are stuck waiting on processing by Windows/Linux. There is no concrete guidance regarding these IO commands threshold as it varies for different applications. You should view this in relation to the Outstanding Disk IO at the VM layer. Select any VM from any tables above. The three line charts will appear automatically and will show data from the same VM to facilitate correlation.\nPoints to Note These guest OS metrics do not appear unless vSphere prerequisites have been met. Once you determine an acceptable threshold for your environment, consider adding thresholds to the table so you can easily see the VMs that exceed a threshold. Group the VM by clusters of the same class of service (e.g. Gold), so you can see the profile for each environment For smaller environment, consider changing the table from listing data centers to listing clusters. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/1.3.12-rightsizing/",
      "title": "12. Rightsizing",
      "tags": [],
      "description": "",
      "content": "Over Provisioning is a common malpractice in real life SDDC for a variety of reasons. P2V is a common reason, as the VM was simply matched to the physical server size. Another reason is conservative sizing by the vendor, which was then further added by Application Team.\nI\u0026rsquo;ve seen large enterprise customers try to do a mass adjustment, downsizing many VMs, only to have the effort backfire when the VM performance suffers.\nSince performance is critical, you should address it from this angle. Take serious time and effort to educate the VM Owner that right sizing actually improves performance, despite the seemingly odd logic. A carrot is a lot more effective than a stick, especially for those with money. Saving money is a weak argument in most cases, as VM Owners have paid for the VMs.\nRightsizing is important for a VM, more so than for a physical server. Here are some benefits:\nThe processes inside the Guest OS may experience less ping-pong. The Guest OS may not be aware of the NUMA nature of the physical motherboard, and think it has a uniform structure. It may move processes within its own CPUs, as it assumes it has no performance impact. If the vCPUs are spread into different NUMA node, example a 20 vCPU on a box with 2-socket and 20 cores, it can experience the ping-pong effect. Lower risk of NUMA effect. Lower risk that the RAM or CPU is spread over a single socket. Due to NUMA architecture, the performance will not be as good. Lower co-stop and ready time. Even if not all vCPU is used by the application, the Guest OS will still demand all the vCPU be provided by the hypervisor. Faster snapshot time, especially if memory snapshot is included. Faster boot time. If a VM does not have a reservation, vSphere will create a swap file the size of the configured RAM. This can impact the boot time if the storage subsystem is slow. Faster vMotion. Windows and Linux use memory as cache. The more it has, the more it uses, all else being equal. Severity of Over Provisioning If you have thousands of large VMs, how do you communicate easily to your senior management that many of the large VMs do not use the CPU given to them in the last few months?\nYou need to present a convincing chart, that shows the utilization of hundreds of large VMs (which you defined as having \u0026gt; 16 vCPU) every 5 minutes, so a short peak is not excluded in your presentation.\nThe first thing you need is to create a dynamic group that captures all the large VMs. Create 1 group for CPU, and one for RAM. You then plot their utilization, every 5 minutes, in the last 3 months.\nIn a perfect world, if all the large VMs are right sized, which scenario will you see?\nThat\u0026rsquo;s right. Scenario 2. Because the group has hundreds of members, there is a good chance that one of the large VMs is using the CPU given to it. On average, they should be hovering around 40 - 50%, as at any given 5-minute interval, some may be idle while others may be busy.\nThe technique we use for both CPU and RAM are the same. I\u0026rsquo;d use CPU as an example.\nOnce you create a group, the next step is to create two super metrics:\nMaximum() Maximum CPU Workload among these large VMs.\nYou expect this number to be hovering around 80%, as it only takes 1 VM among all the large VMs for the line chart to spike.\nIf your Maximum line is constantly ~100% flat, you may have a runaway process.\nIf you have many large VMs, one of them tends to have high utilization at any given time.\nIf this number is low, that means a severe wastage!\nMinimum() Average CPU Workload among these large VMs.\nYou expect this number to hovering around 40%, indicating sizing was done correctly.\nIf this chart is below \u0026lt;20% all the time for the entire month, then all the large VMs are oversized.\nWhy is it not needed to create the Minimum?\nThere is bound to be a VM who is idle at any given time.\nThe two line chart shows us the degree of over provisioning. Can you tell a limitation?\nIt lies in the counter itself. We cannot distinguish if the CPU usage is due to real demand or not. Real demand comes from the app. Non-real demands comes from the infra, such as:\nGuest OS reboot. AV full scan. Process runaway. This can potentially result in 100% CPU Demand if the application is multi-threaded. How to distinguish a runaway process from legitimate high workload is the challenge. 2 Sides of the Formula VM right-sizing is a commonly misunderstood term because there are actually multiple use cases, with each use case having their own factors to consider. Different scenarios require different metrics. It is not a one size fits all, hence there are more than one formula. Here are some popular use cases:\nYour App Team asks for extra vCPU. In this case, the hypervisor overhead is irrelevant. When you size NSX edge vCPU, you do not need to add extra vCPU for the overhead. It\u0026rsquo;s done outside of Linux. You are migrating a VM to a new ESXi with CPUs that are 2x the speed. For example, from a 2 GHz ESXi to 4 GHz. All else being equal, you can cut down the VM size by 2. A 16 vCPU becomes 8. But You are worried about causing queue inside the Guest OS as the application may expect 16 slow threads vs 8 fast ones. You are bulk migrating many VMs to another cluster, with no changes on their configuration. Consider 2 VMs. Both are running Windows Server 2019, have 64 vCPU. Both are running hot, but one of them is heavy on IO. It sends a lot of network packets and doing lots of disk IOPS. The 2nd VM has a very different footprint on the ESXi. It\u0026rsquo;s much more demanding. All those IO processing need to be processed by other physical cores. In this case, you need to consider the external footprint. The queue inside Guest OS is irrelevant. Your boss asks you to properly charge customers, accounting for what they are actually demanding. Would you charge the two VMs above the same way? You might for practical reasons, quietly distribute the cost equally, but you know You are not being fair. You are planning a tech refresh for Cluster X. It has 24 ESXi and 1000 VM. You are hoping to reduce infrastructure to 12 ESXi, hence you increase the CPU Speed and add cores per socket. Do you consider individual VM, or you do see how they behave as a group? The answer is the latter, as 1000 VM will not peak at the same time. Do you consider what happens inside Windows or Linux, or do you see their footprint on your ESXi? The correct answer is the latter, as what happens inside is irrelevant. From the above 5 use cases, we need at least two different formula:\nGuest OS Sizing. Excludes VM overhead, includes Guest OS Queue VM Sizing. Includes VM overhead, excludes Guest OS Queue Rule Description It\u0026rsquo;s not just utilization It needs to consider unmet demand. CPU wants to run, but it cannot. Memory has lots of page fault in Guest OS memory. It\u0026rsquo;s not just demand Size base on what the Guest OS needs to perform well, not just base on what it demands at present. Applicable for RAM, where Guest OS can\u0026rsquo;t operate optimally without buffer.\nIn capacity, we size not just for demand, but also for performance. While we can satisfy the demand for memory with just the In Use, it might come at the expense of performance. The only thing faster than memory is CPU. So make sure CPU is not waiting for data. This is done by caching as much as possible, as it\u0026rsquo;s hard to predict what pieces of data is required by the program. Includes peak Consider the busy or peak period, because that\u0026rsquo;s when the VM needs to work the most Consider big picture A single 5-minute burst is too short a timeframe to determine the entire next 3 months. Consider long term pattern. This alone makes sizing an art, as you need to know the nature of the workload. Excludes IT load Exclude the time when the Guest OS is not doing business workload. There are a few IT workloads that cause high utilization. Common ones are Guest OS reboot, Guest OS updates, anti-virus full scanning, agent-base full back up. So long as these tasks don\u0026rsquo;t prevent the Guest OS from doing useful work, you can exclude them. The exception is when your VM needs to run at these non-business hours too. So it depends on the VM.\nThis is the hard part, as it requires awareness of the footprint (read: process name) Sizing upwards and downwards should have identical formula.\nThe only difference is they have different boundaries. The lower boundary applies to downsizing, and the upper boundary applies to upsizing. For downsizing, Guest OS needs a minimum amount of RAM to operate. For upsizing, consider the NUMA boundary. Also, a VM should not be larger than the total number of logical processors on the ESXi Host, else it won\u0026rsquo;t even boot. In fact, it should be smaller as you want to account for the VMkernel overhead. As you can see from above, sizing is complicated. And the above is just Guest OS. We have not considered other things that need sizing such as Containers and Business Applications.\nThe art of sizing has 2 parts: time and metric.\nFirst, we calculate the value for a given point in time. The correctness of the input value matters, else you have GIGO effect. Second, we plot thousands of these values over time, and project it over time. The projection has to consider the peak cycle, meaning it has to be geared towards conservative sizing. It also has to consider the business cycle. If you have annual sales, then consider annual data. You\u0026rsquo;ll see below that CPU and RAM require different approach.\nGuest OS CPU Sizing You exclude all the VM overhead, as it\u0026rsquo;s not used by the Guest OS. For example, all the IO overhead performed by the hypervisor should not be included when determining how much CPU Windows or Linux should be configured with. For disk sizing, the snapshot is not part of your VMDK sizing.\nRule Description Exclude Hyper-Threading The Guest OS is running, regardless of speed and throughput. With lower efficiency, it will simply run longer. Instead of 40% for 5 minutes, it may run 90%. If it exceeds 100%, then queue will develop inside the Guest OS.\nThe Demand and Usage counters are not suitable as their values are affected by CPU Frequency and HT Exclude CPU Frequency As above. The only exception here is the initial sizing, when the VM is not yet created. The application team may request 32 vCPU at 3 GHz. If what you have is 2 GHz, you need to provide more vCPU. Exclude idle time The CPU is not running. It does not matter whether it\u0026rsquo;s because the Guest OS CPU is waiting for Guest OS IO. The net result is the Guest OS is not running its CPU. While making the IO subsystem faster will result in higher CPU utilization, that\u0026rsquo;s a separate scope. Exclude CPU Context Switch It is not something you can control. Plus it is impossible to translate its value into the right sizing formula. In addition, a high context switch could be caused by too many vCPU or IO. Guest OS is simply balancing among its vCPUs.\nThe Utilization may be high, but if CPU is doing a lot of context switch, it\u0026rsquo;s less productive. Include Co Stop \u0026amp; Ready The Guest OS actually wants to run. Had there been no blockage, the CPU would have been utilized. Adding/Reducing CPU does not change the value of these waits, as this represents a bottleneck somewhere else. However, it does say that this is what the CPU needs, and we need to reflect that.\nGuest OS number will be inaccurate because there is no \u0026ldquo;no data\u0026rdquo;, due to its time being frozen. Include VM Wait, Swap Wait Guest OS becomes idle as CPU is waiting for RAM or IO (disk or network). So this is the same case with Ready and CoStop. Include Overlap The Guest OS actually wants to run, but it\u0026rsquo;s interrupted by the VMkernel. Note that this is already a part of CPU Run, so mathematically is not required if we use CPU Run counter. Include Guest OS CPU Run Queue This is the primary counter tracking if Windows or Linux is unable to cope with the demand. Exclude hypervisor overhead MKS, VMX, System. While it\u0026rsquo;s part of Demand, it\u0026rsquo;s not a demand coming from within the Guest.\nThe VM CPU Used, Demand, Usage counter include system time at VM level, hence they are not appropriate. Based on all the above, the formula to size the Guest OS is:\nGuest OS CPU Needed (vCPU) = (Run + CoStop + Ready + VM Wait + Swap Wait) / 20000 ) + CPU Run Queue factor The result is in the number of vCPU. It is not in % or GHz. We are sizing the Guest OS, not the VM.\nWe need to divide by 20,000 because 20,000 milliseconds represent 100% of a single vCPU. More about this unit is explained here.\nGuest OS CPU Run Queue metric needs some conversion before it can be used. Let\u0026rsquo;s take an example:\nVM has 8 vCPU. CPU Run Queue = 28 for the entire VM. VM can handle 8 x 3 = 24 queues. There is a shortage of 28 - 24 = 4 queues. Each additional vCPU can handle 1 process + 3 queues. Conclusion: we add 1 vCPU. Compared with CPU Usage, Guest OS Needed without the CPU run queue factor tends to be within 10% difference. Usage is higher as it includes system time, and turbo boost. Usage would be lower in HT and CPU frequency clocked down case.\nHere is an example where Usage is higher.\nHere is an example where Usage is lower:\nOnce we know what the Guest OS needs, we can then calculate the recommended size. This is a projection, taking lots of value. Ideally, the recommendation is NUMA aware. It is applied after the sizing is determined. You size, then adjust to account for NUMA. This adjustment depends on the ESXi Host. So it can vary from cluster to cluster, if your vSphere clusters are not identical.\nGuest OS Recommended Size (vCPU) = round up NUMA (projection (Guest OS Needed (vCPU)) For basic NUMA compliant, use 1 socket many cores until you exceed the socket boundary. That means you use 2 vCore 1 vSocket instead of 2 vSockets with 1 vCore each.\nWith the release of Windows 2008, switching the Hardware Abstraction Layer (HAL) was handled automatically by the OS, and with the release of 64-bit Windows, there is no concept of a separate HAL for uni-processor and multi-processor machines. That means one vCPU is a valid configuration and you shouldn\u0026rsquo;t be making two vCPU as the minimum.\nYou should use the smallest NUMA node size across the entire cluster, if you have mixed ESXi with different NUMA node sizes in the cluster. For example, a 12-vCPU VM should be 2 socket x 6 cores and not 1 socket x 12 core as that fits better on both the dual socket 10 core and dual socket 12 core hosts. Take note that the amount of memory on the host and VM could change that recommendation, so this recommendation assumes memory is not a limiting factor in your scenario.\nNotice the number is in vCPU, not GHz, not %. Reason is the adjustment is done at a whole vCPU. In fact in most case, it should be an even number, as odd numbers don\u0026rsquo;t work in NUMA when you cross the size of a CPU socket.\nNote that when you change the VM configuration, application setting may need to change. This is especially on applications that manage its own memory (e.g. database and JVM), and schedule fixed number of threats.\nYou can enable Hot Add on VM, but take note of impact on NUMA.\nReference: rightsizing by Brandon Gordon.\nVM CPU Sizing Sizing the VM is required for the migration use case or chargeback use case.\nRule Description Include Hyper-Threading When a VM runs on a thread that has a peer thread running, it\u0026rsquo;s getting less CPU cycle. Include CPU Frequency Include VM overhead Exclude Guest OS queue Include VM Queue Based on all the above, the formula to size the VM is:\nVM CPU Needed (vCPU) = (Used + CoStop + Ready + VM Wait + Swap Wait) + System / 20000 ) The only time you need to convert into GHz is when you need to migrate into another ESXi with different clock speed. To convert into GHz, we multiply the number by the nominal, static clock speed. You can also enhance this by considering CPU generation and speed, although this can introduce a new problem if not done properly. An application may perform poorly after the reduction in vCPU if it works better with many slow threads vs a few fast threads.\nOnce we know what the VM needs, we need to project and recommend. We apply the same technique we did for Guest OS.\nGuest OS Memory Sizing Accuracy of Guest OS memory has been a debate for a long time in virtualization world. Take a look at the following utilization diagram. It has two bars, shown as thin bar and thick bar. They show different thresholds.\nThe thin bar is a generic guidance for all utilization metrics, such as CPU and memory. The thicker bar is specific to memory utilization.\nWhen you spend your money on infrastructure, you want to maximize its use, ideally at 100%. After all, you pay for the whole box. In the case of memory, it even makes sense to use the whole hardware as the very purpose of memory is just a cache for disk.\nThe first bar above shows the utilization range (0% - 100%). The green range is where you want the utilization to fall. Below the 50% mark is shown in blue, symbolizing cold. The company is wasting money if the utilization is below 50%. So what lies beneath the green zone is not an even greener zone; it is a wastage zone. On the other hand, higher than 75% opens the risk that performance may be impacted. Hence I put a yellow and red threshold. The green zone is actually a relatively narrow band.\nNow let\u0026rsquo;s apply the above concept to memory utilization.\nIn general, applications tend to work on a portion of its Working Set at any given time. The process is not touching all its memory all the time. As a result, the rest becomes cache. This is why it\u0026rsquo;s fine to have active + cache beyond 95%. If your ESXi is showing 98%, do not panic. In fact, ESXi will wait until it passes 99% before it triggers ballooning process. Windows and Linux are doing this too. The modern-day OS is doing its job caching all those pages for you. So you want to keep the Free pages low.\nRule Description Include cache Guest OS uses RAM as cache. If you size the OS based on what it actually uses, it will have neither cache nor free memory. It will start paging out to make room for Cache and Free, which can cause performance problems. As a result, the name of this proposed counter should not be called Demand as it contains more than unmet demand. It is what the OS needs to operate without heavy paging. Hence the counter name to use is Memory Needed, not Memory Demand. Exclude Page File Including the pagefile will result in sizing that is too conservative as Windows and Linux already has cache even in their In Use counter.\nGuest OS uses virtual RAM and physical RAM together. They page-in proactively, prefetching pages when there is no real demand due to memory mapped files. This makes determining unmet demand impossible. A page vault does not distinguish between real need versus proactive need. Don\u0026rsquo;t fallback to VM metric Since we are sizing the Guest OS, we use Guest OS only. No falling back to VM as it\u0026rsquo;s inaccurate. Exclude latency RAM contention measures latency, hence not applicable. We\u0026rsquo;re measuring the disk space, not latency. Space, not Speed. Utilization, not Performance. Unlike CPU, there are more difference between Windows and Linux when it comes to memory.\nFor vRealize Operations specific implementation, review this post by Brandon Gordon.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/1.2.12-root-cause-analysis/",
      "title": "12. Root Cause Analysis",
      "tags": [],
      "description": "",
      "content": "There are many things that can go wrong, especially in production and on the eve before you take a vacation. On the other hand, what settings you can change is relatively limited.\nI\u0026rsquo;m assuming you have followed the configuration best practice, as that\u0026rsquo;s a big topic on its own. You will need to review and apply Windows, Linux, vSphere, NSX, vSAN, server hardware, and network hardware performance best practices. If you use Horizon, then you will need to apply its best practice too, alongside the 3rd party technology used in your VDI architecture. In a large environment with multiple versions and vendors, it can be difficult to ensure the entire stack is compatible. It is a never-ending job as you need to keep up with the versions and product end of life.\nAssuming you have done all the configuration check, then the remaining of what you can do is rather limited. For a performance problem, it basically boils down to capacity, either VM capacity or infrastructure capacity.\nvMotion as a topic keeps coming up. If your application team has concerns, this article goes deep into how it works and this covers the enhancement in vSphere 7.\nRoot Cause Analysis report varies among customers, even if the issue they are troubleshooting is essentially the same. What should be the #1 content in the report?\nThe main content of the report should be the alert that is set up to track just in case the problem happens again. Without this alert set up, you will not be able to detect the issue and can potentially lose valuable time.\nThere is a good chance that the root cause is different than the symptom. It may happen on a different object altogether and the error message could be seemingly unrelated. A root cause typically starts as a log message, meaning it has not bubbled up into the screen (UI) as formal alarm. When the vendor support team recommends you a specific log message to trap, how do you validate it is correct?\nYou need to ensure that the alert is valid. That means it should not result in false positive.\nLet\u0026rsquo;s take an example. This was a VDI mass disconnect issue, where \u0026gt;100 users had their sessions disconnected at the same time. The analysis concludes that the problem started with the \u0026ldquo;resuming traffic on DV port\u0026rdquo;, so we need to trap this message when it appears again.\nThe first thing you need to do is validate the above alert. Using tools like Log Insight, you cross check the message against your entire environment, especially the healthy (in this case, unaffected users). Ideally, you cross check for entire week, not just during the time the incident happen.\nThe following was the result when I cross checked against all the users in the last five working days. It happens more than 1000 times, meaning that \u0026ldquo;resuming traffic on DV port\u0026rdquo; is not the message that I should base my alert on. There are too many of them and there is a clear pattern following office hours.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.13-provider-simplify-it/",
      "title": "13. Provider / Simplify It?",
      "tags": [],
      "description": "",
      "content": "The \u0026ldquo;Provider / Simplify It?\u0026rdquo; dashboard complements the main vSphere configuration dashboards by displaying the actual vSphere objects, with their relevant information. It is designed for vSphere administrator and platform team. It is a part of 8 dashboards that check the environment for optimization opportunities.\nThe dashboard follows the same design consideration with the Consumer / Correct it? dashboard. In fact, the 8 dashboards that form the Optimization Flow is designed as a set. You are meant to use them together as you go through the optimization review process.\nHow to Use Select one of the cluster from the table.\nA cluster is more complex to operate when it has resource pools, shares, and limits. Review the Resource Pools list\nEnsure that the number of VMs in each resource pool reflects the intended settings for the resource pool. The resource pool value is divided and shared among the VMs. The more the VMs, the lesser the resources allotted to each VM. Verify if there are VMs who are sibling to the resource pools. Verify if the resource pools are further split into sub resource pools. Review the CPU Share and Memory shares pie charts\nMultiple combinations of shares, especially both CPU and memory, makes troubleshooting difficult. Each share should map to exactly one class of service, such as one for Gold and one for silver, as the shares defines the class of service. Shares are also relative, meaning the value depends on the value of sibling objects such as, resource pool or VM. Ensure that the values are consistent across clusters to avoid unintended consequences while moving the VM to another cluster. Review the CPU Reservation and Memory Reservation tables\nHigh total reservation, especially both CPU and memory, complicates the cluster operations as it impacts the HA slot calculation and limits the DRS choice of placement. Click the object name to navigate to the Object Summary page to view more configurations. There can be valid reasons why specific configurations are not followed. It is recommended that you discuss best practices with VMware.\nPoints to Note See the Points to Note section of Consumer \\ Correct it? dashboard. This dashboard follows the same design consideration with the dashboard, hence share the same limitations and customization idea.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.13-storage-heavy-hitters/",
      "title": "13. Storage Heavy Hitters",
      "tags": [],
      "description": "",
      "content": "The Storage Heavy Hitters dashboard forms a pair with the Network Top Talkers dashboard. To understand the IO demands in your environment, use them concurrently. If you are using ethernet based storage, storage traffic will run over the same physical network your ethernet based network traffic is using.\nDesign Consideration The Storage Heavy Hitters dashboard forms a pair with the Network Top Talkers dashboard, so they share the same consideration behind their design.\nHow to Use See the Network Top Talkers dashboard as they basically have the same design.\nThe main difference is storage IO has 2 dimensions: IOPS and throughput. Network IO does not have the IOPS dimension as the packet size is identical (1500 bytes being the standard packet, and 9000 bytes being the jumbo frames). Storage IOPs and throughput are related, so use both to gain insight, they should display a similar pattern. If not, that indicates varying block sizes. For example, a throughput spike without an accompanying IOPs spike indicates large block sizes. About the \u0026ldquo;Which VMs hit storage the hardest\u0026rdquo; table\nThe table shows the most demanding VM. You can identify the villain VM and compare their demands with the capabilities of the underlying IaaS. Knowing the infrastructure capability is important, because different class of SSD have different IOPS and throughput capabilities. After identifying the villain VM, talk to the VM owners if the numbers are excessive during peak hours and identify the reasons behind the excessive usage. You must ensure that they do not create a hot spot, for example, vSAN cluster with \u0026gt;100 disk can handle numerous IOPS but if the VM objects are only on a few disks, those disks can become a hot spot.\nPoints to Note Interpreting IOPs and throughput metrics depends on your underlying physical storage. For visibility into this hardware layer, add physical storage metrics to the dashboard.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/3.4.14-provider-optimize-it/",
      "title": "14. Provider / Optimize It?",
      "tags": [],
      "description": "",
      "content": "The \u0026ldquo;Provider / Optimize It?\u0026rdquo; dashboard complements the main vSphere configuration dashboards by displaying the actual vSphere objects, with their relevant information. It is designed for vSphere administrator and platform team. It is a part of 8 dashboards that check the environment for optimization opportunities.\nThe dashboard follows the same design consideration with the Consumer / Correct it? dashboard. In fact, the 8 dashboards that form the Optimization Flow is designed as a set. You are meant to use them together as you go through the optimization review process.\nHow to Use The dashboard is organized into 3 sections for ease of use.\nThe first section cover vSphere clusters configuration\nA small cluster has a higher HA overhead when compared to a large one. For example, a three-node cluster has 33% overhead while a 10-node cluster has 10%. For vSAN, a low number of hosts limits the availability option. Your choice of FTT is relatively more limited. Many small clusters result in silos of resources. As a cluster behaves like a single computer, ensure that it has enough CPU cores, CPU GHz, and Memory. For ESXi in 2020, it is typical to have 512 GB of memory. This results in 12 TB of memory for a 12-node cluster, which is enough for DRS to place many VMs as it balances them. If you have a lot of reservation, add a list for clusters with a relatively high reservation. If your clusters are of different size, use a super metric to convert the reservation value to a percentage. The second section cover ESXi Host configuration\nSmall ESXi. A small host faces scalability limits in running a larger VM. While a 2-socket, 32-cores, 128 GB memory ESXi can run 30 vCPU, 100 GB memory VMs, the VM experiences a non-uniform memory access (NUMA) effect. ESXi powered off. You can mark the ESXi hosts for decommissioning using the custom property feature of vRealize Operations. You can then create a separate list so they are not overlooked. The third section cover storage and network\nUnused network (distributed port group). This is a potential security risk as you may have the tendency of not monitoring it Points to Note See the Points to Note section of Consumer \\ Correct it? dashboard. This dashboard follows the same design consideration with the dashboard, hence share the same limitations and customization idea. For CPU cores, a change in vSphere licensing means that the ideal core is 32 cores per CPU socket. This maximizes the software license. For more information, see vSphere Pricing Model. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/3.2.14-network-top-talkers/",
      "title": "14. Network Top Talkers",
      "tags": [],
      "description": "",
      "content": "Use the Network Top Talkers dashboard to monitor network demand in your IaaS. In a shared environment, a few VMs generating excessive activity can impact the entire data center. While a single VM might not cause a serious problem, a few of them can. Understanding high demand helps you monitor IaaS and allows you to plan capacity.\nIaaS provides four services, CPU, Memory, Disk, and Network. CPU, Memory, and Disk are bound, but an active VM can consume all your network bandwidth, packet per second capacity and storage IOPS capacity.\nA VM with 4 vCPU and 16 GB memory cannot consume more than this amount, the same applies to disk space. A VM configured with 100 GB disk space cannot consume more than that.\nNetwork throughput, disk throughput, and disk IOPS can spike as their physical limit is generally very high per VM. This means that IaaS has enough capacity for all workloads and performs well until VMs start consuming abnormally high amounts of network and disk bandwidth.\nDesign Consideration This dashboard is designed to help you analyze the impact of these VMs on your IaaS. It classifies the workload into two categories: short bursts and sustained hits.\nShort burst last for a few minutes, while sustained hits can last much longer. A sustained hit that lasts for an hour can cause serious problems.\nThe Network Top Talker dashboard forms a pair with the Storage Heavy Hitter dashboard. To understand the IO demand in your environment, use both for a more complete picture.\nHow to Use The dashboard shows the big picture, while allowing you to see the individual VM. It is important to see the VM utilization in the larger context.\nThe dashboard begins by showing the current workload. This is the total network load (received and transmit) from all vSphere environments monitored by vRealize Operations. The idea is to give you an indicator on how hard the overall load is. Select a data center from the data centers list.\nThe columns show the number of clusters, ESXi Hosts and VM for each Data center. The VM count includes powered off VM. If you need to show only the running VM count, edit the widget. If you want to see from all Data center, select the vSphere World row. Upon selection, the Total Demand line chart and the Top Talkers table will be automatically filled up. About the Total Demand line chart:\nThis shows the total throughput (received and transmit) in the selected data center.\nIt shows both the 5-minute peak and the hourly average into 1 line chart. You would expect that the 5-minute peak is much higher than the hourly average, indicating it is just a short burst. You can click on the metric name to hide the corresponding line chart.\nAbout the Top Talkers table: The table shows the most demanding VM. To help you focus on the VMs that hit the network hard, VMs that are not hitting the network hard are filtered out. The threshold used is 1 Megabyte/second sustained in the last collection cycle.\nYou can identify the villain VM and compare their demands with the capabilities of the underlying IaaS. Knowing the infrastructure capability is important. For example, an ESXi with 2 x10 Gb port can theoretically handle 20 Gb TX + 20 Gb RX as its full duplex.\nAfter identifying the villain VM, talk to the VM owners if the numbers are excessive during peak hours and identify the reasons behind the excessive usage. You must ensure that they do not create a hot spot, for example, vSAN cluster with \u0026gt;100 disk can handle numerous IOPS but if the VM objects are only on a few disks, those disks can become a hot spot.\nPoints to Note A heat map would enable us to visualize the data easier. However, it can\u0026rsquo;t show the past data, hence it\u0026rsquo;s not used. If you want see in heat map form, see the Live! Heavy Hitters dashboard. "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/downloads/ops-your-world/",
      "title": "Operationalize Your World",
      "tags": [],
      "description": "",
      "content": "\nOperationalize Your World (OYW) is a program created by Kenon Owens, Sunny Dua and Iwan Rahabok back in 2016. Its purpose built to help large VMware customers derive value from vRealize Operations and Log Insight. While it\u0026rsquo;s designed for existing vRealize customers, it had worked well with potential customers. It comes in the form of a small focused workshop, typically around 10 - 30 technical IT Architect/Administrators and Head of Infrastructure Operations, who have direct responsibilities on day to day operations and capacity management. Ideally the attendees run similar size of operations, as there is a lot of peer discussion \u0026amp; networking in the workshop.\nThe workshop material:\nPowerPoint deck. Used to facilitate discussion and for audience to tailor and present back internally to CIO and application teams (take away deck) vRealize Operations kit. A set of dashboards, views, super metrics, and alerts that you can import. It was built on the latest version of vRealize Operations. They are not tested on earlier versions, so upgrade yours first. A Book. An editable Microsoft Word document. The documentation of OYW, which customers can adopt and tailor as their internal operations guidebook. Yes, make it yours please as each operations is unique :-) The site. What you\u0026rsquo;re reading right now. VMwareOpsGuide site covers more than the book, but the site lags in contents as it takes time \u0026amp; effort to manually sync hundreds of pages that evolves every month. Think of Operationalize Your World as the Pro Max Ultra edition of the plain vRealize Operations and Log Insight. Using analogy from the car industry, it’s like the AMG line of Mercedes. It’s designed for advanced customers who operate large scale Infrastructure, hence need a customized version. Product wise, it assumes you have the Enterprise edition.\nTraditionally, the customisation eventually made it into the product. I\u0026rsquo;d port selected contents after they have been proven with customers. So OYW also serves as the alpha version of the content.\nDifferences The difference between OYW and the OOTB vRealize Operations is summarized below. In future, I may add more, such as application software (via both Telegraf and SDMP), NSX, Kubernetes and Horizon.\nDifferences Why It uses the 20-second peak metric instead of the standard 300-second With 15X sharper visibility, you can see problems that do not sustain for entire 300 seconds. Most issues on disk latency, CPU ready and memory contention do not typically last 300 seconds It adds Business Application use case Enable you to monitor your business critical applications. Create multi tier business applications. For each of them, add the relevant tiers using custom groups It adds Migration use case Enable you to plan migration and prove that the migration does not result in performance degradation to the migrated VMs It adds proactive operations Enable you to profile the performance of your IaaS platform and have a daily cadence to review before users complains It reduces the alert noise I deprecates 20 alerts and replaces them with improved alerts and daily proactive check dashboard It adds Guest OS visibility Problem closer to application tend to impact the application more. Note this requires Telegraf agent for each Windows or Linux Download\rOYW Dashboards.zip\r(108 kb)\rOYW Deprecated Alerts.xml\r(58 kb)\rOYW New Alerts.xml\r(23 kb)\rOYW Newly Migrated VMs group.json\r(1 kb)\rOYW Views set 1.zip\r(29 kb)\rOYW Views set 2.zip\r(24 kb)\rOYW supermetrics set 1.json\r(29 kb)\rOYW supermetrics set 2.json\r(4 kb)\rOperationalize Your World 1-day workshop.pptx\r(39797 kb)\rVMware Operations Transformation 4.0.docx\r(90188 kb)\rHow to Install Review the PowerPoint first. At the end of the deck, there is the on-boarding guide. Follow it closely.\nOptional Step: disable ALL the dashboards prefixed with DEP as they have been deprecated\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/",
      "title": "VMware Operations Guide",
      "tags": [],
      "description": "",
      "content": "VMware Operations Guide The VMware Operations Guide and the underpinning GitHub repository result from countless hours spent by VMware staff to test, collate, and write about the many facets of IT Operations. It is given freely to the community both for consumption and contribution. It is a unique attempt to take deep tribal knowledge from inside VMware and turn it into a detailed library for new and existing customers to reference and build on.\nOur vision is that this project continues to grow as the central all-knowing library for everything vRealize Operations and delving further into IT Operations in a multi-cloud world. The decision to allow open access was a clear one for us. Many VMware customers utilize VMware vRealize Operations at a massive, unthinkable scale in very creative ways. But we also have customers using it on much smaller scales. We are eager to invite all customers to contribute to this repository and provide great insight to all administrators for environments of all sizes.\nWe want this site to take readers from “zero” to “hero” and anywhere in their operations management endeavors.\nContributing If you would like to contribute to this site (we welcome it!), please go to our Github Repository and review the repository wiki. We have a considerable amount of information written for new Git users and include guidance on structure and naming conventions.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.1-complaint-based-operations/",
      "title": "1. Complaint-Based Operations",
      "tags": [],
      "description": "",
      "content": "How do you know that the Infrastructure as a Service (IaaS) Platform (be it on-prem or in the cloud) is serving its workload well? If you depend on complaints, then you run a complaint-based operation.\nChanging from reactive to proactive is unfortunately a complex undertaking, especially in large organizations where there are many roles and personas. It requires operations transformation and a paradigm shift. It is not easy to get customers to agree on a Service Level Agreement (SLA) when you\u0026rsquo;ve promised them \u0026ldquo;good\u0026rdquo; for years already. This book aims to provide practical guidance, something you can implement with the current version of vRealize products.\nThe litmus test below helps you assess the maturity of your IaaS.\nDo your customers blame your infrastructure? If the answer is yes, take a moment to ponder why. There is a high chance you are relying on complaints in your operations so you actually encourage them. No complaint, no problem. That\u0026rsquo;s why it\u0026rsquo;s aptly named Complaint-based Operations.\nThe reason why you rely on complaint is the operations have no other means by which to measure success. You have not defined the performance of your IaaS.\nThat\u0026rsquo;s the goal of this book.\nA sign of matured operations is that you have complete, correct and accurate Service Level Agreements. Complete means you have Performance SLAs and Compliance SLAs, not just Availability SLAs. Correct means the SLA is measured on each paying VM, and not at the infrastructure level. It also means you use the right metric. Accurate means the measurement has to be measured every 5 minutes, as any longer intervals than this can miss the problem.\nIs your IaaS cheaper than public cloud or hybrid cloud? The commoditization of infrastructure means your IaaS is being compared with similar platforms such as VMware Cloud on AWS and Amazon Web Services.\nIf not, your CIO may question your business value. The reason for having an in-house architect is so you can bring lower cost, after taking into account your salary.\nDoes Help Desk provide a good first level defence? If Help Desk simply passes issues through to the next level, you need to look at why.\nHelp Desk is your first line of defence. They are not as technical as you are. Equip them with a simple dashboard so that they can handle VM Owner complaints by discovering:\nIs the problem caused by IaaS not serving the VM well? If yes, which part of the Infra: CPU, RAM, Disk, Network? If not, how to prove it convincingly? Can you justify new infrastructure when utilization is not high? This is not referring to additional money that comes with new projects. This is referring to existing workload on existing clusters/storage.\nCapacity is measured on utilization and performance. A cluster capacity is full if it can\u0026rsquo;t serve its VMs well. Since it takes time to buy hardware, you need to have an early warning system to detect this performance degradation.\nDo you struggle with many over-provisioned VMs? This is an indicator that you are operating as a System Builder as opposed to a Service Provider. As a System Builder, you are meddling with each System (read: Application). You size them and argue with the application team, who are actually your customers. You are busy as there are many applications and you are outnumbered.\nIf you are operating as an internal Cloud Service Provider, You are not \u0026ldquo;in the way\u0026rdquo; of the business. You use an effective pricing model to drive the right behaviour. Does a public cloud provider block application teams when they buy 40 CPU AWS EC2 VMs when they only need 2 CPU? They don\u0026rsquo;t, hence neither should you.\nDoes Troubleshooting mean all hands on deck? Do you have a process that is followed by all teams (network, storage, server, OS, application)? Does that process end with Root Cause Analysis?\nAs part of RCA, do you set up alerts so the same issue can be detected faster if it happens again? Without an alert configured, the RCA is not closed. The alert is also critical as it will trigger the RCA process.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.2-purpose-driven-architecture/",
      "title": "2. Purpose-Driven Architecture",
      "tags": [],
      "description": "",
      "content": "When you architect IaaS or Desktop as a Service (DaaS), what goals do you have in mind? I don\u0026rsquo;t mean the design considerations, such as availability and performance best practices. I mean the business result that your architecture has to deliver, viewed from the people who paid for the architecture.\nLogically, the answer depends on what is being sold. You can either sell application or infrastructure, broadly speaking.\nFor applications, the following tables shows the variety of services.\nIn the case of DaaS, the goal is to ensure End Users are getting a quality desktop experience while keeping the price per user low. We will discuss more on this here.\nLet\u0026rsquo;s dive into the IaaS business. There are three variants of IaaS. Each sells a different item, hence the goal can\u0026rsquo;t be identical.\nService What You Sell Examples IaaS 2 variants:\nVM: Most common service in VMware enterprise customers. Most of them are provided \u0026ldquo;free of charge\u0026rdquo; with vague chargeback.\nResource: Block of compute or storage resource such as 100 GHz CPU and 100 GB RAM. AWS EC2 is the most popular outside the enterprise. HWaaS Hardware as a Service.\nThis is not IaaS as customer buys a whole physical ESXi host and have their own vCenter Server. VMC. The most popular variant of IaaS is VM as a Service. In this variant, the business goal is to ensure the application and VMs (VM) are running well yet cost effective.\nThe cost part is easy to quantify. You know what you spend on hardware, software, services and salary. The \u0026ldquo;well\u0026rdquo; in running well is the hard part as there is a big unknown.\nLet\u0026rsquo;s use IaaS as the example. Say you are architecting for 10,000 VMs in 2 data centers. You envisage 2000 VMs in the first month, 5000 VMs in the first half year, and eventually to 10,000 within the first year. Do you know the basic information about each of these 10,000 VMs, so that you can architect an infrastructure to serve them well?\nHow big are they? What are their vCPU, RAM, Disk configuration? How intense are they? CPU utilization, RAM utilization, disk IOPS, network throughput? What are their workload patterns? Daily, weekly, monthly, no pattern, etc. The answer is obviously no. Even application teams do not know as some of the applications may not be developed yet. Their vendors may not know either as the usage is not yet known.\nPromising that the SDDC will serve all 10,000 VMs well is akin to promising the highway you architect will serve all the cars, buses and motorcycles well, when we can\u0026rsquo;t predict how many there are and how often they will use it. We will cover this more in the Performance section.\nSo how can we promise that your IaaS will serve your customers well?\nWe can by using the price/performance. The principle you share with your customers is the common sense used in all service industries:\nYou want it cheap; it won\u0026rsquo;t be fast. You want it fast; it won\u0026rsquo;t be cheap.\nThis is where the Class of Service and the associated Service Level Agreements come in. The highest class of service provides the best uptime and performance but comes at a price. All these attributes are well defined in the SLA, leaving no room for ambiguity. The contract is not subject to interpretation. You define all the key metrics up front, assuring your customers that you are confident of delivering as promised.\nYou then architect your IaaS to deliver the above classes of service. The class of service becomes your business offering. With that, you are ready to begin with the end in mind.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.3-multi-cloud-operations/",
      "title": "3. Multi-Cloud Operations",
      "tags": [],
      "description": "",
      "content": "Don\u0026rsquo;t be disheartened if your organisation is struggling with running a multi-cloud operations. A single private cloud, something you have complete control, is hard enough to operate, let alone operating multiple incompatible infrastructure. The complexity is due to the lack of maturity of the architecture. There are simply too many components involved, as shown in the landscape diagram by Cloud Native Computing Foundation.\nEventually though, the architecture will slowly mature and turn into a commodity. CIOs will begin focus on the operations as business will demand proper governance with SLA.\nRegardless of the underlying system architecture, CIOs are still required to manage cost, capacity, compliance, performance and availability. The Pillars of Operations do not change just because you change the plumbing. We will cover more of these pillars here.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.4-begin-with-the-end-in-mind/",
      "title": "4. Begin with the end in mind",
      "tags": [],
      "description": "",
      "content": "For me, Architecture is Day 1, and Operations is Day 2. Day 1 happens before Day 2. By Architecture, I mean the detail work, including building and commissioning the system. While the high level marketecture1 is defined during Day 0 (Planning), the real architecture work is done on Day 1.\nHowever, if we think deeper, Day 2 impacts Day 0, which is Planning. The reason is the End State drives your Plan. Your Plan drives your Architecture. So it\u0026rsquo;s 2 -\u0026gt; 0 -\u0026gt; 1, not 0 -\u0026gt; 1 -\u0026gt; 2.\nLet\u0026rsquo;s use an example to illustrate how Day 2 impacts Day 0, which in turn impacts Day 1.\nSay you are an internal cloud provider, and you plan to charge per VM. You plan to have 2 classes of offerings:\nGold: suitable for production workloads. Performance optimized. Silver: suitable for non-production workloads. Cost optimized. For Gold, you plan to not overcommit CPU and RAM. If 1 CPU typically uses 4 GB RAM, then a 40-core ESXi host will only need 160 GB. If you buy a host with 1 TB RAM, then you may end up in a position where you are not able to sell the remaining 864 GB as you have no vCPU to sell. This means your hardware specification is impacted. That\u0026rsquo;s an example of how Day 2 impacts Day 0.\nFor Silver, you plan to overcommit 4:1 for CPU and 2:1 for memory.\nYou assume that 1 vCPU typically uses 4 GB RAM. Your customers are allowed to buy more or less memory, so this 4:1 ratio between CPU and RAM are just your planning guide. You plan to run vSAN with dedupe + NSX + vSphere Replication. You also expect heavy IO VMs, which requires kernel processing. For all these supporting, non-business workloads, you allocate 8 cores and 64 GB RAM. If you buy a 64-core ESXi, you have 56 cores left and you will be able to sell 224 vCPU. These 224 vCPU will need 896 GB RAM. Since you overcommit 2:1, you need 448 GB for VM. Total RAM you need is 448 + 64 = 512 GB. That means the hardware spec you need is 64 core and 512 GB RAM. If you buy more RAM than this, you may not be able to sell this extra RAM as you may not have vCPU to accompany them. The above 2 examples show how your hardware specification can\u0026rsquo;t be decided without considering the average VM profile and the overcommit ratio you plan.\nYou also promise the concept of Availability Zone for Gold class, as they host mission critical business services. Your company policy for Business Continuity dictates that in the event of an entire cluster failure, you plan to cap the number of VMs affected. If you limit to say 300 production VMs, then your cluster size should not be too big as you won\u0026rsquo;t be able to fully utilize the resource. I\u0026rsquo;ve seen many 32-node production clusters running 1000-2000 VMs.\nIn your service offering, you include the ability for the customers to check their own VM health, and how their VMs are served by the underlying platform. This means your architecture needs to know how to associate tenants with their VMs. You need to have a tagging standard, such as business unit, department, contact name.\nYour CIO wants a live information projected for his peers to see on how IT is serving the business. This requires you to think of the Key Performance Indicators (KPI)2. How do you know the IaaS is performing fast enough for its consumers? How do you prove that you are meeting the Service Level Agreement (SLA) you promised?\nFrom the performance management point of view, vSphere cluster is the smallest logical building block of the resources. While the resource pool and VM Host affinity can provide a smaller slice, they are operationally complex, and they cannot deliver the promised quality of IaaS service. Resource pool cannot provide a differentiated class of service. For example, your SLA states that Gold is two times faster than silver because it is charged at 200% more. The resource pool can give Gold two times more shares. Whether those extra shares translate into half the CPU readiness cannot be determined up front.\nIt\u0026rsquo;s important to reflect the business in your operations. Create a hierarchical structure where the operations team and tenants can easily find the relevant VMs. These users will be driven by business applications, so your IaaS needs to be designed around that. The following structure shows Business Unit as the top folder. Each business unit can have 1 or more departments (Business Unit C spans 3 departments in the diagram below). Each department owns multiple business applications. A business application typically consists of multiple tiers (e.g. web tier, app tier, database tier).\nThe limitation of the above is reorganisation. You will need to rename, move folders to the new parent folders, and delete folders. For example, if Business Unit B merges with Business Unit C and the combined entity has a new name, then you need to rename one of them, and delete the other.\nLast but not least, you need to account for problem. Real problems happen in Day 2 as that\u0026rsquo;s when you have business workloads doing revenue generating transactions. Do not architect something you are not willing to troubleshoot. Think of the roles and skills required to operate your architecture. Provide the necessary visibility3 into each component and define what constitutes health, risk and efficiency.\nI hope the above examples show that Day 2 is where you want to start. Begin with the end in mind, says a famous quote.\nDid you notice something missing in the discussion above?\nYes, I did not cover Automation.\nWhy is that?\nFor me, that\u0026rsquo;s part of Architecture. You should not automate what you cannot operate. So, automation is not part of operations. Automation is a feature of your Architecture, meaning you design the system with automation in mind. Using an analogy, it\u0026rsquo;s like a plane with many automation features. Fly-by-wire. That\u0026rsquo;s a feature of the plane. How you operate the plane, so passengers arrive at the destination safely, comfortably and on time, that\u0026rsquo;s operation.\nMarketing architecture. A light reference to PowerPoint based diagram that lacks details to be implemented.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI understand the difference between SLI, SLO, SLA, KAI and KPI. Not using SLI and SLO for PCMCIA reason (People Can\u0026rsquo;t Manage Computer Industry Acronyms). Being precise is good. But using too many jargons is adding complexity.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSome people use the term Observability, and create unnecessary confusion with Monitoring. This is yet another example of PCMCIA. If we really want to split hair, the term debuggability carries more value as just because you can observe a system does not mean it\u0026rsquo;s debuggable.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.5-vcdx-vs-vcox/",
      "title": "5. VCDX vs. VCOX",
      "tags": [],
      "description": "",
      "content": "\nArchitecture and Operations are two equally large realms. While we certainly consider Operations when designing a system, it is not a part of Architecture. This book is an example of Operations. Notice it goes deep into metrics as troubleshooting is at the heart of operations.\nArchitecture and Operations also differ in other industries. The person who designs the space shuttle is not the person operating it. You need to be an astronaut to be qualified to operate a space shuttle. The person who design an F1 race car is not the person driving it. Different expertise are required. They complete each other and are inter-dependent, like Yin and Yang.\nSince Infrastructure is becoming a service, you need to know how to architect a service (e.g., IaaS, Database as a Service, Desktop as a Service).\nWhat are the services the IaaS is providing? How do you define a service? What metrics do you use to quantify its quality? How many services? How do you distinguish between higher class service and normal one? You also need to know what type of services are on demand. Service Architects go out, meet customers, and understand their requirements. What Price/Performance are on demand now and in the future? From there, you can architect the corresponding services to anticipate the demand.\nAs a Business Architect, you not only know the cost of running the service, but you also know how \u0026amp; when to break even. You are not responsible for profit and loss, as you are not the CIO or Cloud Service Provider CEO, but you do play a strategic advisor role to them. You know what to price, how to price and most importantly your price is competitive (at least you can provide the business justification).\nFrom my interactions with customers, I notice that Infrastructure Architects are not leading Day 0 phase. They provide input to the Planning stage, but are not the lead architects driving it. The Infrastructure Architect tends to focus on technical bits, something that CFO and CIO value less (hence they spend less time on it). They also do not architect the operations. I see many seasoned VMware Architects not extending their influence beyond architecture. I think that\u0026rsquo;s a lost opportunity because Day 1 and Day 2 is actually part of the same side. Think of it as Mobius strip.\nInspired by the VCDX program, perhaps the world of multi-cloud operations needs a VCOX program. We need to write the guidebook. That\u0026rsquo;s why I open source this book, so all the Operations Expert out there can collaborate and produce the best practice of operations.\nService Architect and Business Architect are the next steps for Infrastructure Architect. I shared a story of a chef and his cooking back in 2014 during one of the VMUG session.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.6-the-restaurant-analogy/",
      "title": "6. The Restaurant Analogy",
      "tags": [],
      "description": "",
      "content": "We have covered how all aspects of data center management have changed. If you need details, refer to this chapter. These fundamental changes also change your IT business. You are now a service provider. While your engineering or technical knowledge is still important, your customer measures you on your business service level. While they care about your systems architecture and its capabilities, they measure you on your service quality.\nSunny Dua1 and I use the restaurant analogy when explaining the need of formal Service Level Agreement (SLA). The analogy has resonated well with many customers. Humans can always relate to food!\nEssentially, a restaurant has 2 areas, often with a clear demarcation line:\nThe Dining Area. The Kitchen. Think of your IaaS business like a restaurant business. It has a Dining Area, where your customers live, and a Kitchen, where you prepare the food. Guess which one is more important?\nYou are right. The dining area.\nIf everything runs smoothly in the dining area, customers are being served on time and on quality, and they are paying you well, it is a good day for the business. Whether you are running around in the hot kitchen is a separate, internal matter. The customers do not need to know about it.\nWe use the analogy to drive the message that you need to focus on the customers first, and your IaaS second. If you take care of your customers well, and they are happy with your service, the problem you have in your IaaS is a secondary and internal matter.\nThe \u0026ldquo;dining area\u0026rdquo; is the Consumer layer. Look at the diagram below. It is where your customers\u0026rsquo; VMs live. The \u0026ldquo;kitchen\u0026rdquo; is the Provider Layer. This is your infrastructure layer, where VMware and the hardware reside. Public cloud is part of the kitchen. Just because you no longer own the infrastructure does not mean you can\u0026rsquo;t take management responsibility. The structure of enterprise IT means the infrastructure team end up being held accountable.\nThere is clearly a line of demarcation between the two layers. Your customers should not care about the details of your SDDC or EUC. The VM Owner does not care if you are firefighting in the data center. Because they do not care, whether you are using an older VMware Cloud Foundation or the latest, is not something you want them to dictate to you upon. The same goes with your choice of hardware brand and specification.\nThe application team becomes a consumer of a shared service-the cloud platform. Depending on the SLA, the application team can be served as if they have dedicated access to the infrastructure, or they can take a performance hit in exchange for a lower price. For SLAs where performance is guaranteed, the VM running in the cluster should not be impacted by any other VMs. The performance must be as good as if it is the only VM running in the ESXi.\nLet\u0026rsquo;s zoom into the kitchen area, as that\u0026rsquo;s also undergoing a transformation. The Server team or Windows team or Linux team typically took the ownership of the shared platform and evolved to become the platform team. With the evolution of Hyper Converged Infrastructure, the storage is being absorbed into the platform. The boundary with the Network team is also becoming blurry with network virtualization. Many network services such a Firewall and Load Balancers are virtualized.\nSunny and I went back a long way. We both came from the field and eventually became Product Managers.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.7-service-level-agreement/",
      "title": "7. Service Level Agreement",
      "tags": [],
      "description": "",
      "content": "The difference between an enterprise grade Cloud and non-enterprise grade Cloud is the SLA. A cloud provider can state that they have the best technology, the most experienced professionals, the most innovative process, industry certifications, etc. to prove that they are the best. All those will not carry weight if they are afraid to back it up with the SLA in their contract. The SLA enables customers to hold the cloud provider accountable as it carries a financial penalty.\nOnce the SLA is defined, then customers want to know how it will be delivered. This is where the process, architecture, certification etc. come in. The what always come before the how.\nThe 4 SLAs of IaaS The business of IaaS should provide three SLAs, as customers want complete coverage.\nSLA Description Availability This is the most basic SLA. It is the eldest and most well-known. In reality, it is largely a given. It does not matter what the agreed number is in reality. If the darn thing is down, you better hurry to bring it up before there is a complaint or things get worse! Performance Just because something is up, does not mean it is fast. A VM can be up, but if it is too slow to serve, it is as good as down. Performance SLA covers this and addresses the complaint-based operations by defining what exactly is fast. It covers CPU, Memory, Disk and Network, hence there are four metrics used. Compliance This provides security compliance to industry regulation or certification. Service The above three SLAs are provided by technology. They need to be complemented by service provided by human. This should cover proactive and reactive services. The two popular examples are response time and resolution time. KPI vs. SLA KPI and SLA work hand in hand.\nAcronym Description SLA The formal business contract you have with your customers. Typically, this is between the IaaS provider (the infrastructure team) and the IaaS consumer (the application team or business unit). The formal SLA needs Operations Transformation. It requires much more than technical changes, as you need to look at contract, price (not just cost) process, people, etc. It tends to have a financial penalty in the event of SLA breach, such as credit for the next billing cycle. KPI This covers the SLA metrics, plus relevant additional metrics that provide early warning before the SLA metrics are breached. There are many KPI for a given SLA, and KPI is a pre-requisite to SLA. If you do not have an SLA in place, then start with internal KPIs before committing to an SLA. Understand and profile the actual performance of your IaaS first. Use the default settings in vRealize Operations if you do not have your own thresholds, as those thresholds have been chosen to support proactive operations. Using the profiling technique described here, I profile well over a million data points. SLA is a monthly counter, not daily or yearly. You use entire month of data to calculate it.\nThe timeline matters. In the following table, notice 99.999% in a year is actually easier than 99.95% in a week. Your customers would not accept a yearly counter as they can be exposed to a long downtime. You would not accept a daily counter as there is no room for error. The monthly counter provides a balance between service quality and cost to deliver the service. It also makes reporting easier as you simply follow the calendar month.\nEach additional \u0026ldquo;9\u0026rdquo; shrinks your downtime window by 10x. That\u0026rsquo;s why each decimal can cost a lot more money, as a different architecture may be required.\nEven if you measure the SLA once a month, it can still be very difficult to meet. Take a look at the following table. For simplicity, we will use Availability SLA and not Performance SLA, because up or down is a simple binary.\nIf you promise 99.99%, you only have 4.0 minutes - 4.5 minutes of downtime per calendar month. That means your architecture must be able to detect the issue and then complete proper remediation in just a few minutes. That\u0026rsquo;s a tight space to manoeuvre.\nA unique saving grace that applies to Availability but not Performance is scheduled downtime. There is no such thing as scheduled downtime in performance. Specific to IaaS, you can propose that scheduled downtime is not included in the SLA, so long it\u0026rsquo;s done quickly and rarely. Planned activities such as VM hardware upgrade, Tools upgrade and Windows upgrade can be included in scheduled downtime activities. Downtime caused by customer is not included, be it intentional or not. This is why you need two counters: one for SLA and one for actual. The actual will record every downtime, be it a part of SLA or not.\nA challenge that impact Availability but not Performance is recovery time. Your system may detect the VM is down within 1 minute, but the reboot process until the entire OS is properly up and running takes 5 minutes, as it needs to perform filesystem consistency check.\nKPI complements SLA as it tracks at much higher intensity and it covers more counters and events. Use vRealize Log Insight for more time sensitive event, as vRealize Operations measures every 5 minutes.\nFrom the preceding table, note that Guest OS counters are not included as that\u0026rsquo;s part of \u0026ldquo;application KPI\u0026rdquo; or VM KPI, not IaaS KPI. They impact the VM performance, but nothing the IaaS can do, meaning the remediation is at the Guest OS layer.\nKPI also complements SLA by providing the stepping stone in your operations transformation. It is a necessary step towards operations with real business SLA.\nYou walk from where you stand. Adopt KPI first. Baseline your actual availability, performance, and compliance over time. Remember these counters are VM level, not infrastructure. Therefore, you need to profile all the VMs.\nClass of Service The following table shows a basic and generic guideline to a class of service. The actual model that you will implement will certainly differ, taking into account technology and business demand. In the capacity management section, we walk through an actual example.\nThe table above is further defined by their SLA, because you need to quantify what 10% penalty exactly means.\nA Gold class has higher SLA than Silver. For that to happens, that means they are measured against the same benchmark.\nFor availability, you measure all classes against the ideal, which is no downtime. For performance, you measure them against the same threshold, which is a stringent (read: fast) number. For compliance, you measure them against the ideal, which is perfect compliance. For service, you measure them against the ideal, which is the best possible service. Performance SLA Let\u0026rsquo;s elaborate Performance SLA a bit, as it is more complex than the other two.\nFollowing the above, diagram, you offer 99.9% for Gold, and 99% for Silver as the respective SLA.\nFor Gold to be higher than Silver, that means both are measured against the same raw threshold. In other words, a VM in Silver environment will expect that it does not get what it demands as often as a VM in Gold. If the VM Owner wants to have more consistent service in performance, then simply pay more and upgrade to the Gold cluster.\nThis approach is easier than setting up a different performance threshold for each tier. Say you set the following:\nGold: VM Memory Contention: 0.5% Silver: VM Memory Contention: 1.5% You notice the problem already?\nIt is hard to explain the delta or gaps between the class of services. Why is Silver 3x the value if it is only half the price? Shouldn\u0026rsquo;t it be proportionate?\nThere is a 2nd problem. If you set different standards, it is possible that Silver will perform better than Gold, because it has lower standard. This can create confusion.\nOperationally, having a single threshold is easier to set up. No need to play with vRealize Operations policy. You can also have mixed classes of VM in the same cluster or datastore, as the SLA threshold is the same.\nWe will cover the counters used in Performance SLA in more details here.\nDifferentiated Service IaaS is built on commodity hardware and provided as a utility. Having said that, there are many ways to differentiate your service vs your competitors. Use class of service to distinguish premium service. The following table lists some examples.\nService Description Backup Gold Tier provides application-level back up. It also provides more frequent full back up, and customers are provided with self-service individual file restore. High Availability Gold Tier provides application- level monitoring. Customers can also ask for specific boot up sequence of their VMs, and ask for VM-Host affinity rules to minimize risk. Disaster Recovery Gold Tier provides lower RPO and RTO. Customers are also entitled to annual real test, where the production workload are run from the DR site. Snapshot Gold Tier provides longer snapshot and larger snapshot. OS Management Gold Tier provides flexibility in patching. Customers can specify delay in patching and request for custom patch package, where not all patches from Microsoft or Red Hat is applied. VM Management Gold Tier provides flexibility in updating Tools and VM Hardware. Customers are allowed to defer the update Monitoring Service Gold Tier VMs will be proactively monitored, not just relying on alerts. Gold Tier provides deeper visibility into the underlying physical infrastructure where customers VM are running. Customers are entitled for lower internal metrics such as vMotion stun time and VMkernel latency. Gold tier provides self-service monitoring. Customers are given their own login to a portal where they can monitor their own VMs. They can initiate scheduled downtime. Customers will be alerted over email and messaging network. Support Gold Tier provides faster response time, longer business hours, and faster resolution time. Network Gold Tier provides priority network. Customers can opt for periodic ping service to ensure network latency between their applications remain within the agreed threshold. TAM Gold Tier comes with a Technical Account Manager, acting as single point of contact for customers "
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.8-pillar-process-people/",
      "title": "8. Pillar | Process | People",
      "tags": [],
      "description": "",
      "content": "What do you manage, actually? What do your customers want you to take care? How do you manage what you need to manage?\nThe most basic is you need to have visibility into the environment. There are thousands of objects (e.g. VM, application, firewall) with complex relationships and interdependance. Inventory gives you this. That\u0026rsquo;s why it\u0026rsquo;s the first box in the diagram below. I had a large telco telling me that their entire DC can go down (say for scheduled DR exercise) but not vRealize Operations as that\u0026rsquo;s how they monitor the downtime.\nOnce you know what you manage, you can then move on towards making sure they are healthy. If there is no problem, then you move to address potential problem. If there is no risk, then you look for optimization.\nHealth Health is actually hard to define, as it depends on the context and object. The English word health itself is subject to interpretation. So, it\u0026rsquo;s better to define and map to the pillars of operations. Health is the present. It covers real problem that has happened and/or is still ongoing.\nThere are 2 problems that can impact health:\nAvailability Performance Availability and Performance can be mutually exclusive, but both impact health. You can have 1 problem without the other.\nRisk Risk is the future. It covers potential problem. There is no problem at this moment, but if you do not act on it, you increase the risk of it becoming a problem.\nThere are 3 problems that create risk in operations:\nCompliance Configuration Capacity In all the above problems, Health is not impacted as there is no actual performance, availability or security issue. What you have is a risk, as your applications and operations continue as if nothing happens. Your customers may not notice and your business is not affected.\nEfficiency Efficiency is optimization. There is no problem at present, nor there is a risk for future problem. You want to optimize as it lowers cost and improve performance.\nWastage (oversized, unused EC2, idle, unmapped disk space, orphaned file, etc.) Cost. Compare your cost with other cloud providers as IaaS is essentially a commodity. Green Operations fits efficiency as sustainable operations calls for lean operations. Pillars of Operation Best practices of operations management require you to distinguish between pillar and process. Pillar is what you need to manage, while process is how you manage them.\nEach pillar is an individual unit of management. They represent individual disciplines and are compatible with one another. The complexity of each pillar depends on the technology, for example, vSAN capacity is more dynamic than a central array. In vSAN, changing the storage policy can create a sudden spike. Process is the activities within each pillar. It requires roles and responsibilities, which is documented in policies.\nDay 0 is the phase where you plan and define the expected result. Some companies perform stress tests and load tests, so they know what to expect when the real load actually occurs. Without planning and testing, you don\u0026rsquo;t know what the reality will be, as you have not defined \u0026ldquo;well\u0026rdquo;.\nDay 1 is the phase where you build the system and launch the service. This includes configuring the various operations input such as cost drivers (e.g. application license cost, electricity rates). As the focus of this book is Day 2, I\u0026rsquo;m not including Day 1 in the preceding table.\nMonitoring and Troubleshooting are activities. They are not something you manage. In monitoring, you have Standard Operating Procedure (SOP), which defines what roles performs what checking. You focus on insight first, alert second. Troubleshooting is much more than simply \u0026ldquo;finding out\u0026rdquo; and goes beyond just gathering facts. It focuses on why, and then formulates a solution to prevent future incidents. Incidents mean something is dead, slow or breached. You troubleshoot availability, performance, and security.\nInventory is something you have, not something you plan. You plan for capacity, with certain configuration. Inventory merely accounts for what you have. Nothing to troubleshoot nor optimize.\nOptimization delivers many practical benefits and real business results. Here are some of them:\nI\u0026rsquo;m sure there are more of them. Drop me a note with your real-world experience!\nInterdependency The pillars of Operations Management are interdependent. Knowing the relationship is as important as knowing each pillar. Relationship matters as the symptom and the root cause are often two different things. A performance problem could be caused by configuration problem, such as outdated configuration or incompatible versions.\nUsing the above diagram as reference, let\u0026rsquo;s elaborate each pillar.\nAvailability The most fundamental part of operations management, because the rest of the 7 Pillars of Operations are practically irrelevant if the whole environment is down.\nThere is a spectrum of availability solution, from snapshot, back up, HA, FT and SRM. Each can have impact on capacity and performance.\nAvailability considers HA (high availability) setting. As a result, planned downtime (e.g. ESXi in maintenance mode) does not impact the availability value.\nAvailability, done right, will not impact Capacity and Performance as it\u0026rsquo;s already accounted for as part of the design. Yes, this means you need to include the potential workload caused by DR events.\nThe higher the Availability SLA, the higher the price of the service. There is a big increase for each additional 9 of availability. Five 9s of availability costs a lot more than four 9s.\nPerformance \u0026amp; Capacity Performance and Capacity are closely related and interdependent, but not identical, hence one is often mistaken by the other.\nIn larger organizations, they are typically managed by two different teams. The capacity team does not get involved in the day-to-day operations as they focus on longer term resource availability. Capacity planning is about maximizing utilization, without compromising performance. It also considers latent workload and future demand, which performance does not consider.\nThe capacity team may not have the technical skills to troubleshoot performance. On the other hand, the day-to-day operations deals with \u0026ldquo;what\u0026rsquo;s on the floor\u0026rdquo; of the data center. Their primary focus is meeting the demand from applications. It is consumer driven, while capacity is provider driven.\nPerformance is affected by capacity as the lack of capacity is often the reason for poor performance.\nCapacity is affected by Performance as it needs to consider contention counters first, before it considers utilization. If you can\u0026rsquo;t satisfy existing demands, then you won\u0026rsquo;t provision new workload, hence capacity is practically full. The utilization counters may not be high yet, but that\u0026rsquo;s a secondary consideration as you stop adding new workloads until you figure out why.\nPerformance is more time sensitive and important than capacity. Manage performance first, capacity second. Using the restaurant analogy, you focus on the dining area first, then the kitchen.\nPerformance and Capacity have opposite relationships. Highest overall performance is achieved at lowest capacity, as that\u0026rsquo;s when the VM or Infra is delivering the most amount of work.\nCost \u0026amp; Price With hardware becoming commodity and infrastructure becoming invisible, price has naturally become a common denominator among all IaaS providers. The general expectation is price per VM is similar across cloud providers. One way to provide differentiated pricing is SLA.\nWhile Price should be higher than Cost, it can be set independently of cost. Use discount and progressive pricing to set the correct price for the right terms and conditions. Progressive pricing will also discourage large unused VMs to be provisioned in the first place. It\u0026rsquo;s easier to handle than when these VMs are already in production.\nCost goes hand in hand with capacity. The higher the utilization of the IaaS, the lower the cost per VM. Cost is separate from capacity as it can be optimized without reducing capacity.\nCost and capacity can also go independently of each other. You can increase capacity without increasing cost via technology refresh. You can reduce cost without reducing capacity by lowering non-capacity costs such as the rate you pay for services.\nThe better the Performance SLA, the higher the price customer is willing to pay, hence the term Price/Performance.\nCompliance \u0026amp; Security Security is related, but not the same as Compliance. Security covers issues such as attack (be it by internal employee or by external threat). Compliance deals with configuration settings or values that may expose security loopholes or conform to specific sets of standards.\nCompliance is measured against both internal and industry standards. It\u0026rsquo;s also measured continuously.\nConfiguration \u0026amp; Inventory Inventory is related, but not identical to configuration. Configuration impacts performance, cost, capacity, and compliance. Therefore, it is one of the primary focus of optimization assessment. Settings need to be checked across the entire stack, especially the lower stack as problem in a stack will impact the stack above it.\nInventory is an account of what you have. Configuration is the properties of what you have. Inventory uses a small subset of settings as the focus is on counting the number of objects. The majority of properties/settings are not relevant to inventory.\nInventory generally asks what do we have where? By that, it\u0026rsquo;s focusing on the quantity, not specifications. Examples:\nNumber of VMs in a cluster is a part of inventory. It\u0026rsquo;s not a part of configuration. Number of ESXi hosts in a cluster is a part of inventory. But it\u0026rsquo;s also part of configuration as that\u0026rsquo;s the design of that cluster. The cluster is configured with 8 ESXi hosts for a reason, and deviation may need to be explained in documentation. Inventory has concepts such as stock take, which typically involve physical items. Configuration does not.\nRoles \u0026amp; Responsibilities There are many persona required to keep the operations running well. Some are directly involved on the day to tday operations, while others focus on the big picture. In small organisation, the roles are played by the same few people, backing up each other. You can have 3 people doing everything with no structure, or 300 people with clear demarcation. Regardless, the job still need to be done, so document all the roles and responsibilities.\nLevel 1 Ops Deal with the production environment. Perform a regular check on the overall environment. Use both insight and alert. Typically does not require reading logs.\nResponsible to close alert. Alert should be closed only when root cause is known, not when symptom disappear. Closing alerts without knowing why they happened prevents lesson learned and can potentially back fire.\nPerform simple troubleshootng, following SOP. SOP is ideally automated, taking input parameters, so the chance of human error is minimized if the number of manual steps or frequency is high.\nFocus on Health, which is Availability and Performance.\nLevel 2 Ops Activated when Level 1 is unable to solve the problem. For each problem solved, this role should update the troubleshooting guide so Level 1 can be empowered. Focus on insight, not alert. Look at the big picture and try to prevent alert from happening.\nMore senior than Level 1. May specialise in some areas (e.g. vSAN, networking).\nPerform advanced troubleshooting, which often requires logs analysis.\nLead or involve in the evaluation of operations management tools. Design and maintain vRealize dashboards and alerts.\nFocus on Health, Risk and Efficiency.\nArchitecture Look at the future. Evaluate new technology and assess if technology refresh is warranted.\nCapacity Plan the supply side of capacity, working with architect role.\nPlan the demand side of capacity, working with line of business or sales team.\nDoes not get involve in the day to day capacity. ESXi Host going into maintenance mode is an operational problem, not capacity management matter.\nCompliance Set the compliance settings to agreed internal and industry standard.\nVerify that non-compliance alert was addressed timely and correctly by the operations team. Report \u0026amp; discuss the compliance status with upper management.\nFocus on Risk (Configuration, Compliance).\nIT Management There can be multiple levels here, all the way to the CIO.\nLook at the big picture, especially price and cost.\nGenerally does not get involved in troubleshooting and architecture.\nPrimary focus is Compliance and Cost. Performance is not as that was likely promised to be good by the Architect as part of the design.\nInputs of Operations Management There are 2 types of counters that impact your day-to-day operations. Contention is the primary counter for performance, while utilization is the primary counter for capacity. The 3rd type is just informative, such as accounting for what you have.\nWhile contention is what you care, utilization gets the limelight as it\u0026rsquo;s easier to monitor and simpler to explain. There is a tendency to monitor utilization, as if that\u0026rsquo;s a pillar of operations. Just like contention, utilization is not something you manage. Yes, you monitor utilization, but you monitor it for a reason. It\u0026rsquo;s just a way to measure something that you care about. By itself, it has no meaning. The meaning depends on the purpose. Different goals result in different interpretation and utilization metrics. Utilization serves performance and capacity differently. For performance, you should look at actual and real utilization. For capacity, utilization is measured against usable capacity (after HA and buffer).\nWhile they have negative correlation, contention can still develop at low utilization. VMs in the cluster can be competing for resources while the ESXi hosts are not running at high utilization. Unbalanced and incorrect cluster configurations are two typical causes of contention at low utilization. Utilization and contention are explained further in the Performance Management chapter.\nAllocation complements demand as newly provisioned VMs tend to be idle (which can be months). In addition, future load cannot be detected by the demand model, as it does not exist yet. The allocation model should be used to complement the demand model. This is explained further here.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/1.1.9-insight-vs-alert/",
      "title": "9. Insight vs. Alert",
      "tags": [],
      "description": "",
      "content": "Many operations rely on alerts as the starting point. Actions are taken based on alerts, resulting in reactive day-to-day operations. To turn this situation around, vRealize Operations provides insight. Insights complement alerts, it does not replace it. Alerting misses the big picture, as it can only see what is already triggered. For one object that reached this threshold, there could be many just beneath the it. For one alert, there could many supporting metrics that have shown the potential root cause. Think of an iceberg. The small portion above sea level, the visible part, is an alert. The large, invisible part is insight.\nAlerts may auto close if the symptom disappears. This encourages \u0026ldquo;lazy operations\u0026rdquo; when no alert is associated with no problem. Insight does not have this \u0026ldquo;auto close\u0026rdquo; concept as it does not involve help desk ticket. It\u0026rsquo;s recording a fact that something has gone wrong, and that something could potentially cause an alert. Ideally, you want to detect and address that something before an alert is triggered.\nThere is a common misconception that Insight is simply alerts that use different threshold on the same metric. So insight is basically an alert with lower threshold. This is valid, but incomplete. Implementing insight this way can result in an alert storm and a lot of tickets. It is better for Insight to use different metrics than Alerts, so you get a different perspective.\nInsight should focus on the underlying problem. It also helps buy you time so you can address the problem before the user complains. In the following example, the alerts use the SLA metrics and threshold. The insights use more granular metrics and supporting metrics. For example, vMotion stun time is not part of your SLA.\nAlerts Planning Your goal is to minimize alerts storm while providing the greatest coverage. This calls for a careful planning on the alert definition, symptom and threshold. For each alert, ask yourself: what remediation action will be taken by the person seeing the alert?\nIf the answer is nothing, then why have the alert? Using a dashboard can give better picture. If the answer is something, can that be automated? Be careful of simplified logic as computer has no common sense. If the answer is escalating to the next level (e.g. Level 2 support), then ask the team in the next level if they prefer alert or dashboard. If their answer is they need to see a context, then a dashboard makes more sense. What areas do you want to monitor with alerts? There are 7 pillars of Operations Management, so it\u0026rsquo;s easy to confuse when designing the alerts definition.\nAvailability You can minimize reactive operations by tracking soft errors, having proactive hardware replacement and ensuring software stack compatibility.\nPerformance You minimize reactive operations not by using lower threshold, but by tracking early warning metrics. See the above diagram for the example.\nCapacity This is often mistaken as performance problem, as high utilization is a common alert.\nCompliance This is a subset of configuration check, so limit is to formal security standard.\nConfiguration Configuration is broader than compliance. Configuration mistakes can cause availability, performance, capacity and security. Examples:\nAvailability. Incompatibility between software versions could cause an outage. Capacity. Disabling CPU SMT will reduce the number of logical processor. Security. Outdated software may contain known security vulneratibility Cost You don\u0026rsquo;t typically set an alert here as insight with dashboards is a better monitoring solution.\nInventory You don\u0026rsquo;t typically set an alert here as inventory it\u0026rsquo;s merely an account of what you have. There is no good or bad.\nManaging Alerts is not the same as minimizing Alerts. Managing is dealing with alerts that are already triggered. Minimizing takes us towards preventing alerts to begin with. Use insight to minimize alert definition, as alert should be reserved for urgent and important issue.\nIn cases where you can\u0026rsquo;t minimize the alert, you can reduce its severity. You do this not by lowering the threshold, but by monitoring early warning events. For example, CPU and network have early warning that something have gone wrong at hardware level. You track this soft errors and perform proactive replacement.\nIn cases where you can\u0026rsquo;t reduce the severity, you can reduce the occurance of the alert happening in production. You do this by proactive replacement, taken as part of scheduled downtime during green zone. For example, Solid State Drive (SSD) does not have infinite life span in terms of number of writes. The manufacturer has a number in mind for the endurance. If you have thousands of disks, you create a dashboard just to track this limit and schedule proactive replacement for those disks nearing their limit.\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-1---design-considerations/",
      "title": "Chapter 1 - Design Considerations",
      "tags": [],
      "description": "",
      "content": "Chapter 1 Design Considerations There are many considerations required in designing a suite of dashboards that tell a story.\n1. Dashboard | Alert | Report\r2. The Art of Dashboard\r3. Interaction\r4. Dashboard to Dashboard Navigation\r5. Color as Meaning\r6. Table as Insight\r7. Bar Chart as Insight\r8 Distribution Chart Limitation\r9. Dashboards at Scale\r10. Dashboard Getting Started\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-1---overview/",
      "title": "Chapter 1 - Overview",
      "tags": [],
      "description": "",
      "content": "Chapter 1 Overview vSphere counters are more complex than physical machine counters because there are many components as well as inconsistencies that are caused by virtualization. When virtualized, the 4 elements of infrastructure (CPU, RAM, Disk, Network) behave differently.\nThe complexity created by a new layer because it impacts the adjacent layers below and above it. So the net effect you need to learn three layers. That\u0026rsquo;s why from a monitoring and troubleshooting viewpoint, container technology requires a deeper knowledge as the boundary is even less strict. Think of all the problems you have with vSphere Resource Pool performance troubleshooting, and now make it granular at process level!\n"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-1---overview/",
      "title": "Chapter 1 - Overview",
      "tags": [],
      "description": "",
      "content": "Chapter 1 An Overview This first chapter gives a tour of operations management, starting with why a reactive and hectic operations is common, and the paradigm shift required to proactive \u0026amp; predictive operations.\n1. Complaint-Based Operations\r2. Purpose-Driven Architecture\r3. Multi-Cloud Operations\r4. Begin with the end in mind\r5. VCDX vs. VCOX\r6. The Restaurant Analogy\r7. Service Level Agreement\r8. Pillar | Process | People\r9. Insight vs. Alert\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-2---cpu-metrics/",
      "title": "Chapter 2 - CPU Metrics",
      "tags": [],
      "description": "",
      "content": "Chapter 2 CPU Metrics The nuance you saw earlier was due to the nature of additional layer. The following infographic shows there are multiple elements as a result of virtualization. It helps me to understand the metrics, hence the sharing.\nCPU counters for a VM differ from those in the Guest OS. For example, vCenter provides 5 counters to account for the utilization of VM CPU, yet none directly maps to Windows/Linux CPU utilization. The CPU counters in ESXi are also more than the summation of its running VM and VMkernel.\nThe following screenshot shows the CPU counters of a VM. Compared with Guest OS such as Windows, can you notice what\u0026rsquo;s missing and what\u0026rsquo;s added? Go ahead and open Windows PerfMon or SysInternal and compare, and you will quickly notice major differences.\nRight off the bat, you will notice that popular counters such as Ready, CoStop, and Overlap do not exist in Windows. The reason is VM and Guest OS have different vantage points.\nWhen the VMkernel de-schedules a VM to process something else (e.g. other VM, kernel interrupt) on the same physical thread or core, the Guest OS does not know why it is interrupted. In fact, it experiences frozen time for that particular vCPU running on the physical core. Time jumps when it\u0026rsquo;s scheduled again. Because of this unique visibility, it\u0026rsquo;s important to use the correct metrics at the correct layers. Here is what the Guest OS can and cannot see:\nThe different vantage points result in different counters. This creates complexity as you size based on what happens inside the VM, but reclaim based on what happens outside the VM footprint on the ESXi. In other words, you size the Guest OS and you reclaim the VM.\nBoth layers need to be monitored, as each measure different performance problems. Hence it\u0026rsquo;s imperative to install VMware Tools as VMkernel will not provide visibility into the Guest OS. VMware Tools report the statistics about guest to the ESXi host every 20 seconds by default.\n1. Guest OS\r2. VM\r3. ESXi Host\r4. Quiz Time!\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-2---performance-dashboards/",
      "title": "Chapter 2 - Performance Dashboards",
      "tags": [],
      "description": "",
      "content": "Chapter 2 Performance Dashboards The performance dashboards sport KPIs to display the performance of workloads at the consumer layer and the aggregate performance of workloads at the provider layer. They are designed for both day-to-day operations, and ad-hoc troubleshooting.\n1. Design Consideration\r2. Cluster Contention\r3. Cluster Utilization\r4. ESXi Contention\r5. ESXi Utilization\r6. Datastore Performance\r7. vSAN Contention\r8. vSAN Utilization\r9. Network Performance\r10. VM Contention\r11. VM Utilization\r12. Guest OS Performance Profiling\r13. Storage Heavy Hitters\r14. Network Top Talkers\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-2---performance-management/",
      "title": "Chapter 2 - Performance Management",
      "tags": [],
      "description": "",
      "content": "Chapter 2 Performance Management Performance is about ensuring workloads get the necessary resources. KPIs can be used to identify performance problems, giving early warnings before SLA is breached.\n1. A Day In The Life of a Cloud Admin\r2. The 3 Realms\r3. Plan | Monitor | Troubleshoot | Optimize\r4. Contention vs Utilization\r5. Performance vs Capacity\r6. Performance SLA\r7. KPI vs. SLA\r8. Depth vs Breadth\r9. Leading Indicators\r10. Baseline Profiling\r11. Optimized Performance\r12. Root Cause Analysis\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-3---capacity-dashboards/",
      "title": "Chapter 3 - Capacity Dashboards",
      "tags": [],
      "description": "",
      "content": "Chapter 3 Capacity Dashboards The capacity dashboards aims to implement the capacity concept covered in Capacity Management chapter, and complement the existing product pages.\n1. Design Considerations\r2. Cluster Capacity\r3. ESXi Capacity\r4. Datastore Capacity\r5. vSAN Capacity\r6. VM Capacity\r7. VM Reclamation\r8. VM Rightsizing\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-3---capacity-management/",
      "title": "Chapter 3 - Capacity Management",
      "tags": [],
      "description": "",
      "content": "Chapter 3 Capacity Management At the heart of capacity management is balancing demand and supply. It is about meeting demand with the lowest possible cost.\n1. \u0026#34;Good\u0026#34; Advice\r2. End-to-End Capacity\r3. Capacity Planning\r4. Demand Model\r5. Allocation Model\r6. Usable Capacity\r7. Projection\r8. Peak Utilization\r9. Storage Capacity\r10. Optimized Capacity\r11. Reclamation\r12. Rightsizing\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-3---memory-metrics/",
      "title": "Chapter 3 - Memory Metrics",
      "tags": [],
      "description": "",
      "content": "Chapter 3 Memory Metrics We have covered CPU in depth in the previous chapter. Let\u0026rsquo;s now take a trip down memory lane.\nMemory differs from CPU as it is a form of storage. CPU is highly transient in nature. Instructions enter and leave the execution pipelines in less than a nanosecond. Memory is basically a collection of pages (blocks) in physical DIMM. Information is stored in memory in standard block sizes, typically 4 KB or 2 MB. Each block is called a page. At the lowest level, the memory pages are just a series of zeroes and ones. MS Windows initializes its pages with 0, hence there is zero page counter in ESXi.\nWhile CPU discards instructions as they leave the CPU pipeline, memory keeps information for a much longer period of time. We are comparing nanoseconds to seconds (or longer, up to months, depending upon the uptime of your VM).\nKeeping this concept in mind is critical as you review the memory counters. Memory has a very different nature compared to CPU, and the storage nature of memory is the reason why memory monitoring is more challenging than CPU monitoring. Unlike CPU, memory has 2 dimensions: Speed and Space\nSpeed is measured in nanoseconds. The only counter ESXi has is Memory Latency. This counter increases when the time to read from the RAM is longer than usual. The counter tracks the percentage of memory space that\u0026rsquo;s taking longer than expected. It\u0026rsquo;s not tracking the actual latency in nanosecond. This is the opposite of Disk, where we track the actual latency, but not the percentage of amount of space that is facing latency. Both are storage, but \u0026ldquo;server people\u0026rdquo; and \u0026ldquo;storage people\u0026rdquo; measure them differently! Space is measured in GB. This is the bulk of the counters. 1. Virtual Memory\r2. Guest OS vs VM\r3. Guest OS\r4. VM\r5. ESXi Host\r6. Other Metrics\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-4---configuration-dashboards/",
      "title": "Chapter 4 - Configuration Dashboards",
      "tags": [],
      "description": "",
      "content": "Chapter 4 Configuration Dashboards The configuration dashboards aims to implement the concept covered in Configuration Management chapter.\nEach operation is like a fingerprint. While there are commonalities, each customer runs their operations a little differently. Hence it\u0026rsquo;s not possible to design one dashboard that meet every customer\u0026rsquo;s operational needs. A configuration that is important for one may not even be relevant for another. We encourage you to tailor this dashboard to your unique environment. If needed, widgets can be collapsed or expanded allowing more relevant data to be displayed.\n1. Design Considerations\r2. VM Configuration\r3. Cluster Configuration\r4. ESXi Configuration\r5. Network Configuration\r6. vSAN Configuration\r7. Consumer / Correct It?\r8. Consumer / Update It?\r9. Consumer / Simplify It?\r10. Consumer / Optimize It?\r11. Provider / Correct It?\r12. Provider / Update It?\r13. Provider / Simplify It?\r14. Provider / Optimize It?\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-4---configuration-management/",
      "title": "Chapter 4 - Configuration Management",
      "tags": [],
      "description": "",
      "content": "Chapter 4 Configuration Management Configuration Management is about ensuring the actual configuration settings matches the intended or desired value. The configuration of hardware and software products must be identical with the documented systems architecture. Deviation can result in security or compliance issue, performance degradation or availability risk.\n1. Overview\r2. Review Flow\r3. Plan vs Reality\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-4---storage-metrics/",
      "title": "Chapter 4 - Storage Metrics",
      "tags": [],
      "description": "",
      "content": "Chapter 4 Storage Metrics The metrics can be largely grouped into two: Speed and Space.\nSpace as in disk space, is measured in bytes, such as gigabyte. Speed is measured in 2 ways (contention and utilization, and utilization is further divided into IOPS and Throughput. Throughput = IOPS x Block Size.\n1. The Layers in Storage\r2. VM\r3. ESXi Host\r4. Datastore\r5. vSAN\r6. Storage Array\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-5---availability-dashboards/",
      "title": "Chapter 5 - Availability Dashboards",
      "tags": [],
      "description": "",
      "content": "Chapter 5 Availability Dashboards The availability dashboards aims to implement the capacity concept covered in Availability Management chapter. They are rather limited, hence if you have something let\u0026rsquo;s collaborate!\n1. VM Availability\r2. vSphere Availability\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-5---cost-management/",
      "title": "Chapter 5 - Cost Management",
      "tags": [],
      "description": "",
      "content": "Chapter 5 Cost Management With hardware becoming commodity and infrastructure becoming invisible, price has become a common denominator among all IaaS providers. Applications can run spanning multiple cloud, so whichever cheaper gets the deal to run the applications.\n1. Dare to Compare\r2. Price\r3. Cost\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-5---network-metrics/",
      "title": "Chapter 5 - Network Metrics",
      "tags": [],
      "description": "",
      "content": "Chapter 5 Network Metrics Network monitoring is complex, especially in large data centers. Adding network virtualization takes the complexity of performance troubleshooting even higher.\n1. Why Network Monitoring Is Unique\r2. SDDC Network Monitoring\r3. Guest OS\r4. VM\r5. ESXi Host\r6. Distributed Switch\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-6---compliance-management/",
      "title": "Chapter 6 - Compliance Management",
      "tags": [],
      "description": "",
      "content": "Chapter 6 Compliance Management In general, compliance means conforming to a rule, such as a specification, policy, standard or law . In context of this book, compliance relates to conformance to the security standards set by the organization. This chapter will cover how you can use vRealize Operations to make sure your organization is always in compliance with the security policies required by the security team.\n1. Overview\r2. Security Approach\r3. Continuous Compliance\r4. How the Policies Work\r5. Regulatory Benchmarks\r6. Custom Benchmarks\r7. Checking the Result\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-6---noc-dashboards/",
      "title": "Chapter 6 - NOC Dashboards",
      "tags": [],
      "description": "",
      "content": "Chapter 6 NOC Dashboards Network Operations Center has specific requirements and constraints, hence it\u0026rsquo;s covered as a separate chapter. As requirements vary widely among customers, what is provided out of the box are examples to show case the possibilities.\n1. Design Considerations\r2. Live! Cluster Performance Dashboard\r3. Live Cluster Utilization Dashboard\r4. Live! Heavy Hitter Dashboard\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/metrics/chapter-6---other-metrics/",
      "title": "Chapter 6 - Other Metrics",
      "tags": [],
      "description": "",
      "content": "Chapter 6 Other Metrics This section covers metrics and properties beyond the core metrics covered in previous chapter.\n1. Troubleshooting Metrics\r2. VMKernel\r3. vSphere Cluster\r4. VMware Tools\r5. Miscellaneous\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/operations-management/chapter-7---availability-management/",
      "title": "Chapter 7 - Availability Management",
      "tags": [],
      "description": "",
      "content": "Chapter 7 Availability Management Availability is a characteristic of a system which aims to ensure an agreed level of operational performance, usually uptime. We strive towards achieving higher uptime or higher availability of the solution, which can be business service or infrastructure service.\nHigh availability is hard to architect. Each additional nine (as in going up from 99.999% to 99.9999% availability) often requires a different architecture. For non-technical folks, it\u0026rsquo;s easy to see \u0026ldquo;hey it\u0026rsquo;s just another decimal\u0026rdquo; when viewed from availability angle. The correct view should be from the non-availability angle, where the downtime window actually goes down by 1000%. Instead of having 100 minutes of downtime you only have 1 minute, so suddenly every second matters. For deeper reading, review this by Ivan Pepelnjak.\n1. Standalone System\r2. Multi Component System\r3. Availability Reporting\r4. Disaster Avoidance and Recovery\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-7---executive-summary-dashboards/",
      "title": "Chapter 7 - Executive Summary Dashboards",
      "tags": [],
      "description": "",
      "content": "Chapter 7 Executive Summary Dashboards IT Senior Management has a different set requirements, and may even prefer information to be emailed.\n1. Design Considerations\r2. Inventory Summary\r3. Capacity Summary\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-8---true-visibility-suite-dashboards/",
      "title": "Chapter 8 - True Visibility Suite Dashboards",
      "tags": [],
      "description": "",
      "content": "Chapter 8 True Visibility Suite Dashboards Before we get into True Visibility Suite (TVS), let\u0026rsquo;s talk generally about vRealize Operations management packs. They can be broken up into three groups:\nNative - there are \u0026gt;20 management packs currently out of the box with vRealize Operations. They are provided by VMware and are shipped together with the products. TVS - there are \u0026gt;50 management packs in the TVS. They are provided by VMware but focused on non-VMware products. Others - there are dozens of these, some provided by VMware, some not. They are all available on the VMware Marketplace. The TVS management packs come with dashboards, anywhere from a few to a dozen depending on the maturity of the management pack. These dashboards are designed to highlight the target technology as well as relate it back to the relevent vSphere technology, providing the user with end-to-end visibility in their environment.\nWe\u0026rsquo;ll explore vRTVS dashboards via three of the most popular management packs:\nManagement Pack for Microsoft SQL Server Management Pack for Cisco UCS Management Pack for NetApp FAS \u0026amp; AFF 1. Microsoft SQL Server\r2. Cisco UCS Fabric Interconnect\r3. NetApp Storage\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/dashboards/chapter-9---other-dashboards/",
      "title": "Chapter 9 - Other Dashboards",
      "tags": [],
      "description": "",
      "content": "Chapter 9 Other Dashboards These dashboards are not part of vRealize Operations, yet! We can\u0026rsquo;t possibly ship every dashboard for each roles and use case, so I provided them here as examples to show case the possibilities. Check out the VMware vRealize Operations Sample Exchange to find and download popular dashboards.\n1. Green Operations\r2. Multi-Tier Applications\r3. VM Migration\r4. Role-Based Dashboard\r5. vSAN File Services\r"
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/categories/",
      "title": "Categories",
      "tags": [],
      "description": "",
      "content": ""
   },
   {
      "uri": "https://orsox89.github.io/vmware-operations-guide-web/tags/",
      "title": "Tags",
      "tags": [],
      "description": "",
      "content": ""
   }]
